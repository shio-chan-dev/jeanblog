[{"content":"What Is size_t? Why C++ Loops Prefer size_t Over int Subtitle / Abstract When you iterate containers with a for loop, size_t is often safer and closer to the intended meaning than int. This post uses the ACERS structure to explain what size_t is, why it is used, the common pitfalls, and practical patterns for production C++.\nMeta Reading time: 8-10 minutes Tags: C++, size_t, type system, loops, STL SEO keywords: size_t usage, size_t vs int, C++ loop initialization, size_t underflow Meta description: Explain size_t and why loops often use it, with safe patterns and engineering scenarios. Target readers C++ beginners who are new to size_t, sizeof, and container size() return types Mid-level engineers who have seen -Wsign-compare warnings or unsigned underflow bugs Engineers writing cross-platform or high-performance C++ Background / Motivation In C++ code, you often see loops like:\nfor (size_t i = 0; i \u0026lt; vec.size(); ++i) { ... } Common questions:\nWhy not use the more \u0026ldquo;obvious\u0026rdquo; int? What exactly is size_t, and why is it unsigned? Where are the pitfalls? This article answers those questions.\nA - Algorithm (Problem and Approach) The question Why use size_t for loop indices and sizes instead of int in C++?\nThis is fundamentally about type semantics and API consistency:\nsize_t is the standard type for object sizes and indices int is a signed counter with different semantics Basic example 1: container size and index #include \u0026lt;vector\u0026gt; std::vector\u0026lt;int\u0026gt; v{1, 2, 3}; for (std::size_t i = 0; i \u0026lt; v.size(); ++i) { // i matches v.size() type; no signed/unsigned warning } Basic example 2: unsigned underflow #include \u0026lt;cstddef\u0026gt; std::size_t n = 0; std::size_t x = n - 1; // not -1, but a very large positive number Concept sketch:\nsize_t (unsigned) : 0 ---------------------\u0026gt; SIZE_MAX int (signed) : -2^(N-1) ---- 0 ---- 2^(N-1)-1 Key point: size_t cannot represent negative numbers; subtraction can wrap to a huge value.\nC - Concepts (Core Ideas) What is size_t? size_t is an unsigned integer type that can represent the size of any object. sizeof returns size_t. On 64-bit systems it is typically 64-bit; on 32-bit systems it is typically 32-bit. #include \u0026lt;cstddef\u0026gt; std::size_t n = sizeof(int); What category does this belong to? Type semantics: use types to express \u0026ldquo;size/index\u0026rdquo; API consistency: matches container size() signatures Portability: guaranteed to represent any object size Key model sizeof(T) -\u0026gt; size_t Range: 0 \u0026lt;= size_t \u0026lt;= SIZE_MAX SIZE_MAX = 2^N - 1 (N is the bit width) Practical steps (with commands) Include the header: #include \u0026lt;cstddef\u0026gt; for std::size_t. Align with API: use std::size_t or container::size_type for sizes/indices. Cache bounds: store n = v.size() to avoid repeated calls and unsigned pitfalls. Avoid unsigned underflow: do not write v.size() - 1 on possibly empty containers. Reverse iteration: use for (size_t i = n; i-- \u0026gt; 0;) or std::ssize. Enable warnings: -Wsign-compare to surface issues early. # g++ example g++ -std=c++20 -Wall -Wextra -Wsign-compare main.cpp -o demo ./demo Runnable example: safe size_t loops #include \u0026lt;cstddef\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;utility\u0026gt; #include \u0026lt;vector\u0026gt; int main() { std::vector\u0026lt;int\u0026gt; a{5, 2, 4, 6, 1}; for (std::size_t i = 0; i + 1 \u0026lt; a.size(); ++i) { bool swapped = false; std::size_t n = a.size() - i; for (std::size_t j = 0; j + 1 \u0026lt; n; ++j) { if (a[j] \u0026gt; a[j + 1]) { std::swap(a[j], a[j + 1]); swapped = true; } } if (!swapped) break; } for (int x : a) std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#39; \u0026#39;; std::cout \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // Safe reverse iteration for (std::size_t i = a.size(); i-- \u0026gt; 0; ) { std::cout \u0026lt;\u0026lt; a[i] \u0026lt;\u0026lt; \u0026#39; \u0026#39;; } std::cout \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } Why size_t is the better fit Clearer semantics: size_t means \u0026ldquo;size/length\u0026rdquo;, int means \u0026ldquo;signed count\u0026rdquo;. Larger range: on 64-bit systems, int is usually 32-bit and may overflow on huge containers. API matching: vector::size() and string::size() return size_t. Fewer implicit conversions: mixing int and size_t triggers -Wsign-compare and can break logic. E - Engineering (Real-world Usage) Below are three real engineering scenarios with background, rationale, and runnable examples.\nScenario 1: Large-scale batch processing (C++) Background: At billion-scale data, container sizes can exceed 2^31. Why it fits: size_t can represent the range and aligns with STL.\n#include \u0026lt;cstddef\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; int main() { std::vector\u0026lt;int\u0026gt; data(5, 1); std::size_t sum = 0; for (std::size_t i = 0; i \u0026lt; data.size(); ++i) { sum += static_cast\u0026lt;std::size_t\u0026gt;(data[i]); } std::cout \u0026lt;\u0026lt; sum \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } Scenario 2: Memory allocation and buffers (C) Background: C APIs like malloc and memcpy use size_t for byte counts. Why it fits: consistent across platforms and safe for large allocations.\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(void) { size_t n = 5; int *p = (int*)malloc(n * sizeof(int)); if (!p) return 1; for (size_t i = 0; i \u0026lt; n; ++i) p[i] = (int)i; for (size_t i = 0; i \u0026lt; n; ++i) printf(\u0026#34;%d \u0026#34;, p[i]); printf(\u0026#34;\\n\u0026#34;); free(p); return 0; } Scenario 3: Cross-platform library APIs (C++) Background: API functions take buffer length parameters. Why it fits: size_t is the universal size type for callers on different platforms.\n#include \u0026lt;cstddef\u0026gt; #include \u0026lt;cstdint\u0026gt; #include \u0026lt;iostream\u0026gt; std::uint8_t checksum(const std::uint8_t* buf, std::size_t len) { std::uint8_t acc = 0; for (std::size_t i = 0; i \u0026lt; len; ++i) { acc ^= buf[i]; } return acc; } int main() { std::uint8_t payload[] = {1, 2, 3, 4}; std::cout \u0026lt;\u0026lt; static_cast\u0026lt;int\u0026gt;(checksum(payload, sizeof(payload))) \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } R - Reflection (Deep Dive) Time and space complexity The loop examples are typically O(n) time O(1) extra space This is independent of int vs size_t; the difference is correctness and maintainability.\nAlternative approaches Option Pros Cons Use cases int index Simple Small range, signed/unsigned mismatch Small data, teaching examples size_t index Large range, API match Unsigned underflow risk Most size/index cases std::ssize Signed, safe reverse Requires C++20 When negative values are meaningful Iterators/range for Safest No index When you do not need indices Why this approach is most practical\nsize_t is the standard size type with best compatibility. Safe patterns avoid underflow pitfalls. Aligns naturally with STL APIs and avoids warnings. Common questions and pitfalls Is size_t always 64-bit? No, it depends on platform width. Is auto i = 0 OK? It deduces int, not size_t. Why is v.size() - 1 dangerous? Underflows on empty containers. Why is for (size_t i = n - 1; i \u0026gt;= 0; --i) wrong? i \u0026gt;= 0 is always true for unsigned. Does int avoid underflow? It avoids unsigned underflow but introduces range and conversion risks. Best practices Prefer std::size_t or container::size_type for sizes and indices. Cache n = v.size() to avoid repeated calls and reduce risk. For reverse loops use for (size_t i = n; i-- \u0026gt; 0;) or std::ssize. Use range-for if you do not need indices. Enable -Wsign-compare to surface bugs early. S - Summary Key takeaways size_t is the standard type for object size and index; sizeof returns it. It matches vector::size() and avoids signed/unsigned mismatch. Its range is larger than int on 64-bit systems. Unsigned subtraction can underflow; write conditions to avoid it. Reverse iteration has safe patterns; do not use i \u0026gt;= 0 with unsigned. References and further reading C++ reference: std::size_t: https://en.cppreference.com/w/cpp/types/size_t C++ reference: std::ssize: https://en.cppreference.com/w/cpp/iterator/ssize ISO C standard: size_t: https://en.cppreference.com/w/c/types/size_t Conclusion size_t is not a mysterious type. It is the standard way C/C++ expresses sizes and indices. If you avoid unsigned underflow and use safe loop conditions, it is more robust and more consistent than int. Consider enabling -Wsign-compare and cleaning up mixed-sign usage in your codebase.\nCall to Action (CTA) Search your codebase for places where size() is mixed with int, switch to size_t, and run tests. If you have hit a bug related to this, share the case and learnings.\n","permalink":"http://localhost:1313/en/dev/c++/size_t-why-not-int-loop/","summary":"\u003ch1 id=\"what-is-size_\"\u003e\u003cstrong\u003eWhat Is size_t? Why C++ Loops Prefer size_t Over int\u003c/strong\u003e\u003c/h1\u003e\n\u003ch3 id=\"subtitle--abstract\"\u003eSubtitle / Abstract\u003c/h3\u003e\n\u003cp\u003eWhen you iterate containers with a \u003ccode\u003efor\u003c/code\u003e loop, \u003ccode\u003esize_t\u003c/code\u003e is often safer and closer to the intended meaning than \u003ccode\u003eint\u003c/code\u003e. This post uses the ACERS structure to explain what \u003ccode\u003esize_t\u003c/code\u003e is, why it is used, the common pitfalls, and practical patterns for production C++.\u003c/p\u003e\n\u003ch3 id=\"meta\"\u003eMeta\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eReading time: 8-10 minutes\u003c/li\u003e\n\u003cli\u003eTags: C++, size_t, type system, loops, STL\u003c/li\u003e\n\u003cli\u003eSEO keywords: size_t usage, size_t vs int, C++ loop initialization, size_t underflow\u003c/li\u003e\n\u003cli\u003eMeta description: Explain size_t and why loops often use it, with safe patterns and engineering scenarios.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"target-readers\"\u003eTarget readers\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eC++ beginners who are new to \u003ccode\u003esize_t\u003c/code\u003e, \u003ccode\u003esizeof\u003c/code\u003e, and container \u003ccode\u003esize()\u003c/code\u003e return types\u003c/li\u003e\n\u003cli\u003eMid-level engineers who have seen \u003ccode\u003e-Wsign-compare\u003c/code\u003e warnings or unsigned underflow bugs\u003c/li\u003e\n\u003cli\u003eEngineers writing cross-platform or high-performance C++\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"background--motivation\"\u003eBackground / Motivation\u003c/h3\u003e\n\u003cp\u003eIn C++ code, you often see loops like:\u003c/p\u003e","title":"What Is size_t? Why C++ Loops Prefer size_t Over int"},{"content":" Subtitle / Abstract A basic counting problem: use frequency + combinations to drop O(n^2) to O(n). Includes engineering use cases and portable implementations.\nReading time: 8-10 minutes Tags: hash-table, counting, array SEO keywords: Good Pairs, hash map, frequency Meta description: Hash counting solution for Good Pairs with complexity and code. Target readers Beginners learning hash tables and counting Engineers who want to map interview patterns to real stats tasks Interview prep for basic counting models Background / Motivation Counting equal pairs is a classic problem. A double loop is O(n^2). With frequency counting, you can solve it in linear time and scale to large data.\nA - Algorithm (Problem and approach) Problem Given an integer array nums, a pair (i, j) is a good pair if nums[i] == nums[j] and i \u0026lt; j. Return the number of good pairs.\nInput/Output Name Type Description nums int[] integer array return int number of good pairs Examples nums output notes [1, 2, 3, 1, 1, 3] 4 (0,3) (0,4) (3,4) (2,5) [1, 1, 1, 1] 6 C(4,2) = 6 [1, 2, 3] 0 no duplicates Simple intuition:\nValue 1 appears 3 times -\u0026gt; C(3,2)=3 Value 3 appears 2 times -\u0026gt; C(2,2)=1 Total = 4 C - Concepts (Core ideas) Frequency count: count occurrences of each value Combinations: if value appears c times, pairs = c*(c-1)/2 Hash table: O(1) average update Key formula:\nFor each value v with count c: Pairs = c * (c - 1) / 2 One-pass model:\nans += count[nums[i]] count[nums[i]] += 1 Practical steps Initialize count and ans = 0 For each element x, add count[x] to ans Increment count[x] E - Engineering (Real-world usage) Scenario 1: Data quality scoring (Python) Duplicate-pair score for a column:\ndef duplicate_pair_score(values): count = {} score = 0 for v in values: score += count.get(v, 0) count[v] = count.get(v, 0) + 1 return score print(duplicate_pair_score([\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;A\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;A\u0026#34;])) Scenario 2: Batch task dedup weight (Go) package main import \u0026#34;fmt\u0026#34; func goodPairs(ids []int) int { count := map[int]int{} ans := 0 for _, id := range ids { ans += count[id] count[id]++ } return ans } func main() { fmt.Println(goodPairs([]int{7, 7, 8, 9, 7})) } Scenario 3: Frontend duplicate warning (JS) function goodPairs(items) { const count = new Map(); let ans = 0; for (const x of items) { ans += count.get(x) || 0; count.set(x, (count.get(x) || 0) + 1); } return ans; } console.log(goodPairs([\u0026#34;u1\u0026#34;, \u0026#34;u2\u0026#34;, \u0026#34;u1\u0026#34;, \u0026#34;u1\u0026#34;])); R - Reflection Complexity Time: O(n) Space: O(n) Alternatives Approach Time Space Notes double loop O(n^2) O(1) simple but slow sort and group O(n log n) O(1) changes order hash count (one pass) O(n) O(n) fastest in practice Pitfalls Add count[x] before incrementing to avoid self-pairing Use 64-bit integers if counts are large Pre-size hash map if possible S - Summary Good pairs equal combinations of equal values Hash counting drops O(n^2) to O(n) One-pass counting is clean and safe This model transfers to dedup stats, quality scoring, and logs Conclusion Good pairs are a deceptively simple counting problem. Once you master hash counting, many similar tasks become trivial.\nReferences https://leetcode.com/problems/number-of-good-pairs/ https://en.wikipedia.org/wiki/Combination https://docs.python.org/3/library/stdtypes.html#mapping-types-dict https://en.cppreference.com/w/cpp/container/unordered_map https://doc.rust-lang.org/std/collections/struct.HashMap.html Call to Action (CTA) Use this counting model as a base and adapt it to three-sum variants or grouped stats. Share your approach in comments.\nMulti-language reference implementations from typing import List def num_identical_pairs(nums: List[int]) -\u0026gt; int: count = {} ans = 0 for x in nums: ans += count.get(x, 0) count[x] = count.get(x, 0) + 1 return ans if __name__ == \u0026#34;__main__\u0026#34;: print(num_identical_pairs([1, 2, 3, 1, 1, 3])) #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; typedef struct { int key; int count; int used; } Entry; static unsigned hash_int(int key) { return (uint32_t)key * 2654435761u; } static int find_slot(Entry *table, int cap, int key, int *found) { unsigned mask = (unsigned)cap - 1u; unsigned idx = hash_int(key) \u0026amp; mask; while (table[idx].used \u0026amp;\u0026amp; table[idx].key != key) { idx = (idx + 1u) \u0026amp; mask; } *found = table[idx].used \u0026amp;\u0026amp; table[idx].key == key; return (int)idx; } long long num_identical_pairs(const int *nums, int n) { int cap = 1; while (cap \u0026lt; n * 2) cap \u0026lt;\u0026lt;= 1; if (cap \u0026lt; 2) cap = 2; Entry *table = (Entry *)calloc((size_t)cap, sizeof(Entry)); if (!table) return 0; long long ans = 0; for (int i = 0; i \u0026lt; n; ++i) { int found = 0; int pos = find_slot(table, cap, nums[i], \u0026amp;found); if (found) { ans += table[pos].count; table[pos].count += 1; } else { table[pos].used = 1; table[pos].key = nums[i]; table[pos].count = 1; } } free(table); return ans; } int main(void) { int nums[] = {1, 2, 3, 1, 1, 3}; printf(\u0026#34;%lld\\n\u0026#34;, num_identical_pairs(nums, 6)); return 0; } #include \u0026lt;iostream\u0026gt; #include \u0026lt;unordered_map\u0026gt; #include \u0026lt;vector\u0026gt; long long num_identical_pairs(const std::vector\u0026lt;int\u0026gt; \u0026amp;nums) { std::unordered_map\u0026lt;int, long long\u0026gt; count; long long ans = 0; for (int x : nums) { ans += count[x]; count[x] += 1; } return ans; } int main() { std::vector\u0026lt;int\u0026gt; nums{1, 2, 3, 1, 1, 3}; std::cout \u0026lt;\u0026lt; num_identical_pairs(nums) \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; return 0; } package main import \u0026#34;fmt\u0026#34; func numIdenticalPairs(nums []int) int64 { count := map[int]int64{} var ans int64 = 0 for _, x := range nums { ans += count[x] count[x]++ } return ans } func main() { fmt.Println(numIdenticalPairs([]int{1, 2, 3, 1, 1, 3})) } use std::collections::HashMap; fn num_identical_pairs(nums: \u0026amp;[i32]) -\u0026gt; i64 { let mut count: HashMap\u0026lt;i32, i64\u0026gt; = HashMap::new(); let mut ans: i64 = 0; for \u0026amp;x in nums { let c = *count.get(\u0026amp;x).unwrap_or(\u0026amp;0); ans += c; count.insert(x, c + 1); } ans } fn main() { let nums = vec![1, 2, 3, 1, 1, 3]; println!(\u0026#34;{}\u0026#34;, num_identical_pairs(\u0026amp;nums)); } function numIdenticalPairs(nums) { const count = new Map(); let ans = 0; for (const x of nums) { ans += count.get(x) || 0; count.set(x, (count.get(x) || 0) + 1); } return ans; } console.log(numIdenticalPairs([1, 2, 3, 1, 1, 3])); ","permalink":"http://localhost:1313/en/alg/leetcode/good-pairs-count-acers/","summary":"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eSubtitle / Abstract\u003c/strong\u003e\nA basic counting problem: use frequency + combinations to drop O(n^2) to O(n). Includes engineering use cases and portable implementations.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eReading time\u003c/strong\u003e: 8-10 minutes\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTags\u003c/strong\u003e: \u003ccode\u003ehash-table\u003c/code\u003e, \u003ccode\u003ecounting\u003c/code\u003e, \u003ccode\u003earray\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSEO keywords\u003c/strong\u003e: Good Pairs, hash map, frequency\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMeta description\u003c/strong\u003e: Hash counting solution for Good Pairs with complexity and code.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"target-readers\"\u003eTarget readers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eBeginners learning hash tables and counting\u003c/li\u003e\n\u003cli\u003eEngineers who want to map interview patterns to real stats tasks\u003c/li\u003e\n\u003cli\u003eInterview prep for basic counting models\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"background--motivation\"\u003eBackground / Motivation\u003c/h2\u003e\n\u003cp\u003eCounting equal pairs is a classic problem. A double loop is O(n^2). With frequency counting, you can solve it in linear time and scale to large data.\u003c/p\u003e","title":"Data Structures Basics: Number of Good Pairs (Hash Counting ACERS)"},{"content":"XOR and RC4: From Principles to Go Practice (with Safer Alternatives) Subtitle / Abstract Use minimal math to explain XOR and RC4, provide runnable Go examples, and clarify why RC4 is considered insecure with recommended alternatives.\nTarget readers Backend engineers reading legacy RC4 code Beginners who confuse encoding and encryption Intermediate developers building a stream-cipher mental model Background / Motivation Many systems still contain RC4 or custom decryption logic. Common mistakes include treating Base64 as encryption and ignoring integrity checks. Understanding XOR and RC4 helps you evaluate security correctly and avoid copying outdated designs into new systems.\nCore concepts XOR: bitwise operation, reversible Stream cipher: XOR a pseudorandom keystream with plaintext bytes RC4: classic stream cipher, no longer recommended Base64: encoding, not encryption Integrity: encryption alone does not prevent tampering Practical steps Receive a Base64 string (often RC4 output) Decode Base64 to raw bytes Initialize RC4 with a shared key XOR keystream with bytes Convert output to UTF-8 text if it is textual Runnable example (Go) package main import ( \u0026#34;crypto/rc4\u0026#34; \u0026#34;encoding/base64\u0026#34; \u0026#34;fmt\u0026#34; ) func rc4XOR(key string, data []byte) ([]byte, error) { c, err := rc4.NewCipher([]byte(key)) if err != nil { return nil, err } out := make([]byte, len(data)) c.XORKeyStream(out, data) return out, nil } func encryptToBase64RC4(key, plaintext string) (string, error) { out, err := rc4XOR(key, []byte(plaintext)) if err != nil { return \u0026#34;\u0026#34;, err } return base64.StdEncoding.EncodeToString(out), nil } func decryptBase64RC4(key, encoded string) (string, error) { raw, err := base64.StdEncoding.DecodeString(encoded) if err != nil { return \u0026#34;\u0026#34;, err } out, err := rc4XOR(key, raw) if err != nil { return \u0026#34;\u0026#34;, err } return string(out), nil } func main() { key := \u0026#34;demo-key\u0026#34; plaintext := \u0026#34;hello rc4\u0026#34; enc, _ := encryptToBase64RC4(key, plaintext) dec, _ := decryptBase64RC4(key, enc) fmt.Println(enc) fmt.Println(dec) } Run:\ngo run rc4_demo.go Explanation XOR is reversible because a XOR b XOR b = a. RC4 generates a pseudorandom keystream and XORs it with data byte by byte. Since encryption and decryption use the same keystream, keystream reuse or bias can leak information.\nCommon pitfalls Base64 is encoding, not encryption RC4 has known biases and is deprecated Encryption alone does not provide integrity; use MAC or AEAD Reusing keys can reveal plaintext Best practices Use AES-GCM or ChaCha20-Poly1305 for new systems Migrate legacy RC4 systems as soon as possible Consider confidentiality and integrity together Conclusion XOR is the core operation behind stream ciphers. RC4 is easy to understand but unsafe; it is suitable for reading legacy code, not new design. Modern systems should use AEAD algorithms instead.\nReferences https://www.rfc-editor.org/rfc/rfc6229 https://www.rfc-editor.org/rfc/rfc7465 https://en.wikipedia.org/wiki/RC4 https://pkg.go.dev/crypto/rc4 Meta Reading time: 8 minutes Tags: go, security, crypto, rc4, xor SEO keywords: XOR, RC4, stream cipher, Go, encryption, Base64 Meta description: Explain XOR and RC4 with runnable Go examples and why RC4 is no longer secure. Call to Action (CTA) After running the demo, replace RC4 with AES-GCM and document the differences and migration cost for your team.\n","permalink":"http://localhost:1313/en/dev/go/xor-rec4-primer/","summary":"\u003ch1 id=\"xor-and-rc4-from-principles-to-go-practice-with-safer-alternatives\"\u003eXOR and RC4: From Principles to Go Practice (with Safer Alternatives)\u003c/h1\u003e\n\u003ch2 id=\"subtitle--abstract\"\u003eSubtitle / Abstract\u003c/h2\u003e\n\u003cp\u003eUse minimal math to explain XOR and RC4, provide runnable Go examples, and clarify why RC4 is considered insecure with recommended alternatives.\u003c/p\u003e\n\u003ch2 id=\"target-readers\"\u003eTarget readers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eBackend engineers reading legacy RC4 code\u003c/li\u003e\n\u003cli\u003eBeginners who confuse encoding and encryption\u003c/li\u003e\n\u003cli\u003eIntermediate developers building a stream-cipher mental model\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"background--motivation\"\u003eBackground / Motivation\u003c/h2\u003e\n\u003cp\u003eMany systems still contain RC4 or custom decryption logic. Common mistakes include treating Base64 as encryption and ignoring integrity checks. Understanding XOR and RC4 helps you evaluate security correctly and avoid copying outdated designs into new systems.\u003c/p\u003e","title":"XOR and RC4: From Principles to Go Practice (with Safer Alternatives)"},{"content":" Final post of the series: put all algorithms into one decision framework so you can quickly choose what to use, why it fits, and how to validate in real projects.\nTarget Readers Engineers who need to justify sort choices in projects/interviews/presentations. People who want a practical cheat sheet using size, distribution, stability, and memory. Background and Motivation Too many algorithms lead to \u0026ldquo;default quicksort\u0026rdquo; or \u0026ldquo;blind stability\u0026rdquo; without a framework. This post offers an actionable selection table + test checklist covering built-ins, non-comparison, external sort, and hybrids. A - Algorithm (Theme and Quick Reference) Core question: Choose a sorting strategy under different constraints.\nQuick reference (priority suggestions)\nStable + nearly sorted: TimSort / merge (Python/Java default). In-place + worst-case bound: Introsort (C++ std::sort idea) / heap sort. Known range/digits: counting/bucket/radix. Small/near-sorted: insertion; also as a hybrid subroutine. External sort (beyond RAM): chunk + multi-way merge (stable). Teaching/demo: bubble/selection/insertion to show stability and swap cost. C - Concepts (Core Dimensions) Dimension Focus Algorithms Time complexity average/worst quick/Introsort/heap/merge/TimSort/non-comparison Space in-place vs O(n) quick/heap/Introsort in-place; merge/TimSort/counting/radix need extra space Stability preserve relative order merge/TimSort/insertion/counting/radix; quick/heap/selection/shell are unstable Data characteristics size/order/range near-sorted -\u0026gt; TimSort/insertion; known range -\u0026gt; counting/radix; large random -\u0026gt; Introsort/quick Environment memory/external storage memory tight -\u0026gt; in-place; beyond RAM -\u0026gt; external merge E - Engineering Scenarios Scenario 1: API pagination sort (Go) Need: mid-size, no stability, memory tight. Choice: sort.Slice (Introsort idea), insertion for small segments. Validate: reverse and heavy-duplicate cases, check for degeneration and time. Scenario 2: Log batch processing (Python) Need: stable, near-sorted (by time bucket). Choice: built-in TimSort. Validate: local inversions; verify stability preserves order. Scenario 3: Large file sorting (C++) Need: data exceeds RAM, stable. Choice: external sort (chunk sort + k-way merge). Validate: chunk size vs I/O; min-heap merge; ensure stable merge. Scenario 4: Known-range integer batches (Go) Need: small range, speed. Choice: counting or radix; if range large but digits limited, use radix. Validate: estimate k vs n; stress test extremes. Scenario 5: Frontend stable table sort (JavaScript) Need: stable multi-key order. Choice: browser built-in (usually stable) or custom stable merge/TimSort; if unsure, map index to preserve stability. R - Reflection Time/space trade-off: in-place but unstable (quick/heap/Introsort) vs stable with extra memory (merge/TimSort/counting/radix). Worst-case guarantees: Introsort/heap/merge have bounds; quicksort needs anti-degeneration strategy; TimSort worst-case is still O(n log n). Data characteristics: known range/digits make non-comparison a big win; near-sorted favors TimSort/insertion. External sorting: I/O dominated; focus on chunk size, merge fan-in, and temp files. S - Summary Ask four questions first: size/distribution? stability? memory/external? range/digits? Built-in sorts are often enough: Python/Java stable TimSort; C++/Go Introsort-like unstable; customize only when needed. Non-comparison sorts are powerful under bounded range/digits; external sort handles beyond-RAM data. Hybrid strategies are the norm: insertion for small segments, heap fallback on depth, run detection + merge. Practice Guide / Steps Write a selection table: scenario -\u0026gt; requirements -\u0026gt; choice -\u0026gt; rationale. Benchmark on six datasets: random, reverse, nearly sorted, heavy duplicates, range-bounded, beyond-RAM. Add monitoring: sort time, comparisons (if measurable), memory; for external sorts track I/O. Require a \u0026ldquo;sort algorithm + rationale\u0026rdquo; field in PRs or design docs. Common Pitfalls and Notes Ignoring stability when business depends on relative order; use stable sort or index mapping. Underestimating memory: counting/radix can explode; external sort needs temp storage planning. Pivot degeneration: custom quicksort needs random/median-of-three + insertion threshold + tail recursion. Using quicksort on nearly sorted data: TimSort/insertion may be faster. Runnable Example: Simple Selection Function (Python) def choose_sort(stable: bool, n: int, range_known=False, near_sorted=False): if range_known: return \u0026#34;counting/radix\u0026#34; if stable else \u0026#34;counting/radix\u0026#34; if stable: if n \u0026gt; 5e5: return \u0026#34;merge/timsort\u0026#34; return \u0026#34;timsort\u0026#34; if near_sorted and n \u0026lt; 1e4: return \u0026#34;insertion\u0026#34; if n \u0026gt; 1e6: return \u0026#34;introsort/heap\u0026#34; return \u0026#34;introsort/quicksort\u0026#34; print(choose_sort(stable=True, n=10000, range_known=False, near_sorted=True)) References and Further Reading The previous 7 posts in this series: O(n^2) baselines, shell, merge, quick, heap, non-comparison, TimSort/Introsort. CLRS sorting chapters; Bentley \u0026amp; McIlroy \u0026ldquo;Engineering a Sort Function\u0026rdquo;. Meta Reading time: approx. 12 min SEO keywords: sorting selection, stable sort, external sort, TimSort, Introsort Meta description: sorting series finale with decision tables by scale/distribution/stability/memory plus testing guidance for real projects. Call to Action (CTA) Fill out a \u0026ldquo;sorting selection table\u0026rdquo; for your project with scenario/requirements/algorithm/rationale. Run benchmarks on six data distributions and record time/memory to validate your choice. If you need external sorting, build a chunk + merge PoC and measure I/O and storage costs. ","permalink":"http://localhost:1313/en/alg/leetcode/9.sorting-series-selection-guide/","summary":"Practical selection guide: decision tables by scale/distribution/stability/memory, engineering scenarios, test checklist, and common pitfalls to apply the series.","title":"Sorting Series (Final): Practical Selection - Choose by Scale, Stability, Memory, Distribution"},{"content":" Core idea: even with AI, you should be able to implement critical paths offline. AI accelerates; it does not replace thinking. This post combines learning science and practical workflows with a self-checklist.\nTarget readers Mid to senior engineers and tech leads who want AI speed without losing control. Team leads adopting AI-assisted coding or documentation. Engineers who already work with Git, tests, and code reviews. Background and motivation Pain points: Copy-pasting model output without understanding leads to fragile code and hard debugging. Over-reliance on prompts reduces independent implementation ability. Architecture and security decisions get driven by the model instead of the engineer. Goals: Implement critical paths from scratch without AI when needed. Use AI for validation and refactoring, not for blind generation. Build a \u0026ldquo;think first, verify later\u0026rdquo; workflow. Core concepts Feynman technique: if you can explain it simply, you understand it. Deliberate practice: target weak points with feedback and challenge. Retrieval practice: recall and derive before checking answers. Red/blue mode with AI: human writes first (blue), AI critiques (red). Replaceability: can you replace the model and still ship the feature? Practical steps Write a human plan first, then ask AI Sketch interfaces, flow, and edge cases before prompting. Limit copy/paste; hand-type key logic Routes, migrations, permissions should be typed by you; AI can review. Side-by-side comparison Left: your solution, right: AI suggestions. Keep only what you can explain. Retrieval practice loop Implement without AI, then compare with AI, mark blind spots, rewrite once. Feynman output Summarize in 3-5 sentences; if you cannot, study again. Runnable micro-exercise Implement a unique function that preserves order:\ndef unique_keep_order(items): seen = set() result = [] for x in items: if x in seen: continue seen.add(x) result.append(x) return result assert unique_keep_order([1, 2, 2, 3]) == [1, 2, 3] Exercise flow:\nRound 1: no AI, implement and test; note gaps. Round 2: compare with AI, check edge cases (e.g., unhashable items). Round 3: explain complexity and limits to a teammate or in a recording. Explanation Why limit copy/paste? It skips the recall-derive-verify loop and makes understanding shallow. Hand-typing exposes gaps in API knowledge and naming. Trade-offs Fully manual: safest but slow; use for security-critical modules. AI review: faster but needs human design and merge. AI scaffolding: good for kickstart, but requires tests and refactoring. Common questions How to avoid prompt dependence? Write pseudocode and tests first, then ask AI. What if time is tight? Ask AI for checklists or tests; you implement the core. How to prove you are not being driven? Document your decisions and reasons. Security/compliance: never paste secrets; use local or private models if needed. Best practices Weekly: rewrite a core path without AI (auth, billing, migrations). Add PR template fields: what decisions were made by humans vs AI. Use TDD: write tests first, ask AI for edge-case tests only. Keep the \u0026ldquo;explainability\u0026rdquo; rule: if you cannot explain it in 3 sentences, rework. Track blind spots and practice deliberately. Conclusion AI is a multiplier, not a driver. Keep replaceability and explanation as your safety belt. Use Feynman + deliberate practice + retrieval practice to lock in understanding. References Richard Feynman, \u0026ldquo;The Feynman Technique\u0026rdquo; Anders Ericsson, \u0026ldquo;Peak\u0026rdquo; Roediger \u0026amp; Karpicke, \u0026ldquo;Test-Enhanced Learning\u0026rdquo; Thoughtworks Technology Radar (AI-assisted coding) Meta Reading time: about 9 minutes Tags: AI assistant, engineering practice, learning methods SEO keywords: AI dependence, engineering autonomy, deliberate practice, Feynman learning, AI code review Updated: 2025-11-14 Call to Action (CTA) Pick one critical module, hand-write it, then use AI to review and record the diff. Add an \u0026ldquo;AI assistance scope\u0026rdquo; field to your PR template. Share your \u0026ldquo;no-AI rewrite\u0026rdquo; experiences and learnings. ","permalink":"http://localhost:1313/en/thoughts/thoughts/ai-usage-self-control/","summary":"How to avoid copy-paste dependence when using AI for coding: Feynman technique, deliberate practice, retrieval practice, and a practical self-check workflow.","title":"Do Not Let AI Drive You: Keep the Ability to Build Independently"},{"content":" A practical emmet-vim handbook for developers who live in Vim/Neovim but feel HTML/CSS is slow: fast install, must-know shortcuts, minimal runnable examples, and a validation/troubleshooting checklist.\nReader profile and prerequisites Frontend or full-stack engineers using Vim/Neovim for UI work. Comfortable with basic HTML/CSS and editing ~/.vimrc or init.lua. Suggested environment: Vim 8.2+ with +python3 or Neovim 0.7+; Git installed; Homebrew/Apt available. Background and problem Scenario: typing \u0026lt;div class=\u0026quot;card\u0026quot;\u0026gt;\u0026lt;img ...\u0026gt; by hand is slow and error-prone. Pain points: Repetitive HTML/CSS blocks break flow. Managing tag closures and nesting is easy to mess up. VS Code has Emmet built in; Vim lacks comparable speed without a plugin. Goal: expand a full structure in a few keystrokes; example input ul.list\u0026gt;li.item$*3\u0026gt;a{click} should expand correctly, with reliable shortcuts and configurable behavior. Core concepts Abbreviation: ul\u0026gt;li*3 expands to a full tag tree with one shortcut. Trigger key: emmet-vim default is \u0026lt;C-y\u0026gt;, (Ctrl+y then comma); \u0026lt;C-y\u0026gt;d balances/wraps tags. Context aware: in CSS, m10-20 expands to margin: 10px 20px;; in HTML, it builds tags. Numbering with $: li.item$*3 creates item1/2/3; ${} supports placeholders. Environment and dependencies Vim 8.2+ with :echo has('python3') returning 1, or Neovim 0.7+. Python 3.8+ (python3 --version) used by the Emmet engine. Any plugin manager: vim-plug, dein, lazy.nvim, packer.nvim. Optional: Node 18+ for other Emmet CLI tools (not required for emmet-vim). Typical install (vim-plug): \u0026#34; ~/.vimrc or init.vim call plug#begin(\u0026#39;~/.vim/plugged\u0026#39;) Plug \u0026#39;mattn/emmet-vim\u0026#39; call plug#end() let g:user_emmet_leader_key=\u0026#39;,\u0026#39; \u0026#34; customize leader; default is \u0026lt;C-y\u0026gt; Run :PlugInstall in Vim after setup.\nPractical steps (copy-ready) 1) Verify Python support :echo has(\u0026#39;python3\u0026#39;) Expected output is 1. If not, install a Vim build with Python3 or configure Neovim provider.\n2) Configure basic key bindings \u0026#34; Make Emmet trigger shorter: use comma as leader let g:user_emmet_leader_key=\u0026#39;,\u0026#39; \u0026#34; Enable in HTML/CSS/JSX let g:user_emmet_settings = { \\ \u0026#39;javascript.jsx\u0026#39; : { \\ \u0026#39;extends\u0026#39; : \u0026#39;html\u0026#39; \\ } \\} Expected: in HTML/JSX, type an abbreviation and press ,+, or ,+; (same as \u0026lt;C-y\u0026gt;,).\n3) HTML list example Input:\nul.list\u0026gt;li.item$*3\u0026gt;a{click me} Press ,+, to expand:\n\u0026lt;ul class=\u0026#34;list\u0026#34;\u0026gt; \u0026lt;li class=\u0026#34;item1\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;\u0026#34;\u0026gt;click me\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;item2\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;\u0026#34;\u0026gt;click me\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;item3\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;\u0026#34;\u0026gt;click me\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; 4) Wrap or rebalance tags Select text, type ul\u0026gt;li*, press ,+w (Wrap with abbreviation) to wrap it in a list. On a tag, press ,+d to balance select the parent and quickly rearrange. 5) CSS abbreviations Input: p10-20 bgc#0f172a c#e2e8f0 then trigger:\npadding: 10px 20px; background-color: #0f172a; color: #e2e8f0; 6) JSX/TSX usage Extend javascriptreact / typescriptreact in g:user_emmet_settings. In JSX, input Button.primary\u0026gt;{Submit} then trigger: \u0026lt;Button className=\u0026#34;primary\u0026#34;\u0026gt;Submit\u0026lt;/Button\u0026gt; Make sure filetype is javascriptreact/typescriptreact.\nMore frequent snippets (ready to paste) 1) Semantic page shell + top nav Input:\nheader.site\u0026gt;div.container\u0026gt;h1.logo{Brand}+nav\u0026gt;ul\u0026gt;li*3\u0026gt;a{Nav $}+button.btn.primary{Sign up} Output:\n\u0026lt;header class=\u0026#34;site\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;h1 class=\u0026#34;logo\u0026#34;\u0026gt;Brand\u0026lt;/h1\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;\u0026#34;\u0026gt;Nav 1\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;\u0026#34;\u0026gt;Nav 2\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;\u0026#34;\u0026gt;Nav 3\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;button class=\u0026#34;btn primary\u0026#34;\u0026gt;Sign up\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/header\u0026gt; 2) Form with labels and submit Input:\nform#contact\u0026gt;label[for=name]{Name}+input#name[type=text required placeholder=Your name]+label[for=email]{Email}+input#email[type=email required placeholder=hi@example.com]+button.btn[type=submit]{Send} Output:\n\u0026lt;form id=\u0026#34;contact\u0026#34;\u0026gt; \u0026lt;label for=\u0026#34;name\u0026#34;\u0026gt;Name\u0026lt;/label\u0026gt; \u0026lt;input id=\u0026#34;name\u0026#34; type=\u0026#34;text\u0026#34; required placeholder=\u0026#34;Your name\u0026#34;\u0026gt; \u0026lt;label for=\u0026#34;email\u0026#34;\u0026gt;Email\u0026lt;/label\u0026gt; \u0026lt;input id=\u0026#34;email\u0026#34; type=\u0026#34;email\u0026#34; required placeholder=\u0026#34;hi@example.com\u0026#34;\u0026gt; \u0026lt;button class=\u0026#34;btn\u0026#34; type=\u0026#34;submit\u0026#34;\u0026gt;Send\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; 3) Card grid (blog/product list) Input:\nsection.blog\u0026gt;h2{Latest Posts}+div.grid\u0026gt;article.card$*3\u0026gt;img[alt=thumb$ src=/img/thumb$.jpg]+h3{Post $}+p{Short teaser}+a.read[href=/post$]{Read more} Output (excerpt):\n\u0026lt;section class=\u0026#34;blog\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Latest Posts\u0026lt;/h2\u0026gt; \u0026lt;div class=\u0026#34;grid\u0026#34;\u0026gt; \u0026lt;article class=\u0026#34;card1\u0026#34;\u0026gt; \u0026lt;img alt=\u0026#34;thumb1\u0026#34; src=\u0026#34;/img/thumb1.jpg\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;Post 1\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;Short teaser\u0026lt;/p\u0026gt; \u0026lt;a class=\u0026#34;read\u0026#34; href=\u0026#34;/post1\u0026#34;\u0026gt;Read more\u0026lt;/a\u0026gt; \u0026lt;/article\u0026gt; ... \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; 4) Table with auto numbering Input:\ntable.table\u0026gt;thead\u0026gt;tr\u0026gt;th*3{Col $}+tbody\u0026gt;tr*3\u0026gt;td{Row $ Col 1}+td{Row $ Col 2}+td{Row $ Col 3} Output:\n\u0026lt;table class=\u0026#34;table\u0026#34;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Col 1\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Col 2\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Col 3\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Row 1 Col 1\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Row 1 Col 2\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Row 1 Col 3\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Row 2 Col 1\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Row 2 Col 2\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Row 2 Col 3\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Row 3 Col 1\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Row 3 Col 2\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Row 3 Col 3\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; 5) JSX/TSX component snippet Input:\nCard\u0026gt;Image[src=/hero.png alt=Hero aria-label=Hero]+h3{Landing}+p{Faster HTML}+Button.primary{Get started} Expanded in React/TSX:\n\u0026lt;Card\u0026gt; \u0026lt;Image src=\u0026#34;/hero.png\u0026#34; alt=\u0026#34;Hero\u0026#34; aria-label=\u0026#34;Hero\u0026#34; /\u0026gt; \u0026lt;h3\u0026gt;Landing\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;Faster HTML\u0026lt;/p\u0026gt; \u0026lt;Button className=\u0026#34;primary\u0026#34;\u0026gt;Get started\u0026lt;/Button\u0026gt; \u0026lt;/Card\u0026gt; 6) CSS quick combo (Emmet CSS syntax) Input:\nd:f ai:c jc:sb g:16 p:16 m:0 bdrs:12px bgc:#0f172a c:#e2e8f0 Output:\ndisplay: flex; align-items: center; justify-content: space-between; gap: 16px; padding: 16px; margin: 0; border-radius: 12px; background-color: #0f172a; color: #e2e8f0; 7) Wrap with abbreviation examples Select lines \u0026ldquo;Item A\u0026rdquo; and \u0026ldquo;Item B\u0026rdquo;, type ul.list\u0026gt;li*, press ,+w: \u0026lt;ul class=\u0026#34;list\u0026#34;\u0026gt; \u0026lt;li\u0026gt;Item A\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Item B\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; Great for converting raw text to a list or card container. Minimal runnable demo (local) Create demo.html: \u0026lt;!doctype html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt;\u0026lt;title\u0026gt;Emmet Demo\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- type emmet abbreviations here and trigger expand --\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Open in Vim, enter section.hero\u0026gt;h1{Hello}+p{Speed up with emmet-vim}+ul.features\u0026gt;li.feature$*3 inside \u0026lt;body\u0026gt;. Trigger expansion, save with :w, open in browser to see the result. Trade-offs and choices emmet-vim in Vim vs Emmet via LSP/completion: the former is dependency-free and instant; the latter may need Node or a server but integrates with completions. Trigger key: default \u0026lt;C-y\u0026gt; avoids conflicts but is two keystrokes; , or \u0026lt;C-e\u0026gt; is faster but can conflict with other plugins. Formatting: emmet-vim does not format; run Prettier/ESLint on output if needed. Common pitfalls and FAQ Not working: has('python3') is 0, wrong filetype, or :PlugInstall not run. JSX expands with HTML attrs: ensure javascript.jsx/javascriptreact extends html; set filetype if needed. Key conflicts: check mappings with :verbose imap , , and rebind. Multi-cursor: emmet-vim does not support it natively; use vim-visual-multi and trigger after inserting abbreviations. Performance: large expansions can be slow; use on component snippets instead of massive trees. Test and validation checklist :echo has('python3') == 1. In HTML buffer, type div#app\u0026gt;header\u0026gt;h1{Hi}+nav\u0026gt;ul\u0026gt;li*3\u0026gt;a{link$} and expand correctly. In CSS buffer, m10-20 and bgc#333 expand to valid declarations. In JSX buffer, Card\u0026gt;Button.primary{Go} expands to \u0026lt;Card\u0026gt;\u0026lt;Button className=\u0026quot;primary\u0026quot;\u0026gt;Go\u0026lt;/Button\u0026gt;\u0026lt;/Card\u0026gt;. No errors in :messages; trigger key not overridden. Performance and accessibility Prefer semantic tags (header/nav/main/section) for screen readers and SEO. Always add alt for images: img[alt=avatar src=/avatar.png]. Add aria-label placeholders for icon-only buttons. Emmet does not impact performance metrics directly, but avoid unnecessary nesting. Best practices Configure g:user_emmet_settings explicitly per filetype for HTML/JSX/TSX consistency. Customize the leader (e.g., ,) and sync it across machines via dotfiles. Combine with formatters (Prettier/StyLua/ESLint) to normalize style on save. Write a skeleton abbreviation first, then add classes and attributes. Remember $ for numbering and {} for text content. Summary and next steps You now have: install steps, key bindings, HTML/CSS/JSX examples, validation checklist, and troubleshooting. Next steps: Create team snippets as Emmet custom snippets. Combine Emmet with UltiSnips/LuaSnip for composite templates. Integrate with LSP/formatter to build a consistent save workflow. References and links Emmet docs: https://docs.emmet.io/ emmet-vim repo: https://github.com/mattn/emmet-vim Vim Python3 provider: https://github.com/neovim/neovim/wiki/FAQ#python-support Meta Estimated reading: 11 minutes; for Vim/Neovim frontend engineers. Tags: vim, neovim, emmet, frontend, productivity; category: frontend. SEO keywords: emmet-vim, Vim Emmet, HTML CSS autocompletion. Updated: 2025-11-14. CTA Create a local demo.html and expand a few abbreviations yourself. If you hit key conflicts or new scenarios, open an issue or comment. If this helped, star mattn/emmet-vim to support the author. ","permalink":"http://localhost:1313/en/dev/frontend/emmet-vim-guide/","summary":"Practical Emmet notes for Vim/Neovim users: install, key mappings, runnable examples, validation checklist, and common pitfalls to 3x your page and component speed.","title":"Emmet-Vim Speed Guide: Write HTML/CSS with Abbreviations"},{"content":" Sorting series post 8 explains two engineering hybrid sorts: TimSort (stable, run detection + merge + insertion) used by Python/Java, and Introsort (quick + heap + insertion, unstable) behind C++ std::sort.\nTarget Readers Anyone who wants to understand built-in sort behavior, stability, and degeneration protection. Engineers who need a hybrid strategy balancing average performance and worst-case bounds. People preparing interviews or talks on TimSort/Introsort. Background and Motivation Pure quicksort can degrade; pure merge needs O(n) memory and does not fully exploit near-sortedness. Hybrid sorting combines strengths: TimSort uses natural runs and stable merge; Introsort falls back to heap when recursion depth is too large and uses insertion on small segments. A - Algorithm TimSort core flow (stable)\nScan array to detect monotonic runs (increasing/decreasing; reverse decreasing runs). Extend short runs to minrun and use insertion to finish them. Merge runs following stack rules with stable merge; near-sorted data yields long runs and fewer merges. Introsort core flow (unstable)\nStart with quicksort (random/median-of-three). When recursion depth exceeds a threshold (~2*log n), switch to heap sort to avoid O(n^2). Use insertion for segments smaller than a threshold (e.g., 16/24). C - Concepts Algorithm Stable Avg Time Worst Time Space Key Points TimSort Yes O(n log n) O(n log n) O(n) run detection + stable merge + insertion Introsort No O(n log n) O(n log n) O(1) quick start + depth fallback to heap + insertion run: a monotonic contiguous subsequence; more runs means more merges. minrun: lower bound on run length (typically 32~64); short runs are extended with insertion. Depth threshold: Introsort uses 2*floor(log2 n) as a cutoff for heap fallback. E - Engineering Scenario 1: Python/Java default sort (TimSort idea) Background: stable sort with excellent performance on near-sorted data.\n# Simplified TimSort skeleton (idea only, not full merge rules) MINRUN = 32 def insertion(a, l, r): for i in range(l+1, r+1): key=a[i]; j=i-1 while j\u0026gt;=l and a[j]\u0026gt;key: a[j+1]=a[j]; j-=1 a[j+1]=key def timsort(a): n=len(a) # 1) detect runs + extend to MINRUN runs=[]; i=0 while i\u0026lt;n: j=i+1 while j\u0026lt;n and a[j]\u0026gt;=a[j-1]: j+=1 # simplified: only increasing runs l,r=i,j-1 if r-l+1 \u0026lt; MINRUN: end=min(n-1,l+MINRUN-1) insertion(a,l,end) r=end runs.append((l,r)) i=r+1 # 2) simplified merge: left to right import heapq while len(runs)\u0026gt;1: l1,r1 = runs.pop(0) l2,r2 = runs.pop(0) merge(a,l1,r1,l2,r2) runs.insert(0,(l1,r2)) return a def merge(a,l1,r1,l2,r2): buf = a[l1:r2+1] i=0; j=l2-l1; k=l1 while i\u0026lt;=r1-l1 and j\u0026lt;=r2-l1: if buf[i] \u0026lt;= buf[j]: a[k]=buf[i]; i+=1 else: a[k]=buf[j]; j+=1 k+=1 while i\u0026lt;=r1-l1: a[k]=buf[i]; i+=1; k+=1 while j\u0026lt;=r2-l1: a[k]=buf[j]; j+=1; k+=1 arr=[5,2,3,1,4] print(timsort(arr)) Scenario 2: C++ std::sort idea (Introsort) Background: low constants, in-place, worst-case bounded.\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; void insertion(vector\u0026lt;int\u0026gt;\u0026amp; a, int l, int r){ for(int i=l+1;i\u0026lt;=r;++i){int key=a[i], j=i-1; while(j\u0026gt;=l \u0026amp;\u0026amp; a[j]\u0026gt;key){a[j+1]=a[j]; j--;} a[j+1]=key;} } int partition_mid(vector\u0026lt;int\u0026gt;\u0026amp; a, int l, int r){ int m=l+(r-l)/2; if(a[m]\u0026lt;a[l]) swap(a[m],a[l]); if(a[r]\u0026lt;a[l]) swap(a[r],a[l]); if(a[r]\u0026lt;a[m]) swap(a[r],a[m]); int pivot=a[m]; int i=l-1,j=r+1; while(true){ do{i++;}while(a[i]\u0026lt;pivot); do{j--;}while(a[j]\u0026gt;pivot); if(i\u0026gt;=j) return j; swap(a[i],a[j]); } } void heapsort(vector\u0026lt;int\u0026gt;\u0026amp; a, int l, int r){ make_heap(a.begin()+l, a.begin()+r+1); sort_heap(a.begin()+l, a.begin()+r+1); } void introsort(vector\u0026lt;int\u0026gt;\u0026amp; a, int l, int r, int depth){ while(r-l+1 \u0026gt; 16){ if(depth==0){ heapsort(a,l,r); return; } int p = partition_mid(a,l,r); if(p-l \u0026lt; r-p){ introsort(a,l,p,depth-1); l=p+1; } else { introsort(a,p+1,r,depth-1); r=p; } } insertion(a,l,r); } int main(){ vector\u0026lt;int\u0026gt; a={5,2,3,1,4,9,8,7,6}; int depth = 2*log(a.size()); introsort(a,0,a.size()-1,depth); for(int x:a) cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } Scenario 3: Go/JavaScript hybrid sorting Go: built-in sort is similar to Introsort (quick + heap + insertion); check source for details. JS: use TimSort implementations for stability; otherwise mimic Introsort for in-place speed. R - Reflection Complexity: TimSort: worst O(n log n), faster on partially sorted data (long runs, fewer merges), space O(n). Introsort: worst O(n log n), average like quicksort, space O(1) ignoring recursion. Stability: TimSort is stable; Introsort is not. Trade-offs: Near-sorted + stable: TimSort (Python/Java default). Memory tight + low constants: Introsort (C++ std::sort). External sorting: TimSort/merge; with data larger than RAM, use multi-way merge. Why it works: hybrid strategies absorb strengths and avoid degeneration paths. S - Summary TimSort uses run detection + stable merge + insertion; excellent on near-sorted data and stable; default in Python/Java. Introsort starts with quicksort, falls back to heap at depth limit, uses insertion at the end; unstable but in-place and fast; used by C++ std::sort. Selection: stable + near-sorted -\u0026gt; TimSort; in-place + worst-case bound -\u0026gt; Introsort; external -\u0026gt; merge/TimSort; known range -\u0026gt; non-comparison. Understanding built-ins helps performance tuning and interviews. Practice Guide / Steps Decide on stability, memory budget, and degree of order. For TimSort: Implement run detection and reverse decreasing runs. Set minrun (32~64) and fill short runs with insertion. Implement stable merge and follow run-stack rules. For Introsort: Depth limit = 2*floor(log2 n); fallback to heap when exceeded. Use insertion for small segments; pivot random or median-of-three. Benchmark with random, nearly sorted, reverse, heavy duplicates. Common Pitfalls and Notes TimSort merge rules are complex; avoid unbalanced run stacks; keep stability. Introsort heap fallback must pass correct subranges; Hoare partition boundaries matter. Small-segment thresholds should be tuned (commonly 16~32). Runnable Example: Mini Introsort in JavaScript function insertion(a,l,r){ for(let i=l+1;i\u0026lt;=r;i++){ const key=a[i]; let j=i-1; while(j\u0026gt;=l \u0026amp;\u0026amp; a[j]\u0026gt;key){ a[j+1]=a[j]; j--; } a[j+1]=key; } } function partition(a,l,r){ const m=l+((r-l)\u0026gt;\u0026gt;1); if(a[m]\u0026lt;a[l]) [a[m],a[l]]=[a[l],a[m]]; if(a[r]\u0026lt;a[l]) [a[r],a[l]]=[a[l],a[r]]; if(a[r]\u0026lt;a[m]) [a[r],a[m]]=[a[m],a[r]]; const pivot=a[m]; let i=l-1,j=r+1; while(true){ do{i++;}while(a[i]\u0026lt;pivot); do{j--;}while(a[j]\u0026gt;pivot); if(i\u0026gt;=j) return j; [a[i],a[j]]=[a[j],a[i]]; } } function heapify(a,n,i,l){ while(true){ let largest=i, left=2*(i-l)+1+l, right=left+1; if(left\u0026lt;n \u0026amp;\u0026amp; a[left]\u0026gt;a[largest]) largest=left; if(right\u0026lt;n \u0026amp;\u0026amp; a[right]\u0026gt;a[largest]) largest=right; if(largest===i) break; [a[i],a[largest]]=[a[largest],a[i]]; i=largest; } } function heapsort(a,l,r){ const n=r+1; for(let i=Math.floor((l+r)/2); i\u0026gt;=l; i--) heapify(a,n,i,l); for(let end=r; end\u0026gt;l; end--){ [a[l],a[end]]=[a[end],a[l]]; heapify(a,end,l,l); } } function introsort(a,l=0,r=a.length-1,depth=2*Math.floor(Math.log2(a.length||1))){ while(r-l+1\u0026gt;16){ if(depth===0){ heapsort(a,l,r); return a; } const p=partition(a,l,r); if(p-l \u0026lt; r-p){ introsort(a,l,p,depth-1); l=p+1; } else { introsort(a,p+1,r,depth-1); r=p; } } insertion(a,l,r); return a; } console.log(introsort([5,2,3,1,4,9,8,7,6])); References and Further Reading Tim Peters, \u0026ldquo;Timsort\u0026rdquo; design notes (CPython source) Java Arrays.sort (object version) implementation Musser, \u0026ldquo;Introspective Sorting and Selection Algorithms\u0026rdquo; (1997) Bentley \u0026amp; McIlroy, \u0026ldquo;Engineering a Sort Function\u0026rdquo; (1993) Meta Reading time: approx. 16 min SEO keywords: TimSort, Introsort, std::sort, stable sort, hybrid sort Meta description: sorting series (8) explaining TimSort and Introsort strategies, stability, trade-offs, and engineering usage. Call to Action (CTA) Benchmark your dataset: built-in sort vs your hybrid implementation. If you need stability and near-sorted performance, try TimSort ideas; for in-place and worst-case bounds, try Introsort. Follow the series finale: the selection guide. ","permalink":"http://localhost:1313/en/alg/leetcode/8.sorting-series-timsort-introsort/","summary":"Explain Python/Java TimSort and C++ std::sort Introsort: triggers, stability, complexity, trade-offs, with skeletons and selection guidance.","title":"Sorting Series (8): TimSort and Introsort - Engineering Patterns Behind Built-in Sorts"},{"content":" Sorting series post 7 focuses on non-comparison sorting: when key range or digit length is bounded, complexity can drop to O(n+k), but space, stability, and feasibility must be balanced.\nTarget Readers Engineers sorting integer keys with known range/digits. Learners seeking lower-than-n-log-n sorting for large batches. People comparing standard library comparison sorts vs non-comparison. Background and Motivation Comparison sorts have a lower bound of Omega(n log n); non-comparison sorts bypass that by using range/digit information. Cost: extra space and restricted applicability; implementation must handle stability and memory carefully. A - Algorithm Covered algorithms: counting sort, bucket sort, radix sort (LSD).\nBasic examples\nCounting: [4, 2, 2, 8, 3], range 0..9, count -\u0026gt; prefix sums -\u0026gt; stable fill. Radix: group by ones/tens/hundreds digits, stable per digit. C - Concepts Algorithm Idea Time Space Stable Counting frequency + prefix sums O(n+k) O(k+n) Can be stable Bucket split by ranges, sort within buckets expected O(n+k) O(n+k) depends on inner sort Radix stable per-digit sort in multiple passes O(d*(n+b)) O(n+b) Yes if each pass is stable k: range size; d: number of digits; b: base (number of buckets). Stability: counting can be stable; radix requires stable passes; bucket depends on inner sort. E - Engineering Scenario 1: Small-range integer sort (Python counting) def counting_sort(a, max_val): cnt = [0]*(max_val+1) for x in a: cnt[x]+=1 # prefix sums for i in range(1, len(cnt)): cnt[i]+=cnt[i-1] out=[0]*len(a) for x in reversed(a): cnt[x]-=1 out[cnt[x]] = x return out print(counting_sort([4,2,2,8,3], 9)) Scenario 2: Bucket sort for known float distribution (JavaScript) Background: floats uniformly distributed in [0,1).\nfunction bucketSort(arr, buckets=10){ const B=Array.from({length:buckets},()=\u0026gt;[]); for(const x of arr){ const idx = Math.min(buckets-1, Math.floor(x*buckets)); B[idx].push(x); } for(const b of B) b.sort((a,b)=\u0026gt;a-b); return B.flat(); } console.log(bucketSort([0.78,0.17,0.39,0.26,0.72,0.94,0.21,0.12,0.23,0.68])); Scenario 3: Radix sort for large integers (Go, LSD) package main import \u0026#34;fmt\u0026#34; func radixLSD(a []int) { maxv := 0 for _,v := range a { if v\u0026gt;maxv { maxv=v } } exp := 1 buf := make([]int, len(a)) for maxv/exp \u0026gt; 0 { cnt := make([]int, 10) for _,v := range a { digit := (v/exp)%10; cnt[digit]++ } for i:=1;i\u0026lt;10;i++ { cnt[i]+=cnt[i-1] } for i:=len(a)-1;i\u0026gt;=0;i-- { d := (a[i]/exp)%10 cnt[d]-- buf[cnt[d]] = a[i] } copy(a, buf) exp *= 10 } } func main(){ a:=[]int{170,45,75,90,802,24,2,66}; radixLSD(a); fmt.Println(a) } Scenario 4: C++ counting sort (small range) #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; vector\u0026lt;int\u0026gt; counting_sort(const vector\u0026lt;int\u0026gt;\u0026amp; a, int maxv){ vector\u0026lt;int\u0026gt; cnt(maxv+1), out(a.size()); for(int x:a) cnt[x]++; for(int i=1;i\u0026lt;=maxv;i++) cnt[i]+=cnt[i-1]; for(int i=(int)a.size()-1;i\u0026gt;=0;i--){ int x=a[i]; cnt[x]--; out[cnt[x]]=x; } return out; } Scenario 5: Rust radix sort (LSD) pub fn radix_lsd(a: \u0026amp;mut [u32]) { let mut maxv = *a.iter().max().unwrap(); let mut exp = 1u32; let n = a.len(); let mut buf = vec![0u32; n]; while maxv/exp \u0026gt; 0 { let mut cnt = [0usize; 10]; for \u0026amp;v in a.iter() { cnt[((v/exp)%10) as usize] += 1; } for i in 1..10 { cnt[i] += cnt[i-1]; } for \u0026amp;v in a.iter().rev() { let d = ((v/exp)%10) as usize; cnt[d] -= 1; buf[cnt[d]] = v; } a.copy_from_slice(\u0026amp;buf); exp *= 10; } } R - Reflection Complexity and prerequisites: Counting: O(n+k), k is range size; if k \u0026raquo; n, not worth it. Bucket: expected O(n+k) depends on distribution; worst-case can degrade. Radix: O(d*(n+b)), d digits, base b; each pass must be stable. Trade-offs: Memory: counting/bucket needs O(k) or O(n+k); large ranges are infeasible. Stability: counting and radix can be stable; bucket depends on inner sort. Data type: best for integers or keys mappable to integers (dates, IPs, fixed-length strings). Why it works: With bounded range/digits, non-comparison sorts break the n log n lower bound. Great for logs, bucketed stats, and bulk integer sorting. S - Summary Non-comparison sorts require known range/digits/distribution and can reach O(n+k). Counting is simple and stable for small ranges; radix works for multi-digit integers; bucket depends on distribution. Core risks: memory blow-up, distribution mismatch, missing stability. Selection: small range -\u0026gt; counting; moderate digits + stable -\u0026gt; radix; uniform floats -\u0026gt; bucket; otherwise compare-based. Practice Guide / Steps Estimate range/digits: if k is close to or larger than n, be cautious. Decide stability: radix needs stable per-digit sort; bucket may need stable inner sort. Control memory: counting array length = max-min+1; radix buffers at least O(n). Test with random, all equal, huge range, skewed distribution. Common Pitfalls and Notes Counting sort with negatives needs offset (or split positive/negative). Radix loses stability if any digit pass is unstable. Bucket sort degrades on skewed distributions; increase bucket count or sort large buckets with other methods. Large memory usage calls for fallback to comparison sort or chunking. Runnable Example: Counting with negatives (Python) def counting_sort_with_neg(a): mn, mx = min(a), max(a) offset = -mn cnt = [0]*(mx - mn + 1) for x in a: cnt[x+offset]+=1 for i in range(1,len(cnt)): cnt[i]+=cnt[i-1] out=[0]*len(a) for x in reversed(a): cnt[x+offset]-=1 out[cnt[x+offset]] = x return out print(counting_sort_with_neg([3,-1,2,-1,0])) References and Further Reading CLRS non-comparison sorting chapters Donald Knuth, \u0026ldquo;The Art of Computer Programming, Vol. 3\u0026rdquo; (Sorting and Searching) Lower bounds and word-RAM model discussions on integer sorting Meta Reading time: approx. 15 min SEO keywords: counting sort, bucket sort, radix sort, non-comparison, O(n+k) Meta description: sorting series (7) explaining prerequisites, complexity, and engineering trade-offs for counting/bucket/radix with multilingual examples. Call to Action (CTA) Estimate range/digits of your dataset and implement a counting or radix sort benchmark. If distribution is skewed, tune bucket counts or use a hybrid inside large buckets. ","permalink":"http://localhost:1313/en/alg/leetcode/7.sorting-series-non-comparison/","summary":"Explain prerequisites, complexity, implementation details, and pitfalls of non-comparison sorts with multilingual examples for counting, bucket, and radix.","title":"Sorting Series (7): Non-Comparison Sorting - Counting, Bucket, Radix and the Range/Digit Tradeoff"},{"content":" For frontend developers with 1-2 years of experience who want a fast, state-driven button in Svelte. Covers state colors, disabled and loading states, accessibility (ARIA), testing, pitfalls, and runnable examples.\nTarget readers and prerequisites Frontend engineers familiar with JS/TS and new to Svelte or already using it. Developers who need a unified button style, state, and interaction in a project. Requirements: Node 18+, Svelte 5, package manager (npm/pnpm), can run npm create svelte@latest. Background / Motivation Buttons are high-frequency interactions, but style, state, and accessibility are often ignored. Dynamic class names without null protection lead to undefined or broken styles. Accessibility (keyboard and ARIA) plus loading/disabled states are product-grade requirements. Consistency needs a centralized state-to-style mapping to avoid magic strings everywhere. Core concepts State mapping: map business states to class strings via a function, not nested ternaries in templates. Optional chaining (?.) and nullish coalescing (??): safely read backend fields and provide defaults. ARIA and keyboard access: aria-busy, aria-disabled, role, tabindex help screen readers and keyboard users. Visual hierarchy: primary, secondary, ghost buttons. Environment and dependencies Node 18+, Svelte 5 UI utility classes: examples use Tailwind (replace with any styling system) Recommended commands: npm create svelte@latest demo-buttons cd demo-buttons npm install Practical steps 1) Centralize state-to-style mapping // statusTone.ts export function statusTone(status?: string) { if (status === \u0026#39;succeeded\u0026#39; || status === \u0026#39;completed\u0026#39;) { return \u0026#39;bg-emerald-600 hover:bg-emerald-700 text-white border border-emerald-600\u0026#39;; } if (status === \u0026#39;failed\u0026#39;) { return \u0026#39;bg-rose-600 hover:bg-rose-700 text-white border border-rose-600\u0026#39;; } if (status === \u0026#39;processing\u0026#39; || status === \u0026#39;pending\u0026#39;) { return \u0026#39;bg-amber-500 hover:bg-amber-600 text-white border border-amber-500\u0026#39;; } return \u0026#39;bg-slate-200 text-slate-700 border border-slate-300\u0026#39;; } Why: keep status-to-class logic centralized and maintainable; supports both completed and succeeded.\n2) Safe values inside a Svelte component \u0026lt;script lang=\u0026#34;ts\u0026#34;\u0026gt; import { statusTone } from \u0026#39;./statusTone\u0026#39;; export let status: string | undefined; export let loading = false; export let label = \u0026#39;Submit\u0026#39;; \u0026lt;/script\u0026gt; \u0026lt;button class={`inline-flex items-center gap-2 rounded-full px-4 py-2 text-sm font-semibold transition ${statusTone(status)}`} aria-busy={loading} aria-disabled={loading} disabled={loading} \u0026gt; {#if loading} \u0026lt;span class=\u0026#34;h-3 w-3 animate-spin rounded-full border-2 border-white border-t-transparent\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; {/if} {label ?? \u0026#39;Submit\u0026#39;} \u0026lt;/button\u0026gt; Notes:\nlabel ?? 'Submit' provides a default label safely. aria-busy, aria-disabled, and disabled stay in sync. 3) Optional chaining and nullish coalescing example {#if detailStatus?.status ?? record.status} \u0026lt;span class=\u0026#34;text-xs text-slate-500\u0026#34;\u0026gt; Current status: {detailStatus?.status ?? record.status ?? \u0026#39;pending\u0026#39;} \u0026lt;/span\u0026gt; {/if} ?. avoids errors if detailStatus is undefined, ?? falls back to a default.\n4) Keyboard and screen reader support For non-\u0026lt;button\u0026gt; elements, add: role=\u0026quot;button\u0026quot;, tabindex=\u0026quot;0\u0026quot;, aria-label=\u0026quot;...\u0026quot;. Handle on:keydown for Enter or Space. Sync loading/disabled state with aria-busy and aria-disabled. 5) Common variants Primary: main action, high-contrast or brand color. Secondary: dark or outline style for secondary actions. Ghost: transparent background with border. Icon button: add aria-label for screen readers. 6) Skeleton loading / disabled strategy Loading: show spinner, block double-submit; use disabled and aria-busy. Disabled: for permission/quota conditions, use weaker style like opacity-60 cursor-not-allowed. 7) Events and error handling Wrap click: set loading optimistically, run async work, reset in finally. On error: show toast, and color with statusTone('failed') if needed. Runnable snippet \u0026lt;script lang=\u0026#34;ts\u0026#34;\u0026gt; import { statusTone } from \u0026#39;./statusTone\u0026#39;; let status: \u0026#39;pending\u0026#39; | \u0026#39;processing\u0026#39; | \u0026#39;succeeded\u0026#39; | \u0026#39;failed\u0026#39; = \u0026#39;pending\u0026#39;; let loading = false; async function simulate() { loading = true; status = \u0026#39;processing\u0026#39;; await new Promise((r) =\u0026gt; setTimeout(r, 1200)); status = Math.random() \u0026gt; 0.5 ? \u0026#39;succeeded\u0026#39; : \u0026#39;failed\u0026#39;; loading = false; } \u0026lt;/script\u0026gt; \u0026lt;div class=\u0026#34;space-y-3\u0026#34;\u0026gt; \u0026lt;button class={`inline-flex items-center gap-2 rounded-full px-4 py-2 text-sm font-semibold transition ${statusTone(status)}`} aria-busy={loading} aria-disabled={loading} disabled={loading} on:click={simulate} \u0026gt; {#if loading} \u0026lt;span class=\u0026#34;h-3 w-3 animate-spin rounded-full border-2 border-white border-t-transparent\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; {/if} {status === \u0026#39;pending\u0026#39; ? \u0026#39;Start\u0026#39; : status === \u0026#39;processing\u0026#39; ? \u0026#39;Processing...\u0026#39; : status === \u0026#39;succeeded\u0026#39; ? \u0026#39;Done\u0026#39; : \u0026#39;Retry\u0026#39;} \u0026lt;/button\u0026gt; \u0026lt;p class=\u0026#34;text-sm text-slate-600\u0026#34;\u0026gt;Current status: {status}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; Run and verify:\nnpm run dev # Page shows the button; click it to see Processing... then success or failure color Common questions and notes Inconsistent status values: backend may return succeeded/completed; handle both. Long class strings: you can use clsx or classnames, but keep mapping logic centralized. Accessibility gaps: custom elements need role/tabindex/aria-label; loading needs aria-busy. Disabled styles: add opacity-60 cursor-not-allowed for clarity. Default text: use ?? instead of || to avoid empty string issues. Testing checklist Unit: statusTone returns expected classes for each state. Component: when loading, button.disabled === true and aria-busy=\u0026quot;true\u0026quot; exists. Accessibility: Tab focuses, Enter/Space triggers; aria-label present for icon buttons. Visual: contrast ratio \u0026gt;= 4.5:1 for text on backgrounds. Best practices Split mapping, structure, and a11y: function (state-\u0026gt;class) + template + accessibility helpers. Define the state machine before styling; avoid scattered magic strings. Default to accessibility: keyboard, screen reader, and synchronized disabled/busy states. Provide a runnable example for team reuse. Summary / Next steps The key is \u0026ldquo;state mapping + safe values + a11y sync\u0026rdquo;. statusTone centralizes styles, ?. and ?? make data safe, ARIA makes it production ready. Next: align with your design system (colors/sizes/icons), publish a Button component, and add Playwright a11y checks. References Svelte docs: events and accessibility MDN: Optional chaining, Nullish coalescing WAI-ARIA Authoring Practices: Button Call to Action (CTA) Copy the example into your component library and replace colors/states. Audit existing buttons for missing aria-* and disabled styles. ","permalink":"http://localhost:1313/en/dev/frontend/svelte-button-config-guide/","summary":"Build reusable buttons in Svelte: dynamic classes, optional chaining and nullish coalescing, safe defaults, state-driven styles, accessibility, testing, and common pitfalls.","title":"Svelte Button Configuration Guide: States, Styles, and Accessibility"},{"content":" Sorting series post 6 focuses on heap sort: in-place O(n log n), unstable, slightly higher constants but worst-case guaranteed. It is also the foundation of streaming top-k.\nTarget Readers Engineers who need in-place sorting with worst-case O(n log n) guarantees. Learners connecting priority queues, top-k, and heap sort. People comparing quick/merge/heap selection. Background and Motivation Heap sort builds a heap and repeatedly extracts the max; best/avg/worst are all O(n log n). Pros: in-place, worst-case safe. Cons: unstable, cache-unfriendly, higher constants than quicksort. Shares structure with priority queues and streaming top-k, giving strong engineering value. A - Algorithm Steps\nBuild a max-heap (bottom-up O(n)). Repeatedly swap root with tail, shrink heap, sift down to restore heap (O(log n) each). Basic example Array [4, 10, 3, 5, 1]:\nAfter heapify: [10, 5, 3, 4, 1]. Swap root and tail -\u0026gt; [1,5,3,4,10], sift down -\u0026gt; [5,4,3,1,10]. Repeat until sorted. C - Concepts Concept Description Heap property Parent \u0026gt;= children (max-heap), children of i are 2i+1 and 2i+2. Heapify Sift down from last non-leaf to root, O(n). Sift down Swap node downward to restore heap, O(log n). Stability Unstable; swaps can reorder equals. Space In-place O(1) extra space. Complexity\nTime: heapify O(n) + n times sift O(log n) =\u0026gt; O(n log n); worst-case same. Space: O(1); recursion uses O(log n) stack, iterative uses O(1). E - Engineering Scenario 1: In-place backend sorting (C) Background: need in-place and worst-case guarantees.\nvoid heapify(int *a, int n, int i){ while(1){ int l=2*i+1, r=2*i+2, largest=i; if(l\u0026lt;n \u0026amp;\u0026amp; a[l]\u0026gt;a[largest]) largest=l; if(r\u0026lt;n \u0026amp;\u0026amp; a[r]\u0026gt;a[largest]) largest=r; if(largest==i) break; int t=a[i]; a[i]=a[largest]; a[largest]=t; i=largest; } } void heap_sort(int *a, int n){ for(int i=n/2-1;i\u0026gt;=0;i--) heapify(a,n,i); for(int end=n-1; end\u0026gt;0; end--){ int t=a[0]; a[0]=a[end]; a[end]=t; heapify(a,end,0); } } Scenario 2: Streaming top-k (Python, min-heap) Background: maintain top k values in a stream.\nimport heapq def topk(stream, k): h=[] for x in stream: if len(h)\u0026lt;k: heapq.heappush(h, x) else: if x\u0026gt;h[0]: heapq.heapreplace(h, x) return sorted(h, reverse=True) print(topk([5,1,9,3,12,4], 3)) # [12,9,5] Scenario 3: Go priority queue + sorting Background: use container/heap to build a heap-based sort.\npackage main import ( \u0026#34;container/heap\u0026#34; \u0026#34;fmt\u0026#34; ) type IntHeap []int func (h IntHeap) Len() int { return len(h) } func (h IntHeap) Less(i, j int) bool { return h[i] \u0026lt; h[j] } func (h IntHeap) Swap(i, j int) { h[i], h[j] = h[j], h[i] } func (h *IntHeap) Push(x interface{}) { *h = append(*h, x.(int)) } func (h *IntHeap) Pop() interface{} { old := *h; n := len(old); x := old[n-1]; *h = old[:n-1]; return x } func heapSort(a []int) []int { h := IntHeap(a) heap.Init(\u0026amp;h) res := make([]int, 0, len(a)) for h.Len()\u0026gt;0 { res = append(res, heap.Pop(\u0026amp;h).(int)) } return res // ascending } func main(){ fmt.Println(heapSort([]int{4,10,3,5,1})) } Scenario 4: Rust in-place heap sort pub fn heap_sort(a: \u0026amp;mut [i32]) { let n = a.len(); // build max-heap for i in (0..n/2).rev() { sift_down(a, i, n); } for end in (1..n).rev() { a.swap(0, end); sift_down(a, 0, end); } } fn sift_down(a: \u0026amp;mut [i32], mut i: usize, n: usize) { loop { let l = 2*i+1; let r = l+1; let mut largest = i; if l \u0026lt; n \u0026amp;\u0026amp; a[l] \u0026gt; a[largest] { largest = l; } if r \u0026lt; n \u0026amp;\u0026amp; a[r] \u0026gt; a[largest] { largest = r; } if largest == i { break; } a.swap(i, largest); i = largest; } } Scenario 5: JavaScript concise version function heapify(a, n, i){ while(true){ let l=2*i+1, r=2*i+2, largest=i; if(l\u0026lt;n \u0026amp;\u0026amp; a[l]\u0026gt;a[largest]) largest=l; if(r\u0026lt;n \u0026amp;\u0026amp; a[r]\u0026gt;a[largest]) largest=r; if(largest===i) break; [a[i],a[largest]]=[a[largest],a[i]]; i=largest; } } function heapSort(a){ const n=a.length; for(let i=Math.floor(n/2)-1;i\u0026gt;=0;i--) heapify(a,n,i); for(let end=n-1;end\u0026gt;0;end--){ [a[0],a[end]]=[a[end],a[0]]; heapify(a,end,0); } return a; } console.log(heapSort([4,10,3,5,1])); R - Reflection Complexity: time O(n log n) in worst/avg/best; space O(1). Alternatives: Need stability -\u0026gt; merge/TimSort. Better constants/cache -\u0026gt; quicksort often faster. Known range -\u0026gt; counting/bucket/radix. Why it works: Worst-case guarantees, suitable when degradation is unacceptable. In-place, good for memory-constrained environments. Shares structure with priority queues and streaming top-k. S - Summary Heap sort: in-place, unstable, worst-case O(n log n), higher constants than quicksort. Engineering: heaps are common for top-k/streaming; full heap sort is less visible in libraries but available (C++ make_heap/sort_heap). If you need stability or near-sorted optimization, use merge/TimSort; for low constants, use quick/Introsort; heap sort shines when you need in-place and worst-case guarantees. Heapify bottom-up is O(n); iterative sift-down avoids recursion. Practice Guide / Steps Implement heapify (bottom-up) and sift-down (iterative); verify child index math. If only top-k is required, maintain a min-heap of size k, space O(k). Benchmark random, reversed, heavy duplicates; record swap counts and time to observe cache effects. For stability, add original index as a secondary key (higher constant). Common Pitfalls and Notes Child index math is easy to get wrong: 2i+1, 2i+2; continue sifting after swap. Recursive sift-down uses O(log n) stack; iterative avoids stack risk. Heap sort is unstable; equal elements may reorder. Runnable Example: Minimal Python def heap_sort(a): n=len(a) def sift(i, size): while True: l,r=2*i+1,2*i+2; largest=i if l\u0026lt;size and a[l]\u0026gt;a[largest]: largest=l if r\u0026lt;size and a[r]\u0026gt;a[largest]: largest=r if largest==i: break a[i],a[largest]=a[largest],a[i]; i=largest for i in range(n//2-1,-1,-1): sift(i,n) for end in range(n-1,0,-1): a[0],a[end]=a[end],a[0] sift(0,end) return a print(heap_sort([4,10,3,5,1])) References and Further Reading CLRS \u0026ldquo;Introduction to Algorithms\u0026rdquo; heap sort C++ std::make_heap / std::sort_heap implementation William Cochran, \u0026ldquo;Heaps and Priority Queues\u0026rdquo; notes Meta Reading time: approx. 14 min SEO keywords: heap sort, in-place sorting, top-k, priority queue Meta description: sorting series (6) explaining heap sort, heapify/sift, complexity, and engineering trade-offs with multilingual examples. Call to Action (CTA) Compare quicksort vs heap sort on the same dataset and observe cache effects. If you need top-k, implement a min-heap and benchmark it. Follow the series: non-comparison sorting, TimSort/Introsort, selection guide. ","permalink":"http://localhost:1313/en/alg/leetcode/6.sorting-series-heap-sort/","summary":"Explain heap sort principles, complexity, and engineering scenarios; compare with quick/merge; include multilingual implementations and top-k examples.","title":"Sorting Series (6): Heap Sort - In-place O(n log n) with Worst-Case Guarantees"},{"content":" Sorting series post 5 focuses on quicksort: average O(n log n), in-place, low constant factors, but it needs pivot strategy and tail recursion optimization to avoid worst-case O(n^2) and deep stacks. This is the ACERS view from theory to engineering practice.\nTarget Readers Developers who want a production-ready quicksort. Readers curious about pivot choice, duplicates handling, tail-recursion/hybrid strategies. People who want to understand std::sort / Introsort design motivation. Background and Motivation Quicksort is often the default because it is in-place, cache-friendly, and fast, but worst-case O(n^2) and duplicates can hurt. Engineering practice uses random pivot, median-of-three, three-way partition, tail recursion, and insertion for small segments. A - Algorithm Theme: Achieve average O(n log n) with in-place and low constants, while mitigating degeneration.\nBasic example Array [3, 5, 2, 2, 8], pivot = 3:\nAfter partition -\u0026gt; [2,2,3,5,8], left \u0026lt; 3, right \u0026gt;= 3. Recurse on left and right segments. C - Concepts Key Concept Description Pivot selection Random, median-of-three (first/mid/last), or median-of-five to reduce degeneration. Partition strategy Lomuto (single side) is simple but swaps more; Hoare (two-side) swaps less; three-way partition handles duplicates. Duplicates Three-way partition (\u0026lt;, =, \u0026gt;) prevents degeneration with many equal keys. Tail recursion Always recurse on smaller side and iterate on larger side to keep stack O(log n). Hybrid strategy Use insertion for small segments; fall back to heap sort when recursion depth is too high (Introsort). Complexity\nAverage time O(n log n), worst-case O(n^2) with extreme pivots. Space: average recursion stack O(log n), worst-case O(n); tail recursion reduces risk. Unstable, in-place. E - Engineering Scenario 1: General backend sorting (Go) Background: dataset ~1e5, random distribution. Why: Go sort.Slice uses quick/heap hybrid; example includes insertion for small segments.\npackage main import \u0026#34;fmt\u0026#34; func insertion(a []int, l, r int) { for i := l+1; i \u0026lt;= r; i++ { key := a[i]; j := i-1 for j \u0026gt;= l \u0026amp;\u0026amp; a[j] \u0026gt; key { a[j+1]=a[j]; j-- } a[j+1]=key } } func partition(a []int, l, r int) int { pivot := a[(l+r)\u0026gt;\u0026gt;1] i, j := l, r for i \u0026lt;= j { for a[i] \u0026lt; pivot { i++ } for a[j] \u0026gt; pivot { j-- } if i \u0026lt;= j { a[i], a[j] = a[j], a[i]; i++; j-- } } return i } func quick(a []int, l, r int) { for r-l+1 \u0026gt; 16 { p := partition(a, l, r) if p-l \u0026lt; r-p { quick(a, l, p-1); l = p } else { quick(a, p, r); r = p-1 } } insertion(a, l, r) } func main(){ arr := []int{3,5,2,2,8,1,7} quick(arr,0,len(arr)-1) fmt.Println(arr) } Scenario 2: Many duplicates (Python three-way) Background: many equal values (e.g., bucketed IDs), two-way partition degrades. Why: three-way partition handles equal keys in one pass.\ndef quick3(a, l=0, r=None): if r is None: r = len(a)-1 while l \u0026lt; r: if r - l + 1 \u0026lt;= 16: for i in range(l+1, r+1): key=a[i]; j=i-1 while j\u0026gt;=l and a[j]\u0026gt;key: a[j+1]=a[j]; j-=1 a[j+1]=key return pivot = a[(l+r)//2] lt, i, gt = l, l, r while i \u0026lt;= gt: if a[i] \u0026lt; pivot: a[lt], a[i] = a[i], a[lt]; lt+=1; i+=1 elif a[i] \u0026gt; pivot: a[i], a[gt] = a[gt], a[i]; gt-=1 else: i+=1 if lt-l \u0026lt; r-gt: quick3(a, l, lt-1); l = gt+1 else: quick3(a, gt+1, r); r = lt-1 return a arr=[3,5,2,2,8,1,7,2,2] quick3(arr) print(arr) Scenario 3: C++ performance-sensitive partition (Hoare + median-of-three) Background: performance-sensitive, need fewer swaps and more robust pivot.\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; int median3(vector\u0026lt;int\u0026gt;\u0026amp; a, int l, int r){ int m = l + (r-l)/2; if(a[m] \u0026lt; a[l]) swap(a[m], a[l]); if(a[r] \u0026lt; a[l]) swap(a[r], a[l]); if(a[m] \u0026lt; a[r]) swap(a[m], a[r]); // a[r] = median return a[r]; } int partition(vector\u0026lt;int\u0026gt;\u0026amp; a, int l, int r){ int pivot = median3(a,l,r); int i=l-1, j=r; while(true){ do{ i++; } while(a[i] \u0026lt; pivot); do{ j--; } while(a[j] \u0026gt; pivot); if(i\u0026gt;=j) break; swap(a[i], a[j]); } swap(a[i], a[r]); return i; } void quick(vector\u0026lt;int\u0026gt;\u0026amp; a, int l, int r){ while(l \u0026lt; r){ if(r-l+1 \u0026lt;= 16){ for(int i=l+1;i\u0026lt;=r;++i){int key=a[i], j=i-1; while(j\u0026gt;=l \u0026amp;\u0026amp; a[j]\u0026gt;key){a[j+1]=a[j]; j--;} a[j+1]=key;} return; } int p = partition(a,l,r); if(p-l \u0026lt; r-p){ quick(a,l,p-1); l=p+1; } else{ quick(a,p+1,r); r=p-1; } } } Scenario 4: JavaScript small arrays with median-of-three Background: mid-size arrays, use median-of-three + insertion threshold.\nfunction insertion(a,l,r){ for(let i=l+1;i\u0026lt;=r;i++){ const key=a[i]; let j=i-1; while(j\u0026gt;=l \u0026amp;\u0026amp; a[j]\u0026gt;key){ a[j+1]=a[j]; j--; } a[j+1]=key; } } function partition(a,l,r){ const m = l + ((r-l)\u0026gt;\u0026gt;1); if(a[m]\u0026lt;a[l]) [a[m],a[l]]=[a[l],a[m]]; if(a[r]\u0026lt;a[l]) [a[r],a[l]]=[a[l],a[r]]; if(a[r]\u0026lt;a[m]) [a[r],a[m]]=[a[m],a[r]]; const pivot = a[r]; let i=l-1; for(let j=l;j\u0026lt;r;j++) if(a[j]\u0026lt;=pivot){ i++; [a[i],a[j]]=[a[j],a[i]]; } [a[i+1],a[r]]=[a[r],a[i+1]]; return i+1; } function quick(a,l=0,r=a.length-1){ while(l\u0026lt;r){ if(r-l+1\u0026lt;=16){ insertion(a,l,r); return; } const p=partition(a,l,r); if(p-l \u0026lt; r-p){ quick(a,l,p-1); l=p+1; } else{ quick(a,p+1,r); r=p-1; } } return a; } console.log(quick([3,5,2,2,8,1,7])); R - Reflection Complexity: average O(n log n), worst O(n^2); stack depth O(log n) avg; tail recursion + insertion threshold keep it bounded. Alternatives: Need stability or guaranteed upper bound -\u0026gt; merge/heap/TimSort. Known range -\u0026gt; counting/bucket/radix. Standard libraries: C++ std::sort uses Introsort (quick + heap + insertion); Python/Java use TimSort (stable). Why this works: Random/median-of-three reduces degeneration. Three-way partition handles duplicates. Tail recursion + insertion threshold reduces stack depth and constants. S - Summary Quicksort strengths: in-place, low constants, cache-friendly, average O(n log n). Risks: extreme pivot -\u0026gt; O(n^2); duplicates -\u0026gt; degeneration; unstable. Robust strategy: random/median-of-three pivot, three-way partition, insertion for small segments, tail recursion; use Introsort ideas when needed. Selection: stability/external -\u0026gt; merge/TimSort; memory tight + random -\u0026gt; quick/Introsort; duplicates -\u0026gt; three-way. Practice Guide / Steps Pivot: random or median-of-three; median-of-five for extra robustness. Duplicates: use three-way partition; otherwise two-way is fine. Set small segment threshold (e.g., 16/24) and insert; set depth limit to fall back to heap (Introsort). Test sets: random, reverse, all equal, many duplicates, large arrays. Common Pitfalls and Notes Lomuto partition swaps more; Hoare partition returns an index that changes recursion boundaries. Deep recursion can overflow stack: use tail recursion or iterative loops. Not handling duplicates causes degeneration; three-way is critical. Fixed first-element pivot degenerates on sorted data. Runnable Examples: Minimal Multilang Python (random pivot + three-way) import random def quick3(a, l=0, r=None): if r is None: r = len(a)-1 while l \u0026lt; r: if r-l+1 \u0026lt;= 16: for i in range(l+1, r+1): key=a[i]; j=i-1 while j\u0026gt;=l and a[j]\u0026gt;key: a[j+1]=a[j]; j-=1 a[j+1]=key return a pivot_i = random.randint(l, r) a[l], a[pivot_i] = a[pivot_i], a[l] pivot = a[l] lt, i, gt = l, l+1, r while i \u0026lt;= gt: if a[i] \u0026lt; pivot: a[lt], a[i] = a[i], a[lt]; lt+=1; i+=1 elif a[i] \u0026gt; pivot: a[i], a[gt] = a[gt], a[i]; gt-=1 else: i+=1 if lt-l \u0026lt; r-gt: quick3(a, l, lt-1); l = gt+1 else: quick3(a, gt+1, r); r = lt-1 return a arr=[3,5,2,2,8,1,7,2,2] quick3(arr); print(arr) C (Hoare partition + insertion threshold) #include \u0026lt;stdlib.h\u0026gt; void insertion(int *a,int l,int r){ for(int i=l+1;i\u0026lt;=r;i++){ int key=a[i], j=i-1; while(j\u0026gt;=l \u0026amp;\u0026amp; a[j]\u0026gt;key){ a[j+1]=a[j]; j--; } a[j+1]=key; } } int partition(int *a,int l,int r){ int pivot=a[(l+r)/2]; int i=l-1, j=r+1; while(1){ do{ i++; } while(a[i]\u0026lt;pivot); do{ j--; } while(a[j]\u0026gt;pivot); if(i\u0026gt;=j) return j; int t=a[i]; a[i]=a[j]; a[j]=t; } } void quick(int *a,int l,int r){ while(l\u0026lt;r){ if(r-l+1\u0026lt;=16){ insertion(a,l,r); return; } int p=partition(a,l,r); if(p-l \u0026lt; r-p){ quick(a,l,p); l=p+1; } else{ quick(a,p+1,r); r=p; } } } C++ (median-of-three + Hoare) int partition(vector\u0026lt;int\u0026gt;\u0026amp; a,int l,int r){ int m=l+(r-l)/2; if(a[m]\u0026lt;a[l]) swap(a[m],a[l]); if(a[r]\u0026lt;a[l]) swap(a[r],a[l]); if(a[r]\u0026lt;a[m]) swap(a[r],a[m]); int pivot=a[m]; int i=l-1,j=r+1; while(true){ do{i++;}while(a[i]\u0026lt;pivot); do{j--;}while(a[j]\u0026gt;pivot); if(i\u0026gt;=j) return j; swap(a[i],a[j]); } } Go (two-way, simplified) func Quick(a []int, l, r int){ for l\u0026lt;r { if r-l+1 \u0026lt;= 16 { insertion(a,l,r); return } p := partition(a,l,r) if p-l \u0026lt; r-p { Quick(a,l,p-1); l=p } else { Quick(a,p,r); r=p-1 } } } Rust (three-way) pub fn quick3(a: \u0026amp;mut [i32]) { fn insertion(a: \u0026amp;mut [i32]) { for i in 1..a.len() { let key=a[i]; let mut j=i as i32-1; while j\u0026gt;=0 \u0026amp;\u0026amp; a[j as usize]\u0026gt;key { a[(j+1) as usize]=a[j as usize]; j-=1; } a[(j+1) as usize]=key; } } fn sort(a: \u0026amp;mut [i32]) { let n=a.len(); if n\u0026lt;=16 { insertion(a); return; } let pivot=a[n/2]; let (mut lt, mut i, mut gt) = (0,0,n-1); while i\u0026lt;=gt { if a[i]\u0026lt;pivot { a.swap(lt,i); lt+=1; i+=1; } else if a[i]\u0026gt;pivot { a.swap(i,gt); if gt==0 {break;} gt-=1; } else { i+=1; } } sort(\u0026amp;mut a[..lt]); sort(\u0026amp;mut a[gt+1..]); } if !a.is_empty() { sort(a); } } JavaScript (median-of-three + insertion) function insertion(a,l,r){ for(let i=l+1;i\u0026lt;=r;i++){ const key=a[i]; let j=i-1; while(j\u0026gt;=l \u0026amp;\u0026amp; a[j]\u0026gt;key){ a[j+1]=a[j]; j--; } a[j+1]=key; } } function quick(a,l=0,r=a.length-1){ while(l\u0026lt;r){ if(r-l+1\u0026lt;=16){ insertion(a,l,r); return a; } const m=l+((r-l)\u0026gt;\u0026gt;1); if(a[m]\u0026lt;a[l]) [a[m],a[l]]=[a[l],a[m]]; if(a[r]\u0026lt;a[l]) [a[r],a[l]]=[a[l],a[r]]; if(a[r]\u0026lt;a[m]) [a[r],a[m]]=[a[m],a[r]]; const pivot=a[m]; let i=l, j=r; while(i\u0026lt;=j){ while(a[i]\u0026lt;pivot) i++; while(a[j]\u0026gt;pivot) j--; if(i\u0026lt;=j){ [a[i],a[j]]=[a[j],a[i]]; i++; j--; } } if(j-l \u0026lt; r-i){ quick(a,l,j); l=i; } else { quick(a,i,r); r=j; } } return a; } console.log(quick([3,5,2,2,8,1,7])); Best Practices Default to language built-in sort; if custom, include random/median-of-three, three-way for duplicates, insertion threshold, tail recursion. Use merge/TimSort for stability; consider Introsort for strict upper bounds. Benchmark on random, reverse, all equal, many duplicates, and large arrays. Conclusion Quicksort is fast and in-place but must use pivot strategy and three-way partition to avoid degeneration. Tail recursion + insertion thresholds are standard engineering practice; fall back to heap if depth grows (Introsort). Selection rules: stability/external -\u0026gt; merge/TimSort; memory-tight random -\u0026gt; quick/Introsort; many duplicates -\u0026gt; three-way. References and Further Reading Hoare, \u0026ldquo;Quicksort\u0026rdquo; (1961) Bentley \u0026amp; McIlroy, \u0026ldquo;Engineering a Sort Function\u0026rdquo; (1993) C++ std::sort and std::stable_sort implementation notes Meta Reading time: approx. 16 min SEO keywords: quicksort, pivot selection, three-way partition, tail recursion, Introsort Meta description: sorting series (5) explaining pivot strategies, duplicate handling, tail recursion, and hybrid optimizations with multilingual implementations. Call to Action (CTA) Benchmark random vs fixed pivots on your real data; compare performance. Add \u0026ldquo;insertion threshold + tail recursion\u0026rdquo; to your implementation and measure stack depth and time. Follow the series: heap sort, non-comparison, TimSort/Introsort, selection guide. ","permalink":"http://localhost:1313/en/alg/leetcode/5.sorting-series-quick-sort/","summary":"Comprehensive quicksort guide: pivot selection, three-way partitioning, tail recursion optimization, hybrid sorting practices, with multilingual implementations and engineering guidance.","title":"Sorting Series (5): Quick Sort - Pivot Strategy, Tail Recursion, Engineering Practice"},{"content":"Find First and Last Position of Element in Sorted Array Summary Given a sorted array, return the first and last index of a target value, or [-1, -1] if not found. Use lower_bound and upper_bound.\nApproach l = lower_bound(target) r = upper_bound(target) - 1 If l is out of range or nums[l] != target, return [-1, -1]. Complexity Time: O(log n) Space: O(1) Python reference implementation from bisect import bisect_left, bisect_right def search_range(nums, target): l = bisect_left(nums, target) r = bisect_right(nums, target) - 1 if l \u0026gt;= len(nums) or nums[l] != target: return [-1, -1] return [l, r] ","permalink":"http://localhost:1313/en/alg/leetcode/binary-search-search-range-start-end/","summary":"\u003ch1 id=\"find-first-and-last-position-of-element-in-sorted-array\"\u003eFind First and Last Position of Element in Sorted Array\u003c/h1\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eGiven a sorted array, return the first and last index of a target value, or \u003ccode\u003e[-1, -1]\u003c/code\u003e if not found. Use lower_bound and upper_bound.\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003el = lower_bound(target)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003er = upper_bound(target) - 1\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eIf \u003ccode\u003el\u003c/code\u003e is out of range or \u003ccode\u003enums[l] != target\u003c/code\u003e, return \u003ccode\u003e[-1, -1]\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"complexity\"\u003eComplexity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTime: O(log n)\u003c/li\u003e\n\u003cli\u003eSpace: O(1)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"python-reference-implementation\"\u003ePython reference implementation\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e bisect \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e bisect_left, bisect_right\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003esearch_range\u003c/span\u003e(nums, target):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    l \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e bisect_left(nums, target)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    r \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e bisect_right(nums, target) \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e l \u003cspan style=\"color:#f92672\"\u003e\u0026gt;=\u003c/span\u003e len(nums) \u003cspan style=\"color:#f92672\"\u003eor\u003c/span\u003e nums[l] \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e target:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [l, r]\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Find First and Last Position of Element in Sorted Array"},{"content":"Find Target Indices After Sorting Summary Sort the array and return all indices where the target appears. Use binary search to find the range efficiently.\nApproach Sort the array. Use bisect_left and bisect_right to get [l, r). Return list(range(l, r)). Complexity Time: O(n log n) Space: O(n) if sorting a copy Python reference implementation from bisect import bisect_left, bisect_right def target_indices(nums, target): nums = sorted(nums) l = bisect_left(nums, target) r = bisect_right(nums, target) return list(range(l, r)) ","permalink":"http://localhost:1313/en/alg/leetcode/binary-search-find-target-index/","summary":"\u003ch1 id=\"find-target-indices-after-sorting\"\u003eFind Target Indices After Sorting\u003c/h1\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eSort the array and return all indices where the target appears. Use binary search to find the range efficiently.\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eSort the array.\u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003ebisect_left\u003c/code\u003e and \u003ccode\u003ebisect_right\u003c/code\u003e to get \u003ccode\u003e[l, r)\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eReturn \u003ccode\u003elist(range(l, r))\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"complexity\"\u003eComplexity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTime: O(n log n)\u003c/li\u003e\n\u003cli\u003eSpace: O(n) if sorting a copy\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"python-reference-implementation\"\u003ePython reference implementation\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e bisect \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e bisect_left, bisect_right\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003etarget_indices\u003c/span\u003e(nums, target):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    nums \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e sorted(nums)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    l \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e bisect_left(nums, target)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    r \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e bisect_right(nums, target)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e list(range(l, r))\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Find Target Indices After Sorting"},{"content":"Sliding Window in Engineering: Max Vowels to Monitoring Summary Sliding window is a simple but powerful pattern. The LeetCode problem \u0026ldquo;Maximum Number of Vowels in a Substring of Given Length\u0026rdquo; is a clean entry point and maps to real monitoring windows.\nApproach (max vowels) Keep a window of length k, maintain a running count of vowels, and update the maximum.\nComplexity Time: O(n) Space: O(1) Python reference implementation def max_vowels(s, k): vowels = set(\u0026#34;aeiou\u0026#34;) cur = sum(1 for c in s[:k] if c in vowels) ans = cur for i in range(k, len(s)): if s[i-k] in vowels: cur -= 1 if s[i] in vowels: cur += 1 ans = max(ans, cur) return ans ","permalink":"http://localhost:1313/en/alg/leetcode/sliding-window-max-vowel-substring-to-monitoring/","summary":"\u003ch1 id=\"sliding-window-in-engineering-max-vowels-to-monitoring\"\u003eSliding Window in Engineering: Max Vowels to Monitoring\u003c/h1\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eSliding window is a simple but powerful pattern. The LeetCode problem \u0026ldquo;Maximum Number of Vowels in a Substring of Given Length\u0026rdquo; is a clean entry point and maps to real monitoring windows.\u003c/p\u003e\n\u003ch2 id=\"approach-max-vowels\"\u003eApproach (max vowels)\u003c/h2\u003e\n\u003cp\u003eKeep a window of length \u003ccode\u003ek\u003c/code\u003e, maintain a running count of vowels, and update the maximum.\u003c/p\u003e\n\u003ch2 id=\"complexity\"\u003eComplexity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTime: O(n)\u003c/li\u003e\n\u003cli\u003eSpace: O(1)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"python-reference-implementation\"\u003ePython reference implementation\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emax_vowels\u003c/span\u003e(s, k):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    vowels \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e set(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;aeiou\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    cur \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e sum(\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e s[:k] \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e c \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e vowels)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    ans \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e cur\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e range(k, len(s)):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e s[i\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003ek] \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e vowels:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            cur \u003cspan style=\"color:#f92672\"\u003e-=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e s[i] \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e vowels:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            cur \u003cspan style=\"color:#f92672\"\u003e+=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        ans \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e max(ans, cur)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e ans\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"High-Value Sliding Window Applications: From Max Vowels to Real Monitoring"},{"content":"Maximum Count of Positive and Negative Numbers Summary Given a sorted array, return the maximum of the number of positive and negative values. Binary search gives the split points in O(log n).\nApproach Use bisect_left(nums, 0) to get count of negatives. Use bisect_right(nums, 0) to get first positive index. Positive count = n - right_zero. Complexity Time: O(log n) Space: O(1) Python reference implementation from bisect import bisect_left, bisect_right def maximum_count(nums): n = len(nums) neg = bisect_left(nums, 0) pos = n - bisect_right(nums, 0) return max(neg, pos) ","permalink":"http://localhost:1313/en/alg/leetcode/binary-search-maximum-count-positive-negative/","summary":"\u003ch1 id=\"maximum-count-of-positive-and-negative-numbers\"\u003eMaximum Count of Positive and Negative Numbers\u003c/h1\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eGiven a sorted array, return the maximum of the number of positive and negative values. Binary search gives the split points in O(log n).\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eUse \u003ccode\u003ebisect_left(nums, 0)\u003c/code\u003e to get count of negatives.\u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003ebisect_right(nums, 0)\u003c/code\u003e to get first positive index.\u003c/li\u003e\n\u003cli\u003ePositive count = \u003ccode\u003en - right_zero\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"complexity\"\u003eComplexity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTime: O(log n)\u003c/li\u003e\n\u003cli\u003eSpace: O(1)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"python-reference-implementation\"\u003ePython reference implementation\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e bisect \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e bisect_left, bisect_right\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emaximum_count\u003c/span\u003e(nums):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    n \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e len(nums)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    neg \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e bisect_left(nums, \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    pos \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e n \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e bisect_right(nums, \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e max(neg, pos)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Maximum Count of Positive and Negative Numbers"},{"content":"Maximum Sum of Almost Unique Subarray Summary Given an array, window size k, and threshold m, find the maximum sum of any length-k subarray that contains at least m distinct elements.\nApproach Use a sliding window with a frequency map, track window sum and number of distinct values.\nComplexity Time: O(n) Space: O(n) for frequency map Python reference implementation def max_sum_almost_unique(nums, m, k): from collections import defaultdict count = defaultdict(int) distinct = 0 window_sum = 0 ans = 0 for i, x in enumerate(nums): window_sum += x if count[x] == 0: distinct += 1 count[x] += 1 if i \u0026gt;= k: y = nums[i - k] window_sum -= y count[y] -= 1 if count[y] == 0: distinct -= 1 if i \u0026gt;= k - 1 and distinct \u0026gt;= m: ans = max(ans, window_sum) return ans ","permalink":"http://localhost:1313/en/alg/leetcode/almost-unique-subarray-max-sum/","summary":"\u003ch1 id=\"maximum-sum-of-almost-unique-subarray\"\u003eMaximum Sum of Almost Unique Subarray\u003c/h1\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eGiven an array, window size \u003ccode\u003ek\u003c/code\u003e, and threshold \u003ccode\u003em\u003c/code\u003e, find the maximum sum of any length-\u003ccode\u003ek\u003c/code\u003e subarray that contains at least \u003ccode\u003em\u003c/code\u003e distinct elements.\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cp\u003eUse a sliding window with a frequency map, track window sum and number of distinct values.\u003c/p\u003e\n\u003ch2 id=\"complexity\"\u003eComplexity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTime: O(n)\u003c/li\u003e\n\u003cli\u003eSpace: O(n) for frequency map\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"python-reference-implementation\"\u003ePython reference implementation\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emax_sum_almost_unique\u003c/span\u003e(nums, m, k):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e collections \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e defaultdict\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    count \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e defaultdict(int)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    distinct \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    window_sum \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    ans \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i, x \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e enumerate(nums):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        window_sum \u003cspan style=\"color:#f92672\"\u003e+=\u003c/span\u003e x\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e count[x] \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            distinct \u003cspan style=\"color:#f92672\"\u003e+=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        count[x] \u003cspan style=\"color:#f92672\"\u003e+=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003e\u0026gt;=\u003c/span\u003e k:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            y \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e nums[i \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e k]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            window_sum \u003cspan style=\"color:#f92672\"\u003e-=\u003c/span\u003e y\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            count[y] \u003cspan style=\"color:#f92672\"\u003e-=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e count[y] \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                distinct \u003cspan style=\"color:#f92672\"\u003e-=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003e\u0026gt;=\u003c/span\u003e k \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003eand\u003c/span\u003e distinct \u003cspan style=\"color:#f92672\"\u003e\u0026gt;=\u003c/span\u003e m:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            ans \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e max(ans, window_sum)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e ans\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Maximum Sum of Almost Unique Subarray"},{"content":"Minimum Recolors to Get K Consecutive Black Blocks Summary Given a string of \u0026lsquo;B\u0026rsquo; and \u0026lsquo;W\u0026rsquo;, find the minimum recolors to make a substring of length k all black.\nApproach Use a sliding window of length k and count the number of whites in the window. The minimum whites across all windows is the answer.\nComplexity Time: O(n) Space: O(1) Python reference implementation def minimum_recolors(blocks, k): whites = sum(1 for c in blocks[:k] if c == \u0026#39;W\u0026#39;) ans = whites for i in range(k, len(blocks)): if blocks[i-k] == \u0026#39;W\u0026#39;: whites -= 1 if blocks[i] == \u0026#39;W\u0026#39;: whites += 1 ans = min(ans, whites) return ans ","permalink":"http://localhost:1313/en/alg/leetcode/minimum-recolors-k-consecutive-black-blocks/","summary":"\u003ch1 id=\"minimum-recolors-to-get-k-consecutive-black-blocks\"\u003eMinimum Recolors to Get K Consecutive Black Blocks\u003c/h1\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eGiven a string of \u0026lsquo;B\u0026rsquo; and \u0026lsquo;W\u0026rsquo;, find the minimum recolors to make a substring of length \u003ccode\u003ek\u003c/code\u003e all black.\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cp\u003eUse a sliding window of length \u003ccode\u003ek\u003c/code\u003e and count the number of whites in the window. The minimum whites across all windows is the answer.\u003c/p\u003e\n\u003ch2 id=\"complexity\"\u003eComplexity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTime: O(n)\u003c/li\u003e\n\u003cli\u003eSpace: O(1)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"python-reference-implementation\"\u003ePython reference implementation\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eminimum_recolors\u003c/span\u003e(blocks, k):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    whites \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e sum(\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e blocks[:k] \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e c \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;W\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    ans \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e whites\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e range(k, len(blocks)):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e blocks[i\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003ek] \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;W\u0026#39;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            whites \u003cspan style=\"color:#f92672\"\u003e-=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e blocks[i] \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;W\u0026#39;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            whites \u003cspan style=\"color:#f92672\"\u003e+=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        ans \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e min(ans, whites)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e ans\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Minimum Recolors to Get K Consecutive Black Blocks"},{"content":"Search Insert Position Summary Find the index where a target should be inserted into a sorted array. If it exists, return its index; otherwise return the insertion position. This is a classic lower_bound binary search.\nApproach Use binary search to find the first index i such that nums[i] \u0026gt;= target.\nComplexity Time: O(log n) Space: O(1) Python reference implementation from bisect import bisect_left def search_insert(nums, target): return bisect_left(nums, target) ","permalink":"http://localhost:1313/en/alg/leetcode/binary-search-search-insert-position/","summary":"\u003ch1 id=\"search-insert-position\"\u003eSearch Insert Position\u003c/h1\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eFind the index where a target should be inserted into a sorted array. If it exists, return its index; otherwise return the insertion position. This is a classic lower_bound binary search.\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cp\u003eUse binary search to find the first index \u003ccode\u003ei\u003c/code\u003e such that \u003ccode\u003enums[i] \u0026gt;= target\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"complexity\"\u003eComplexity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTime: O(log n)\u003c/li\u003e\n\u003cli\u003eSpace: O(1)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"python-reference-implementation\"\u003ePython reference implementation\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e bisect \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e bisect_left\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003esearch_insert\u003c/span\u003e(nums, target):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e bisect_left(nums, target)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Search Insert Position: Binary Search for the Insert Index"},{"content":"Smallest Letter Greater Than Target Summary Given a sorted list of letters with wrap-around, return the smallest letter strictly greater than the target.\nApproach Use bisect_right to find the first letter greater than target. If index reaches the end, wrap to index 0.\nComplexity Time: O(log n) Space: O(1) Python reference implementation from bisect import bisect_right def next_greatest_letter(letters, target): i = bisect_right(letters, target) return letters[i] if i \u0026lt; len(letters) else letters[0] ","permalink":"http://localhost:1313/en/alg/leetcode/binary-search-smallest-letter-greater-than-target/","summary":"\u003ch1 id=\"smallest-letter-greater-than-target\"\u003eSmallest Letter Greater Than Target\u003c/h1\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eGiven a sorted list of letters with wrap-around, return the smallest letter strictly greater than the target.\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cp\u003eUse \u003ccode\u003ebisect_right\u003c/code\u003e to find the first letter greater than target. If index reaches the end, wrap to index 0.\u003c/p\u003e\n\u003ch2 id=\"complexity\"\u003eComplexity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTime: O(log n)\u003c/li\u003e\n\u003cli\u003eSpace: O(1)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"python-reference-implementation\"\u003ePython reference implementation\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e bisect \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e bisect_right\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003enext_greatest_letter\u003c/span\u003e(letters, target):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    i \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e bisect_right(letters, target)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e letters[i] \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e len(letters) \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e letters[\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Smallest Letter Greater Than Target"},{"content":"Spells and Potions Summary For each spell, count how many potions make spell * potion \u0026gt;= success. Sort potions and binary search the threshold.\nApproach Sort potions. For each spell, compute need = ceil(success / spell). Use binary search to find the first potion \u0026gt;= need. Complexity Time: O(n log n) Space: O(1) extra (or O(n) if sorting a copy) Python reference implementation import bisect import math def successful_pairs(spells, potions, success): potions = sorted(potions) n = len(potions) res = [] for s in spells: need = (success + s - 1) // s idx = bisect.bisect_left(potions, need) res.append(n - idx) return res ","permalink":"http://localhost:1313/en/alg/leetcode/spells-and-potions-successful-pairs/","summary":"\u003ch1 id=\"spells-and-potions\"\u003eSpells and Potions\u003c/h1\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eFor each spell, count how many potions make \u003ccode\u003espell * potion \u0026gt;= success\u003c/code\u003e. Sort potions and binary search the threshold.\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eSort potions.\u003c/li\u003e\n\u003cli\u003eFor each spell, compute \u003ccode\u003eneed = ceil(success / spell)\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eUse binary search to find the first potion \u0026gt;= need.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"complexity\"\u003eComplexity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTime: O(n log n)\u003c/li\u003e\n\u003cli\u003eSpace: O(1) extra (or O(n) if sorting a copy)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"python-reference-implementation\"\u003ePython reference implementation\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e bisect\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e math\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003esuccessful_pairs\u003c/span\u003e(spells, potions, success):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    potions \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e sorted(potions)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    n \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e len(potions)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    res \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e []\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e s \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e spells:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        need \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e (success \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e s \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e) \u003cspan style=\"color:#f92672\"\u003e//\u003c/span\u003e s\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        idx \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e bisect\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ebisect_left(potions, need)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        res\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eappend(n \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e idx)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e res\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Spells and Potions: Count Successful Pairs"},{"content":"Two Sum Summary Find two indices such that nums[i] + nums[j] = target. Use a hash map for O(n) time.\nApproach Iterate and store value -\u0026gt; index. For each number x, check if target - x exists.\nComplexity Time: O(n) Space: O(n) Python reference implementation def two_sum(nums, target): seen = {} for i, x in enumerate(nums): y = target - x if y in seen: return [seen[y], i] seen[x] = i ","permalink":"http://localhost:1313/en/alg/leetcode/two-sum-hash-map-acers/","summary":"\u003ch1 id=\"two-sum\"\u003eTwo Sum\u003c/h1\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eFind two indices such that \u003ccode\u003enums[i] + nums[j] = target\u003c/code\u003e. Use a hash map for O(n) time.\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cp\u003eIterate and store \u003ccode\u003evalue -\u0026gt; index\u003c/code\u003e. For each number \u003ccode\u003ex\u003c/code\u003e, check if \u003ccode\u003etarget - x\u003c/code\u003e exists.\u003c/p\u003e\n\u003ch2 id=\"complexity\"\u003eComplexity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTime: O(n)\u003c/li\u003e\n\u003cli\u003eSpace: O(n)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"python-reference-implementation\"\u003ePython reference implementation\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003etwo_sum\u003c/span\u003e(nums, target):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    seen \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e {}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i, x \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e enumerate(nums):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        y \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e target \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e x\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e y \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e seen:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [seen[y], i]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        seen[x] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e i\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Two Sum with Hash Map (ACERS Summary)"},{"content":" Sorting series post 4 focuses on merge sort: classic divide and conquer, stable, O(n log n) time, with the cost of O(n) extra space. It is the foundation for external sorting and many stable library sorts.\nTarget Readers Engineers who need stability and can afford O(n) extra space. Learners building divide-and-conquer foundations for quicksort/TimSort. People working with huge files or streams and want external merge knowledge. Background and Motivation Merge sort is O(n log n) on all inputs, unaffected by pivot degeneration. The trade-off is O(n) extra space; in-place variants are complex and costly. External sorting (data larger than RAM) uses \u0026ldquo;chunk sort + k-way merge\u0026rdquo; based on merge ideas. A - Algorithm Problem: Sort a comparable sequence, stable, in O(n log n).\nSteps (top-down)\nSplit: recursively divide the array into halves. Conquer: sort left and right halves. Merge: merge two sorted halves using a buffer. Basic example Array [5,2,4,6,1,3]:\nSplit into [5,2,4] and [6,1,3], then split further. Merge [2,4,5] and [1,3,6] -\u0026gt; [1,2,3,4,5,6] (stable preserves order). C - Concepts Key Concept Description Divide and conquer Split into subproblems, solve and merge. Stability When equal, take from left first to preserve relative order. Space Typical implementation uses O(n) buffer; bottom-up still needs buffer. Variants Bottom-up merge, block merge, external k-way merge. Complexity\nTime: T(n) = 2T(n/2) + O(n) =\u0026gt; O(n log n) (best/avg/worst). Space: O(n) buffer (external sort depends on block size). E - Engineering Scenario 1: Stable multi-key sorting (Python) Background: sort logs by date then user_id, need stability. Why: Python built-in sort is stable (TimSort), use directly.\nfrom operator import itemgetter logs = [(\u0026#34;2025-11-21\u0026#34;, \u0026#34;u2\u0026#34;), (\u0026#34;2025-11-21\u0026#34;, \u0026#34;u1\u0026#34;), (\u0026#34;2025-11-20\u0026#34;, \u0026#34;u3\u0026#34;)] logs.sort(key=itemgetter(0,1)) print(logs) Scenario 2: External sorting for large files (C++) Background: sort a 10GB integer file with 512MB RAM. Why: chunk sort + k-way merge, stable and memory controlled.\n// Skeleton pseudocode to show the idea auto sort_chunk = [](vector\u0026lt;int\u0026gt;\u0026amp; buf, int id){ sort(buf.begin(), buf.end()); ofstream out(\u0026#34;chunk\u0026#34;+to_string(id)+\u0026#34;.tmp\u0026#34;); for(int v:buf) out\u0026lt;\u0026lt;v\u0026lt;\u0026lt;\u0026#39;\\n\u0026#39;; }; // read -\u0026gt; sort chunks -\u0026gt; k-way merge (priority queue min-heap) Scenario 3: Frontend stable sorting (JavaScript) Background: table must keep original order for equal keys. Why: modern browser sort is mostly stable; if unsure, use a stable merge.\nfunction mergeSort(arr){ if(arr.length\u0026lt;=1) return arr; const mid = arr.length\u0026gt;\u0026gt;1; const left = mergeSort(arr.slice(0,mid)); const right = mergeSort(arr.slice(mid)); const res=[]; let i=0,j=0; while(i\u0026lt;left.length \u0026amp;\u0026amp; j\u0026lt;right.length){ if(left[i].key \u0026lt;= right[j].key) res.push(left[i++]); else res.push(right[j++]); } return res.concat(left.slice(i)).concat(right.slice(j)); } console.log(mergeSort([{key:1},{key:1},{key:0}])); Scenario 4: Stable backend sorting (Go) Background: stable sort by multiple fields. Why: sort.SliceStable is merge-based and stable.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sort\u0026#34; ) type Item struct{ Date string; User string } func main(){ items := []Item{{\u0026#34;2025-11-21\u0026#34;,\u0026#34;u2\u0026#34;},{\u0026#34;2025-11-21\u0026#34;,\u0026#34;u1\u0026#34;},{\u0026#34;2025-11-20\u0026#34;,\u0026#34;u3\u0026#34;}} sort.SliceStable(items, func(i, j int) bool { if items[i].Date == items[j].Date { return items[i].User \u0026lt; items[j].User } return items[i].Date \u0026lt; items[j].Date }) fmt.Println(items) } R - Reflection Complexity analysis: time O(n log n), space O(n); external sort cost dominated by I/O and block size. Alternatives: vs quicksort: quick is in-place and small-constant but unstable and can degrade; merge is stable and bounded. vs heap sort: heap is in-place and unstable with poor cache behavior; merge is better for stability/external. vs TimSort: TimSort is faster on nearly sorted data and stable but more complex; merge is its base. Why it is preferred: stable, predictable O(n log n), and the default for external sorting. S - Summary Merge sort provides stable and predictable O(n log n) with O(n) extra space. External sorting, stable multi-key sorting, and many stable libraries rely on merge ideas. Bottom-up merge avoids recursion depth but still needs buffers. If input is nearly sorted and you want more speed, consider TimSort; if memory is tight and stability is not needed, use quick/heap. Evaluate stability needs, memory budget, data size, and I/O cost. Practice Guide / Steps Decide stability and memory budget: if O(n) buffer is ok, use merge/stable libraries; otherwise quick/heap. Choose implementation: top-down is simplest; bottom-up avoids deep recursion. Ensure stability in merge: when equal, pick from left. Edge tests: empty, single, all equal, reverse, heavy duplicates. Runnable Examples: Multilingual Implementations Python (top-down) def merge_sort(a): if len(a) \u0026lt;= 1: return a mid = len(a)//2 left = merge_sort(a[:mid]) right = merge_sort(a[mid:]) i=j=0; res=[] while i \u0026lt; len(left) and j \u0026lt; len(right): if left[i] \u0026lt;= right[j]: res.append(left[i]); i+=1 else: res.append(right[j]); j+=1 res.extend(left[i:]); res.extend(right[j:]) return res print(merge_sort([5,2,4,6,1,3])) C (bottom-up) #include \u0026lt;stdlib.h\u0026gt; void merge(int *a, int *buf, int l, int m, int r){ int i=l, j=m, k=l; while(i\u0026lt;m \u0026amp;\u0026amp; j\u0026lt;r){ if(a[i] \u0026lt;= a[j]) buf[k++] = a[i++]; else buf[k++] = a[j++]; } while(i\u0026lt;m) buf[k++] = a[i++]; while(j\u0026lt;r) buf[k++] = a[j++]; for(int t=l; t\u0026lt;r; ++t) a[t]=buf[t]; } void merge_sort(int *a, int n){ int *buf = malloc(sizeof(int)*n); for(int width=1; width\u0026lt;n; width*=2){ for(int i=0; i\u0026lt;n; i+=2*width){ int l=i, m=i+width\u0026lt; n? i+width: n, r=i+2*width\u0026lt; n? i+2*width: n; merge(a, buf, l, m, r); } } free(buf); } C++ (top-down) void merge(vector\u0026lt;int\u0026gt;\u0026amp; a, int l, int m, int r, vector\u0026lt;int\u0026gt;\u0026amp; buf){ int i=l,j=m,k=l; while(i\u0026lt;m \u0026amp;\u0026amp; j\u0026lt;r){ if(a[i]\u0026lt;=a[j]) buf[k++]=a[i++]; else buf[k++]=a[j++]; } while(i\u0026lt;m) buf[k++]=a[i++]; while(j\u0026lt;r) buf[k++]=a[j++]; for(int t=l;t\u0026lt;r;++t) a[t]=buf[t]; } void merge_sort(vector\u0026lt;int\u0026gt;\u0026amp; a, int l, int r, vector\u0026lt;int\u0026gt;\u0026amp; buf){ if(r-l\u0026lt;=1) return; int m = l + (r-l)/2; merge_sort(a,l,m,buf); merge_sort(a,m,r,buf); merge(a,l,m,r,buf); } Go (top-down) func mergeSort(a []int) []int { if len(a) \u0026lt;= 1 { return a } mid := len(a)/2 left := mergeSort(a[:mid]) right := mergeSort(a[mid:]) res := make([]int, 0, len(a)) i, j := 0, 0 for i \u0026lt; len(left) \u0026amp;\u0026amp; j \u0026lt; len(right) { if left[i] \u0026lt;= right[j] { res = append(res, left[i]); i++ } else { res = append(res, right[j]); j++ } } res = append(res, left[i:]...) res = append(res, right[j:]...) return res } Rust (top-down with buffer) fn merge_sort(a: \u0026amp;mut [i32]) { let n = a.len(); if n \u0026lt;= 1 { return; } let mid = n/2; merge_sort(\u0026amp;mut a[..mid]); merge_sort(\u0026amp;mut a[mid..]); let mut buf = a.to_vec(); merge(\u0026amp;a[..mid], \u0026amp;a[mid..], \u0026amp;mut buf[..]); a.copy_from_slice(\u0026amp;buf); } fn merge(left: \u0026amp;[i32], right: \u0026amp;[i32], out: \u0026amp;mut [i32]) { let (mut i, mut j, mut k) = (0,0,0); while i \u0026lt; left.len() \u0026amp;\u0026amp; j \u0026lt; right.len() { if left[i] \u0026lt;= right[j] { out[k]=left[i]; i+=1; } else { out[k]=right[j]; j+=1; } k+=1; } if i \u0026lt; left.len() { out[k..k+left.len()-i].copy_from_slice(\u0026amp;left[i..]); } if j \u0026lt; right.len() { out[k..k+right.len()-j].copy_from_slice(\u0026amp;right[j..]); } } JavaScript (top-down) function mergeSort(a){ if(a.length\u0026lt;=1) return a; const mid = a.length\u0026gt;\u0026gt;1; const left = mergeSort(a.slice(0,mid)); const right = mergeSort(a.slice(mid)); const res=[]; let i=0,j=0; while(i\u0026lt;left.length \u0026amp;\u0026amp; j\u0026lt;right.length){ if(left[i] \u0026lt;= right[j]) res.push(left[i++]); else res.push(right[j++]); } return res.concat(left.slice(i)).concat(right.slice(j)); } console.log(mergeSort([5,2,4,6,1,3])); Common Pitfalls and Notes Recursion depth: for large n use bottom-up iteration or stack tuning. Space usage: evaluate O(n) buffer; external sort requires careful block sizing and merge fan-in. Stability: when equal, take left to preserve order. Performance: use double-buffering or alternating buffers to reduce copies. Best Practices Use stable library sort when available (Python/Java object sort, Go SliceStable). Factor out a merge helper to enforce stability; use bottom-up for large arrays. External sort: control chunk size, use priority queue for k-way merge, batch I/O. For nearly sorted data, consider TimSort; merge is its foundation. Conclusion Merge sort is stable and predictably O(n log n), ideal for stable multi-key sorting and external sorting. Extra space is the main trade-off; in-place variants are complex and uncommon. Bottom-up merge avoids recursion; external merge is essential for huge data. References and Further Reading CLRS \u0026ldquo;Introduction to Algorithms\u0026rdquo; merge sort TimSort paper and CPython/Java sources (run merging) PostgreSQL tuplesort external sorting implementation Meta Reading time: approx. 15 min SEO keywords: merge sort, stable sort, external sorting, divide and conquer Meta description: sorting series (4) explaining merge sort stability, space trade-offs, external sorting, and multilingual implementations. Call to Action (CTA) Benchmark built-in stable sort vs your merge implementation on your dataset. If sorting large files, prototype chunk + k-way merge and measure I/O cost. Follow the series: quicksort, heap sort, non-comparison, TimSort/Introsort, selection guide. ","permalink":"http://localhost:1313/en/alg/leetcode/4.sorting-series-merge-sort/","summary":"Systematic explanation of merge sort principles, stability, space trade-offs, and engineering scenarios with Python/C/C++/Go/Rust/JS implementations and external sorting guidance.","title":"Sorting Series (4): Merge Sort - Stable Divide and Conquer and External Sorting"},{"content":" Sorting series post 3 focuses on Shell sort: grouped insertion with decreasing gaps reduces worst-case O(n^2) toward around O(n log^2 n), making it a key step in understanding \u0026ldquo;local order to global order.\u0026rdquo;\nTarget Readers Learners who know insertion sort and want its higher-level optimization. Engineers needing in-place sorting for mid-size data. People explaining the impact of gap sequences in talks or courses. Background and Motivation Insertion sort is fast when nearly sorted but remains O(n^2) on random arrays. Shell sort uses grouping + shrinking gaps so elements move toward their approximate positions early. Gap sequence choice directly affects performance and complexity. A - Algorithm Problem: Sort a length-n comparable sequence in-place.\nCore steps (gap starts at n/2)\nChoose initial gap; split array into gap-based subsequences. Run insertion sort on each subsequence (step size = gap). Decrease gap and repeat until gap = 1 (equivalent to insertion). Basic example Array [9, 8, 3, 7, 5, 6, 4, 1], gap sequence 4 -\u0026gt; 2 -\u0026gt; 1:\ngap=4: subsequences (0,4),(1,5),(2,6),(3,7), insert sort each to roughly position elements. gap=2: finer groups and more insertion. gap=1: final insertion pass for full order. C - Concepts Key Concept Description Gap sequence Common choices: n/2, Knuth (1,4,13,40,\u0026hellip;), Sedgewick, etc. Determines comparison bounds. Grouped insertion Insertion sort on gap-separated subsequences, moves distant elements early. In-place Uses constant extra space. Stability Classic Shell sort is not stable (cross-gap swaps can reorder equals). Complexity range\nWorst-case depends on gap sequence; simple n/2 can still be O(n^2). Good sequences (e.g., Sedgewick) achieve O(n^(4/3)) or O(n log^2 n), often ~O(n^{1.2-1.3}) in practice. Space: O(1). E - Engineering Scenario 1: Mid-size, memory-sensitive sort (C) Background: embedded/backend arrays (1e4~1e5), need in-place with low memory. Why: Shell sort is in-place with low constants; often better than pure insertion; more stable performance than quick/heap on some distributions.\nvoid shell_sort(int *a, int n) { // Knuth sequence: 1,4,13,40,... until \u0026lt; n/3 int gap = 1; while (gap \u0026lt; n/3) gap = gap * 3 + 1; for (; gap \u0026gt;= 1; gap /= 3) { for (int i = gap; i \u0026lt; n; ++i) { int temp = a[i], j = i; while (j \u0026gt;= gap \u0026amp;\u0026amp; a[j-gap] \u0026gt; temp) { a[j] = a[j-gap]; j -= gap; } a[j] = temp; } } } Scenario 2: Nearly sorted business lists (Python) Background: list appends a few elements; total size \u0026lt;= 1e5. Why: gentle gap sequence moves distant elements into place, then gap=1 finishes with insertion.\ndef shell_sort(arr): n = len(arr) gap = 1 while gap \u0026lt; n // 3: gap = 3 * gap + 1 # Knuth while gap \u0026gt;= 1: for i in range(gap, n): temp = arr[i] j = i while j \u0026gt;= gap and arr[j - gap] \u0026gt; temp: arr[j] = arr[j - gap] j -= gap arr[j] = temp gap //= 3 return arr data = [9,8,3,7,5,6,4,1] print(shell_sort(data)) Scenario 3: Go backend batch sorting Background: per-request sorting length 1e3~1e4; in-place to reduce GC. Why: custom Shell sort as an alternative to reduce allocations.\npackage main import \u0026#34;fmt\u0026#34; func shellSort(a []int) { gap := 1 for gap \u0026lt; len(a)/3 { gap = gap*3 + 1 } for gap \u0026gt;= 1 { for i := gap; i \u0026lt; len(a); i++ { tmp, j := a[i], i for j \u0026gt;= gap \u0026amp;\u0026amp; a[j-gap] \u0026gt; tmp { a[j] = a[j-gap] j -= gap } a[j] = tmp } gap /= 3 } } func main(){ arr := []int{9,8,3,7,5,6,4,1}; shellSort(arr); fmt.Println(arr) } Scenario 4: Frontend large array but low memory (JavaScript) Background: browser handling thousands of records, avoid allocations. Why: in-place and short implementation; Knuth sequence works well.\nfunction shellSort(a){ let gap = 1; while (gap \u0026lt; a.length/3) gap = gap*3 + 1; while (gap \u0026gt;= 1){ for (let i = gap; i \u0026lt; a.length; i++){ const tmp = a[i]; let j = i; while (j \u0026gt;= gap \u0026amp;\u0026amp; a[j-gap] \u0026gt; tmp){ a[j] = a[j-gap]; j -= gap; } a[j] = tmp; } gap = Math.floor(gap/3); } return a; } console.log(shellSort([9,8,3,7,5,6,4,1])); R - Reflection Complexity: Time depends on gap sequence. Knuth works well in practice but can still be O(n^2) worst-case. Sedgewick improves to O(n^(4/3)) bounds. Space: O(1). Alternatives: vs insertion: Shell reduces long-distance moves; gap=1 returns to insertion. vs quick/heap: Shell is more cache-friendly but lacks strict O(n log n) bounds. vs merge: merge is stable but needs O(n) extra space; Shell is in-place but unstable. Why it works: Large gaps quickly move elements toward their approximate positions, reducing later insertion cost. Gap selection is critical; too large yields little benefit, too small leaves too many inversions. S - Summary Shell sort = grouped insertion + decreasing gaps. In-place but unstable; performance hinges on gap sequence. Knuth sequence is a practical default; Sedgewick/Pratt can improve theoretical bounds. Best for mid-size arrays when in-place is required and stability is not. In hybrid strategies, Shell can replace insertion for small segments as a middle layer. Benchmark using real data distribution; theory alone is not enough. Practice Guide / Steps Choose gap: Knuth by default; use Sedgewick if you want better upper bounds. Switching rule: after gap=1, finish with insertion; in hybrids, use Shell below a threshold. Test sets: random, nearly sorted, reversed, heavy duplicates. Record metrics: comparisons/moves, time, cache hits (perf/pprof). Runnable Examples: Multilingual Implementations Python def shell_sort(a): n=len(a); gap=1 while gap \u0026lt; n//3: gap = 3*gap + 1 while gap\u0026gt;=1: for i in range(gap,n): tmp=a[i]; j=i while j\u0026gt;=gap and a[j-gap]\u0026gt;tmp: a[j]=a[j-gap]; j-=gap a[j]=tmp gap//=3 return a print(shell_sort([9,8,3,7,5,6,4,1])) C void shell_sort(int *a, int n){ int gap=1; while(gap \u0026lt; n/3) gap = gap*3 + 1; for(; gap\u0026gt;=1; gap/=3){ for(int i=gap;i\u0026lt;n;i++){ int tmp=a[i], j=i; while(j\u0026gt;=gap \u0026amp;\u0026amp; a[j-gap]\u0026gt;tmp){ a[j]=a[j-gap]; j-=gap; } a[j]=tmp; } } } C++ void shell(vector\u0026lt;int\u0026gt;\u0026amp; a){ int n=a.size(), gap=1; while(gap\u0026lt;n/3) gap=gap*3+1; for(; gap\u0026gt;=1; gap/=3){ for(int i=gap;i\u0026lt;n;i++){ int tmp=a[i], j=i; while(j\u0026gt;=gap \u0026amp;\u0026amp; a[j-gap]\u0026gt;tmp){ a[j]=a[j-gap]; j-=gap; } a[j]=tmp; } } } Go func ShellSort(a []int) { gap := 1 for gap \u0026lt; len(a)/3 { gap = gap*3 + 1 } for gap \u0026gt;= 1 { for i := gap; i \u0026lt; len(a); i++ { tmp, j := a[i], i for j \u0026gt;= gap \u0026amp;\u0026amp; a[j-gap] \u0026gt; tmp { a[j] = a[j-gap] j -= gap } a[j] = tmp } gap /= 3 } } Rust pub fn shell_sort(a: \u0026amp;mut [i32]) { let mut gap = 1usize; while gap \u0026lt; a.len()/3 { gap = gap*3 + 1; } while gap \u0026gt;= 1 { for i in gap..a.len() { let tmp = a[i]; let mut j = i; while j \u0026gt;= gap \u0026amp;\u0026amp; a[j-gap] \u0026gt; tmp { a[j] = a[j-gap]; j -= gap; } a[j] = tmp; } if gap == 1 { break; } gap /= 3; } } JavaScript function shellSort(a){ let gap=1; while(gap \u0026lt; a.length/3) gap = gap*3 + 1; while(gap\u0026gt;=1){ for(let i=gap;i\u0026lt;a.length;i++){ const tmp=a[i]; let j=i; while(j\u0026gt;=gap \u0026amp;\u0026amp; a[j-gap]\u0026gt;tmp){ a[j]=a[j-gap]; j-=gap; } a[j]=tmp; } gap=Math.floor(gap/3); } return a; } Common Pitfalls and Notes Stability: Shell sort is unstable; if stability is required, choose merge/TimSort. Gap choice: simple n/2 often degenerates; use at least Knuth or Sedgewick. Size: for tiny arrays use insertion; for huge arrays evaluate O(n log n) alternatives. Benchmark: gap sequences behave differently across data distributions; measure on your data. Best Practices Default to Knuth sequence for simplicity and performance; use Sedgewick/Pratt for better bounds. In hybrids, replace the \u0026ldquo;small segment threshold\u0026rdquo; with Shell and measure whether it beats insertion. For teaching, visualize gap=4/2/1 passes to illustrate grouped insertion. Count comparisons/moves to evaluate different gap sequences. Conclusion Shell sort uses grouped insertion to reduce long-distance inversions; in-place but unstable. Knuth is practical; for stability or strict bounds use merge/TimSort/heap. As a hybrid layer, Shell can bridge insertion and quick/heap performance. References and Further Reading D. L. Shell, \u0026ldquo;A High-Speed Sorting Procedure\u0026rdquo; (1959) Robert Sedgewick, \u0026ldquo;Analysis of Shellsort and Related Algorithms\u0026rdquo; (1986) CLRS discussion of Shell sort Meta Reading time: approx. 15 min SEO keywords: Shell sort, gap sequence, in-place sorting, unstable sorting Meta description: sorting series (3) explaining gap sequences, complexity, and engineering usage of Shell sort with multilingual implementations. Call to Action (CTA) Compare Knuth vs Sedgewick sequences on your dataset and record timing differences. Replace small-segment insertion in your quicksort with Shell sort and measure the impact. Follow the series: merge, quick, heap, non-comparison, TimSort/Introsort, selection guide. ","permalink":"http://localhost:1313/en/alg/leetcode/3.sorting-series-shell-sort/","summary":"Explain Shell sort principles, gap strategies, and engineering usage with scenarios and Python/C/C++/Go/Rust/JS implementations.","title":"Sorting Series (3): Shell Sort - From Insertion to Gap-Based Efficiency"},{"content":" This is the second post in the sorting series, focusing on three O(n^2) baseline algorithms: bubble, selection, and insertion. They are simple and foundational, useful for understanding higher-level sorts and still valuable on small or nearly sorted data.\nTarget Readers Practice and teaching: need to master baseline sorts and explain them. Engineers: small-scale, embedded, or code-size-sensitive scenarios. Learners: want to understand stability, in-place behavior, and complexity sources. Background and Motivation Pain points: O(n^2) sorts are often ignored, but they represent the three core ideas: swap, select, insert. On small or nearly sorted data, insertion sort can outperform O(n log n) algorithms. We need a side-by-side comparison of stability, swaps/moves, and engineering use. A - Algorithm Theme: Compare bubble (swap-driven), selection (min selection), and insertion (prefix insertion) with a basic example.\nExample array: [5, 2, 4, 6, 1]\nBubble: adjacent swaps bubble the max to the end; repeat n passes. Selection: pick min each pass and swap into place; at most n swaps. Insertion: maintain a sorted prefix and insert current element; efficient when nearly sorted. Illustration (first two insertion passes):\nPass 1: |5| 2 4 6 1 -\u0026gt; 2 5 4 6 1 Pass 2: 2 |5| 4 6 1 -\u0026gt; 2 4 5 6 1 C - Concepts Algorithm Idea Stable In-place Comparisons (avg) Swaps/Moves Bubble Adjacent swaps Yes Yes O(n^2) O(n^2) swaps Selection Select min each pass No Yes O(n^2) O(n) swaps Insertion Insert into sorted prefix Yes Yes O(n^2) O(n^2) moves; O(n) when nearly sorted Where they fit\nBubble: teaching, stability requirement, tiny arrays. Selection: high swap cost (large objects), comparisons are acceptable. Insertion: small arrays, nearly sorted; also used as a subroutine in TimSort/Shell. E - Engineering Scenario 1: Embedded firmware small arrays (C) Background: microcontroller sorting at most tens of integers. Why: short code, in-place, no extra memory; selection sort has few swaps.\n// Selection sort, in-place O(1) space void selection_sort(int *a, int n) { for (int i = 0; i \u0026lt; n - 1; ++i) { int min_i = i; for (int j = i + 1; j \u0026lt; n; ++j) if (a[j] \u0026lt; a[min_i]) min_i = j; if (min_i != i) { int tmp = a[i]; a[i] = a[min_i]; a[min_i] = tmp; } } } Scenario 2: Nearly sorted small lists (Python) Background: UI list receives a few new items; data is mostly ordered. Why: insertion sort runs close to O(n) when inversions are small.\ndef insertion_sort(arr): for i in range(1, len(arr)): key = arr[i] j = i - 1 while j \u0026gt;= 0 and arr[j] \u0026gt; key: arr[j + 1] = arr[j] j -= 1 arr[j + 1] = key return arr data = [1, 2, 3, 5, 4] print(insertion_sort(data)) Scenario 3: Teaching visualization (JavaScript) Background: show swap vs insert in a classroom or demo. Why: bubble sort is stable and intuitive; JS is short and visual.\nfunction bubbleSort(arr) { const a = [...arr]; for (let i = 0; i \u0026lt; a.length; i++) { let swapped = false; for (let j = 0; j \u0026lt; a.length - i - 1; j++) { if (a[j] \u0026gt; a[j + 1]) { [a[j], a[j + 1]] = [a[j + 1], a[j]]; swapped = true; } } if (!swapped) break; // small optimization } return a; } console.log(bubbleSort([5, 2, 4, 6, 1])); Scenario 4: Small batch sorting (Go) Background: request payload size \u0026lt; 64, prefer smaller constants. Why: Go sort switches to insertion for small segments; show a minimal implementation.\npackage main import \u0026#34;fmt\u0026#34; func insertionSort(a []int) { for i := 1; i \u0026lt; len(a); i++ { key := a[i] j := i - 1 for j \u0026gt;= 0 \u0026amp;\u0026amp; a[j] \u0026gt; key { a[j+1] = a[j] j-- } a[j+1] = key } } func main() { arr := []int{5, 2, 4, 6, 1} insertionSort(arr) fmt.Println(arr) } R - Reflection Complexity: all three have O(n^2) time in worst/avg, O(1) space. Stability: bubble and insertion are stable; selection is not (swap can break order). Alternatives: Small arrays: insertion beats bubble/selection; also used as fallback in TimSort/Introsort. Large arrays: switch to O(n log n) (quick/merge/heap) or non-comparison. Why keep them: Teaching value: clear view of comparisons, swaps, and moves. Engineering value: tiny input, nearly sorted, code size constraints, or as hybrid submodules. S - Summary Bubble/selection/insertion represent swap/select/insert ideas and are core to understanding sorting. Stability: bubble and insertion are stable; selection is not but uses few swaps. On small or nearly sorted data, insertion often beats O(n log n) algorithms. Modern sort implementations use hybrids: large segments use quick/heap/merge, small segments fall back to insertion. Choose based on size, degree of order, stability, and swap cost. Practice Guide / Steps If n \u0026lt; 64 and nearly sorted, prefer insertion. Need stability and visualization: bubble with early-exit optimization. Swap cost is high: selection reduces swaps. Use insertion as a subroutine in quick/merge for small segments. Runnable Examples (Multilang Baselines) Python - Insertion def insertion_sort(a): for i in range(1, len(a)): key = a[i]; j = i - 1 while j \u0026gt;= 0 and a[j] \u0026gt; key: a[j+1] = a[j]; j -= 1 a[j+1] = key return a print(insertion_sort([5,2,4,6,1])) C - Selection void selection_sort(int *a, int n) { for (int i = 0; i \u0026lt; n - 1; ++i) { int min_i = i; for (int j = i + 1; j \u0026lt; n; ++j) if (a[j] \u0026lt; a[min_i]) min_i = j; if (min_i != i) { int t=a[i]; a[i]=a[min_i]; a[min_i]=t; } } } C++ - Bubble #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; void bubble(vector\u0026lt;int\u0026gt;\u0026amp; a){ for(size_t i=0;i\u0026lt;a.size();++i){ bool swapped=false; for(size_t j=0;j+1\u0026lt;a.size()-i;++j){ if(a[j]\u0026gt;a[j+1]){swap(a[j],a[j+1]);swapped=true;} } if(!swapped) break; } } int main(){vector\u0026lt;int\u0026gt; a={5,2,4,6,1}; bubble(a); for(int x:a) cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34; \u0026#34;;} Go - Insertion func insertion(a []int){ for i:=1;i\u0026lt;len(a);i++{ key:=a[i]; j:=i-1 for j\u0026gt;=0 \u0026amp;\u0026amp; a[j]\u0026gt;key { a[j+1]=a[j]; j-- } a[j+1]=key } } Rust - Insertion fn insertion_sort(a: \u0026amp;mut [i32]) { for i in 1..a.len() { let key = a[i]; let mut j = i as i32 - 1; while j \u0026gt;= 0 \u0026amp;\u0026amp; a[j as usize] \u0026gt; key { a[(j+1) as usize] = a[j as usize]; j -= 1; } a[(j+1) as usize] = key; } } fn main(){ let mut v = vec![5,2,4,6,1]; insertion_sort(\u0026amp;mut v); println!(\u0026#34;{:?}\u0026#34;, v); } JavaScript - Bubble function bubbleSort(a){ for(let i=0;i\u0026lt;a.length;i++){ let swapped=false; for(let j=0;j\u0026lt;a.length-i-1;j++){ if(a[j]\u0026gt;a[j+1]){[a[j],a[j+1]]=[a[j+1],a[j]];swapped=true;} } if(!swapped) break; } return a; } console.log(bubbleSort([5,2,4,6,1])); Explanation and Trade-offs Bubble vs Selection: bubble is stable but swaps more; selection swaps less but is unstable. Insertion vs Bubble: insertion does fewer moves; nearly sorted arrays can drop to O(n). Hybrid strategy: quick/heap for large segments, insertion for small segments. Common Pitfalls and Notes Bubble without early exit wastes O(n^2) on already sorted input. Selection with large structs: fewer swaps but each swap is costly; for stability use index arrays. Insertion degrades on large arrays; best for small or nearly sorted segments. Best Practices Keep a comparison table for stability, swaps/moves, and constants. Write an insertion helper and reuse it in custom quick/merge sorts. Test with sorted, reversed, many duplicates, and nearly sorted to observe early-exit behavior. Conclusion The O(n^2) trio is the foundation and a key component of hybrid sorting. For nearly sorted or small inputs, insertion remains a strong choice. Stable needs -\u0026gt; bubble or insertion; swap cost sensitive -\u0026gt; selection or stable variants. References and Further Reading CLRS chapters on insertion/bubble/selection sort CPython TimSort implementation notes (insertion thresholds) Intel/AMD notes on cache effects for small array sorting Meta Reading time: approx. 14 min SEO keywords: bubble sort, selection sort, insertion sort, O(n^2) sorting, stability Meta description: sorting series (2) comparing bubble/selection/insertion principles, stability, scenarios, and multilingual implementations for small or nearly sorted data. Call to Action (CTA) Benchmark a small dataset (e.g., 50 log rows) with all three algorithms. Add a \u0026ldquo;\u0026lt;= 32 switch to insertion\u0026rdquo; optimization in your quick/merge and measure the gain. Follow the series: shell, merge, quick, heap, non-comparison, TimSort/Introsort, selection guide. ","permalink":"http://localhost:1313/en/alg/leetcode/2.sorting-series-on2-baseline/","summary":"Systematic ACERS explanation of bubble/selection/insertion sorts: principles, stability, scenarios, and multilingual implementations with selection guidance.","title":"Sorting Series (2): Bubble, Selection, Insertion - Three O(n^2) Baselines"},{"content":" For readers preparing a systematic sorting series: this is the preface. We first build a selection map with the ACERS framework so you can quickly decide when to use quicksort, merge, heap, counting/radix, TimSort, Introsort, and more.\nTarget Readers Practice and study: want a structured overview to write a sorting series. Backend/data engineers: care about memory, stability, and parallel scenarios. Teaching and sharing: need a reusable framework and examples. Background and Motivation Pain points: too many sorting algorithms with similar names; stability/complexity are easy to mix up; engineering requires cache behavior, external sort, and language defaults. Goal: provide a \u0026ldquo;selection cheat sheet + scenarios + code skeletons\u0026rdquo; so the rest of the series has consistent structure and language. A - Algorithm Theme: How to choose a sorting algorithm based on input size, data distribution, and stability requirements.\nBasic examples\nExample 1: small array (\u0026lt;= 30) and nearly sorted -\u0026gt; insertion sort. Example 2: mid-size random array (~1e4) -\u0026gt; quicksort or Introsort. Example 3: huge integer keys with narrow range (\u0026lt;= 1e6) -\u0026gt; counting or bucket sort. Simple input/output\nInput: an array/slice of comparable elements Output: array/slice sorted in non-decreasing order C - Concepts Algorithm Avg Time Space Stable In-place Notes Bubble/Selection/Insertion O(n^2) O(1) Bubble/Insertion yes Yes/Yes/Yes baseline/teaching Shell between O(n^2) and O(n log n) O(1) No Yes gap sequence matters Merge O(n log n) O(n) Yes No good for external sort Quick O(n log n) avg; worst O(n^2) O(log n) No Yes pivot choice is key Heap O(n log n) O(1) No Yes good for streaming top-k Counting/Bucket/Radix O(n + k) O(n + k) Counting/Radix stable No/depends known range/digits required TimSort O(n log n) O(n) Yes No default in Python/Java Introsort O(n log n) O(1) No Yes C++ std::sort Categories\nDivide and conquer: merge, quick. Heap-based: heap sort. Increment-based: shell. Non-comparison: counting, bucket, radix. Engineering hybrids: TimSort (insertion + merge), Introsort (quick + heap + insertion). E - Engineering Scenario 1: Batch analytics (Python) Background: process 1e6 log rows, stable sort by timestamp to keep original order for ties. Why: Python built-in sort uses TimSort, stable and fast on partially sorted data.\nfrom operator import itemgetter logs = [ (\u0026#34;2025-11-01T10:00:00\u0026#34;, \u0026#34;user1\u0026#34;, 3), (\u0026#34;2025-11-01T10:00:00\u0026#34;, \u0026#34;user2\u0026#34;, 1), (\u0026#34;2025-11-01T10:00:01\u0026#34;, \u0026#34;user3\u0026#34;, 2), ] # Sort by timestamp ascending; stable keeps original order for ties logs.sort(key=itemgetter(0)) print(logs) Scenario 2: Backend pagination sort (Go) Background: sort items by price ascending and sales descending; dataset \u0026lt; 1e5. Why: sort.Slice is in-place and flexible; standard library is sufficient here.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sort\u0026#34; ) type Item struct { Price int; Sales int } func main() { items := []Item{{100, 50}, {80, 200}, {100, 120}} sort.Slice(items, func(i, j int) bool { if items[i].Price == items[j].Price { return items[i].Sales \u0026gt; items[j].Sales // sales desc } return items[i].Price \u0026lt; items[j].Price }) fmt.Println(items) } Scenario 3: Memory-limited offline sort (C++, external merge) Background: sort a 10GB integer file with only 512MB RAM. Why: external sort requires chunking + multi-way merge; stable and memory-bound.\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; int main() { vector\u0026lt;int\u0026gt; buf; buf.reserve(1 \u0026lt;\u0026lt; 20); // ~1M ints vector\u0026lt;string\u0026gt; tmpFiles; int x; int chunk = 0; while (cin \u0026gt;\u0026gt; x) { buf.push_back(x); if (buf.size() == buf.capacity()) { sort(buf.begin(), buf.end()); string name = \u0026#34;chunk\u0026#34; + to_string(chunk++) + \u0026#34;.tmp\u0026#34;; ofstream out(name); for (int v : buf) out \u0026lt;\u0026lt; v \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; tmpFiles.push_back(name); buf.clear(); } } // Omit the final chunk and k-way merge; show the idea cerr \u0026lt;\u0026lt; \u0026#34;chunks: \u0026#34; \u0026lt;\u0026lt; tmpFiles.size() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } Scenario 4: Frontend table sorting (JavaScript) Background: sort by multiple columns and keep order for equal keys (stable). Why: modern browsers usually have stable Array.prototype.sort; if unsure, map indices and sort.\nconst rows = [ { price: 100, sales: 50 }, { price: 100, sales: 120 }, { price: 80, sales: 200 }, ]; rows .map((row, idx) =\u0026gt; ({ ...row, idx })) .sort((a, b) =\u0026gt; a.price - b.price || a.idx - b.idx) .forEach(r =\u0026gt; console.log(r)); R - Reflection Complexity and space: O(n log n) workhorses: merge (stable, not in-place), quick (in-place, worst-case), heap (in-place, cache-unfriendly). O(n + k) non-comparison: counting/bucket/radix, only when range/digits are bounded. O(n^2) baseline: bubble/selection/insertion, mostly for teaching or tiny arrays. Alternatives: External sort vs in-memory: if data exceeds RAM, chunk + merge is mandatory. TimSort vs plain merge: TimSort is faster on partially sorted data and is the engineering default. Introsort vs plain quicksort: depth fallback to heap avoids worst-case O(n^2). Why this selection is reasonable: Stability first: merge/TimSort/counting/radix. Memory first: quick/heap/Introsort (in-place). Range known: counting/bucket/radix. Huge data: external merge with multi-way streaming. S - Summary Selection depends on data size, distribution, stability needs, and memory/external constraints. Default to the language built-in sort (often TimSort/Introsort); customize only for special needs. Non-comparison sorting can drop complexity to O(n + k) when range/digits are bounded. External sorting is essential for data larger than memory; core idea is chunking + multi-way merge. Choose criteria first (time, space, stability), then the algorithm. Practice Guide / Steps Step 1: Evaluate size and distribution (random/near-sorted/heavy duplicates). Step 2: Decide stability requirement and memory budget. Step 3: Use the table to pick a baseline; for Python/Java, prefer built-in stable sort. Step 4: Write three boundary tests: all equal, reverse, nearly sorted. Step 5: Benchmark large data and record time/memory. Runnable Example (Quick Benchmark, Python) import random, time def bench(n=100000): arr = [random.randint(0, 1000000) for _ in range(n)] t0 = time.time(); sorted(arr); t1 = time.time() print(f\u0026#34;n={n}, timsort time={t1 - t0:.3f}s\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: bench(200000) Common Pitfalls and Notes Forgetting comparator logic in Array.sort / sort.Slice may break stability or ordering. Fixed pivot in quicksort degenerates on sorted input; use random or median-of-three. Counting/bucket sort can blow memory if range is large; estimate min/max first. External sort with too many temp files requires k-way merge or staged merging. Best Practices Use standard library sorts in production unless you have explicit constraints. Write comparator + tests before implementing the sort; verify stability if needed. Sample large data to judge whether bucket/radix is appropriate or external sort is needed. Require a \u0026ldquo;sorting algorithm + rationale\u0026rdquo; note in PRs for review. Conclusion This preface provides the ACERS selection map for the series. Next steps: expand by category (O(n^2) baseline, shell, merge, quick, heap, non-comparison, TimSort, Introsort, selection playbook). References and Further Reading CLRS \u0026ldquo;Introduction to Algorithms\u0026rdquo; sorting chapters TimSort paper and CPython listobject.c C++ std::sort / std::stable_sort implementation notes PostgreSQL external sort (tuplesort) Meta Reading time: approx. 12 min SEO keywords: sorting selection, algorithm stability, TimSort, Introsort, external sort Meta description: sorting series preface using ACERS to summarize complexity, stability, and engineering scenarios with runnable examples and a selection checklist. Call to Action (CTA) Write a \u0026ldquo;sorting selection checklist\u0026rdquo; for your project with size/distribution/stability notes. Run the Python benchmark above with your real data distribution. Follow the series (quicksort, merge, heap, non-comparison, TimSort/Introsort, selection playbook) and replicate it with the ACERS template. ","permalink":"http://localhost:1313/en/alg/leetcode/1.sorting-series-preface/","summary":"Use the ACERS template to map common sorting algorithms by scenario, complexity, stability, and engineering usage, with runnable examples and a selection checklist.","title":"Sorting Series (1): How to Choose an Algorithm - Time, Space, Stability, Scenarios"},{"content":"UFW + CrowdSec: Stop Malicious Port Scans Subtitle / Abstract: How do you protect exposed server ports? This guide shows how to move past Fail2ban regex hell and build a stable, automated, intelligent port-scan defense system.\nTarget readers Developers using FRP or reverse tunnels Operators of cloud servers (Tencent, Alibaba, AWS, etc.) Linux users who want to stop port scans and SSH brute force People using Fail2ban who want a modern alternative Anyone improving personal server security Background / Motivation: Why you need port-scan defense When you run FRP (frps + frpc) or expose multiple ports, you will often see:\nMassive scans: repeated SYN probes Malicious connection attempts SSH password brute force Automated scans of 6001-6010, 7000, 22, 8080, etc. Traditional approaches have weaknesses:\nUFW only blocks passively Fail2ban is regex-heavy, error-prone, and lacks behavior analysis FRPS logs are hard to match in Fail2ban Attacks still consume frps/sshd resources and can cause slowdowns We need a modern system: no regex, auto detection, intelligent IP banning.\nCore concepts FRP (frps / frpc): reverse tunnel tool, often exposes many TCP ports (e.g., 6001-6010) UFW: Ubuntu firewall, but not intelligent Fail2ban: log-matching ban tool that requires regex CrowdSec (recommended): modern open-source IPS that detects port scans and brute force with behavior analysis and low resource usage Practical guide: Auto-block port scans with CrowdSec (Ubuntu/Debian) 1) Install CrowdSec curl -s https://packagecloud.io/install/repositories/crowdsec/crowdsec/script.deb.sh | sudo bash sudo apt install crowdsec -y 2) Install firewall bouncer (iptables/UFW) sudo apt install crowdsec-firewall-bouncer-iptables CrowdSec will manage blocking automatically.\n3) What it detects out of the box TCP port scans FRP brute-force attempts SSH brute force High-rate connections (DoS-like) Suspicious sequences (behavior analysis) No extra rules needed for 6001-6010 and other ports.\n4) View banned IPs sudo cscli decisions list Example:\nID Scope Value Reason Duration 1 Ip 195.24.237.176 portscan 4h 2 Ip 213.199.63.251 ssh-bf 24h 5) Manual ban (optional) sudo cscli decisions add --ip 195.24.237.176 6) Dashboard (optional) sudo apt install crowdsec-lapi Why CrowdSec \u0026gt; Fail2ban Feature Fail2ban CrowdSec Port-scan detection No Yes (auto) FRP log support Regex heavy No log match needed Config complexity High Low Performance Medium Very low Extensibility Weak Modular + behavior analysis Visualization None Dashboard Resource usage Medium RAM \u0026lt; 20MB CrowdSec is a modern replacement for Fail2ban with lower overhead and stronger detection.\nFail2ban pitfalls (why it fails in FRP scenarios) FRPS logs are complex; IP fields shift and are inconsistent Regex must be perfect; a small mistake matches nothing Logs include colons, brackets, and ports, which break patterns Host IP may be internal (e.g., 10.5.100.2), causing mismatched source IPs UFW log formats vary; Fail2ban cannot extract IP reliably Encoding issues can lead to \u0026ldquo;No failure-id group\u0026rdquo; Risks and notes Blocking can briefly impact FRP or SSH; always keep a backup access method (cloud console). CrowdSec may false-positive crawlers. Whitelist trusted IPs: sudo cscli machines list sudo cscli decisions delete --ip \u0026lt;trusted-ip\u0026gt; FRP often hides real client IPs in logs; CrowdSec works at the kernel level, so it still sees the source. Best practices Replace Fail2ban with CrowdSec (strongly recommended) Close unused FRP ports, use strong tokens and encryption Use SSH keys only, disable password auth Keep UFW default deny incoming Check bans regularly: cscli decisions list Consider Cloudflare Tunnel as an alternative to FRP Summary This guide covered:\nHow to detect and block port scans Why Fail2ban regex often fails Why FRP logs are a poor fit for Fail2ban How CrowdSec provides automated, low-maintenance protection Final solution: UFW + CrowdSec = stable, automated, low-maintenance server defense.\nReferences CrowdSec docs: https://doc.crowdsec.net CrowdSec bouncer: https://github.com/crowdsecurity/cs-firewall-bouncer Fail2ban docs: https://fail2ban.readthedocs.io FRP: https://github.com/fatedier/frp UFW docs: https://wiki.ubuntu.com/UFW ","permalink":"http://localhost:1313/en/linux/linux/ufw-crowdsec-portscan/","summary":"\u003ch1 id=\"ufw--crowdsec-stop-malicious-port-scans\"\u003eUFW + CrowdSec: Stop Malicious Port Scans\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eSubtitle / Abstract:\u003c/strong\u003e How do you protect exposed server ports? This guide shows how to move past Fail2ban regex hell and build a stable, automated, intelligent port-scan defense system.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"target-readers\"\u003eTarget readers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eDevelopers using FRP or reverse tunnels\u003c/li\u003e\n\u003cli\u003eOperators of cloud servers (Tencent, Alibaba, AWS, etc.)\u003c/li\u003e\n\u003cli\u003eLinux users who want to stop port scans and SSH brute force\u003c/li\u003e\n\u003cli\u003ePeople using Fail2ban who want a modern alternative\u003c/li\u003e\n\u003cli\u003eAnyone improving personal server security\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"background--motivation-why-you-need-port-scan-defense\"\u003eBackground / Motivation: Why you need port-scan defense\u003c/h2\u003e\n\u003cp\u003eWhen you run FRP (frps + frpc) or expose multiple ports, you will often see:\u003c/p\u003e","title":"UFW + CrowdSec: Stop Malicious Port Scans (From Fail2ban Pain to a Modern Solution)"},{"content":"WireGuard Full Guide: Build a Secure High-Speed Private Network (VPN Tutorial) Subtitle / Abstract: A beginner-to-intermediate WireGuard VPN guide. Learn to build a fast, secure private network and enforce a zero-exposure model where services are only reachable through VPN.\nTarget readers People who want to hide server or PC ports behind a VPN Users who want to reduce scanning and brute force risk Anyone building a private LAN or remote access to home Linux/Windows users, developers, and ops beginners Background and motivation: Why WireGuard? If you expose ports to the public internet (SSH, databases, admin panels), you will face:\nconstant scans brute force attempts automated probes potential intrusion risk OpenVPN is mature but heavy, slower, and complex to configure.\nWireGuard is built for modern security:\nsmall, secure, fast (next-gen VPN) codebase \u0026lt; 4000 lines (OpenVPN is 400k+) easy config low latency, high throughput great for private networks and remote work This guide helps you build a private network that is invisible to the public internet.\nCore concepts What is WireGuard? WireGuard is a modern, minimal VPN protocol in the Linux kernel, using modern crypto (ChaCha20, Curve25519, etc.).\nHighlights:\nvery fast simple config files strong security by default stable roaming (mobile network switching works) Terminology Term Meaning Interface WireGuard virtual interface, e.g., wg0 Peer A node (client/server) PrivateKey private key (keep secret) PublicKey public key (identity to peers) AllowedIPs IP ranges allowed for a peer WireGuard is peer-to-peer and does not need a certificate system like OpenVPN.\nWireGuard vs OpenVPN Item WireGuard OpenVPN Performance very fast (kernel) slower (user space) Config complexity minimal complex Security modern by default configurable but easy to misconfigure Stability high average Roaming excellent weak Code size ~4000 lines ~400k lines One-line summary: if you want speed, simplicity, and stability, choose WireGuard.\nPractical setup: Build WireGuard on a server Example uses Ubuntu/Debian.\n1. Install WireGuard sudo apt update sudo apt install wireguard -y 2. Generate server keys wg genkey | tee server_private.key | wg pubkey \u0026gt; server_public.key 3. Create server config /etc/wireguard/wg0.conf [Interface] Address = 10.8.0.1/24 ListenPort = 51820 PrivateKey = \u0026lt;server_private_key\u0026gt; # client peers will be added below 4. Start WireGuard sudo wg-quick up wg0 Enable on boot:\nsudo systemctl enable wg-quick@wg0 Create a mobile client (Peer) 1. Generate client keys wg genkey | tee phone_private.key | wg pubkey \u0026gt; phone_public.key 2. Add peer on the server Edit /etc/wireguard/wg0.conf:\n[Peer] PublicKey = \u0026lt;phone_public_key\u0026gt; AllowedIPs = 10.8.0.2/32 Restart WireGuard:\nsudo wg-quick down wg0 sudo wg-quick up wg0 3. Create client config (phone) phone.conf:\n[Interface] PrivateKey = \u0026lt;phone_private_key\u0026gt; Address = 10.8.0.2/32 DNS = 1.1.1.1 [Peer] PublicKey = \u0026lt;server_public_key\u0026gt; Endpoint = \u0026lt;your-public-ip-or-domain\u0026gt;:51820 AllowedIPs = 0.0.0.0/0 PersistentKeepalive = 25 Import on mobile via QR code Install:\nAndroid: WireGuard (Google Play) iOS: WireGuard (App Store) Generate QR code:\nqrencode -t ansiutf8 \u0026lt; phone.conf Scan in the WireGuard app.\nAfter connecting, your phone gets:\nInternal IP: 10.8.0.2 You can access:\nYour server: 10.8.0.1 Examples:\nSSH: ssh user@10.8.0.1 RDP: 10.8.0.1 Web: http://10.8.0.1:xxxx Why this works 1. Peer-to-peer design No certificates, no TLS, no expiry issues.\n2. Keys are identity Each device has a key pair as its identity.\n3. Kernel implementation WireGuard runs in the kernel crypto subsystem for high efficiency.\n4. Designed for modern networks Seamless roaming between 4G and Wi-Fi on mobile.\nCommon pitfalls Error 1: port 51820/udp not open You must open:\nUDP 51820 Error 2: wrong AllowedIPs If you set:\nAllowedIPs = 0.0.0.0/0 all phone traffic goes through VPN.\nTo access only the LAN:\nAllowedIPs = 10.8.0.0/24 Error 3: IP forwarding disabled echo \u0026#34;net.ipv4.ip_forward=1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf sysctl -p Best practices Generate a unique key pair for each device Do not share config files Use a fixed server IP (or DDNS) Restrict non-VPN traffic via UFW Bind backend services to internal IP only Example: SSH listens only on\nListenAddress 10.8.0.1 Summary WireGuard is ideal for:\nhome or work private networks hiding server ports secure remote access building a private LAN This guide covers principles, install, config, mobile access, and best practices. You can now:\ndeploy WireGuard quickly on any server access your private network securely avoid public port exposure and scanning If you need:\nDocker-based WireGuard Windows as the server multi-user management advanced routing Let me know and I can extend the series.\nReferences WireGuard docs: https://www.wireguard.com/ Linux man pages: man wg, man wg-quick WireGuard paper: https://www.wireguard.com/papers/wireguard.pdf Meta (SEO) Keywords: WireGuard tutorial, VPN private network, self-hosted VPN, server security, WireGuard vs OpenVPN Reading time: 8-12 minutes Tags: VPN, Linux, security, private network, tutorial Meta description: A comprehensive WireGuard VPN tutorial for building a fast and secure private network, with setup and mobile access. Call to Action (CTA) If this helped, star it, ask questions, or tell me your WireGuard scenario. I can help you tailor the config and extend the series.\n","permalink":"http://localhost:1313/en/linux/linux/wireguard-vpn-neiwang/","summary":"\u003ch1 id=\"wireguard-full-guide-build-a-secure-high-speed-private-network-vpn-tutorial\"\u003eWireGuard Full Guide: Build a Secure High-Speed Private Network (VPN Tutorial)\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eSubtitle / Abstract:\u003c/strong\u003e\nA beginner-to-intermediate WireGuard VPN guide. Learn to build a fast, secure private network and enforce a zero-exposure model where services are only reachable through VPN.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"target-readers\"\u003eTarget readers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003ePeople who want to hide server or PC ports behind a VPN\u003c/li\u003e\n\u003cli\u003eUsers who want to reduce scanning and brute force risk\u003c/li\u003e\n\u003cli\u003eAnyone building a private LAN or remote access to home\u003c/li\u003e\n\u003cli\u003eLinux/Windows users, developers, and ops beginners\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"background-and-motivation-why-wireguard\"\u003eBackground and motivation: Why WireGuard?\u003c/h2\u003e\n\u003cp\u003eIf you expose ports to the public internet (SSH, databases, admin panels), you will face:\u003c/p\u003e","title":"WireGuard Full Guide: Build a Secure High-Speed Private Network (VPN Tutorial)"},{"content":"Build a Hugo Blog with GitHub Pages in 10 Minutes Subtitle / Abstract This guide takes you from zero to a deployed Hugo blog on GitHub Pages with GitHub Actions. It is beginner-friendly and explains the key moving parts.\nTarget readers Hugo beginners Developers who want a quick technical blog Users of GitHub Pages and GitHub Actions Anyone who wants free static hosting Background / Motivation Common pain points when publishing a blog:\nmanual uploads scattered deployment steps confusing GitHub Pages setup theme assets failing to build The combo Hugo + GitHub Pages + GitHub Actions solves these:\nHugo is fast Pages is free Actions deploys on every push Core concepts Hugo: static site generator GitHub Pages: free static hosting GitHub Actions: CI pipeline to build and deploy PaperMod: popular Hugo theme Steps: from local to online Step 1: Create a Hugo site hugo new site myblog cd myblog git init Add PaperMod:\ngit submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod Set config.toml:\nbaseURL = \u0026#34;https://\u0026lt;your-username\u0026gt;.github.io/\u0026lt;repo\u0026gt;/\u0026#34; languageCode = \u0026#34;en-us\u0026#34; title = \u0026#34;My Blog\u0026#34; theme = \u0026#34;PaperMod\u0026#34; Step 2: Push to GitHub git remote add origin git@github.com:\u0026lt;your-username\u0026gt;/\u0026lt;repo\u0026gt;.git git add . git commit -m \u0026#34;init blog\u0026#34; git push -u origin main Step 3: Enable GitHub Pages In your repo:\nSettings -\u0026gt; Pages Build and deployment -\u0026gt; Source = GitHub Actions If the repo is private, set it public or enable Pages for private repositories (paid). Otherwise you may see 404.\nStep 4: Add GitHub Actions workflow Create .github/workflows/hugo.yml:\nname: Deploy Hugo site to Pages on: push: branches: [\u0026#34;main\u0026#34;] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 with: submodules: true - uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;0.120.4\u0026#34; - name: Build run: hugo --minify - name: Upload uses: actions/upload-pages-artifact@v2 with: path: ./public deploy: needs: build runs-on: ubuntu-latest permissions: pages: write id-token: write environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v2 Step 5: Create a post and publish hugo new posts/hello-world.md Edit front matter, set draft: false, write your content, and push.\nCommon issues draft: true means the post will not show incorrect baseURL causes broken links missing submodules in Actions -\u0026gt; theme missing Pages source not set to Actions Summary Hugo builds fast static pages GitHub Actions automates build and deploy GitHub Pages hosts for free Once set, you only need to write Markdown and push.\n","permalink":"http://localhost:1313/en/thoughts/thoughts/how-to-build-a-blog-system/","summary":"\u003ch1 id=\"build-a-hugo-blog-with-github-pages-in-10-minutes\"\u003eBuild a Hugo Blog with GitHub Pages in 10 Minutes\u003c/h1\u003e\n\u003ch2 id=\"subtitle--abstract\"\u003eSubtitle / Abstract\u003c/h2\u003e\n\u003cp\u003eThis guide takes you from zero to a deployed Hugo blog on GitHub Pages with GitHub Actions. It is beginner-friendly and explains the key moving parts.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"target-readers\"\u003eTarget readers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eHugo beginners\u003c/li\u003e\n\u003cli\u003eDevelopers who want a quick technical blog\u003c/li\u003e\n\u003cli\u003eUsers of GitHub Pages and GitHub Actions\u003c/li\u003e\n\u003cli\u003eAnyone who wants free static hosting\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"background--motivation\"\u003eBackground / Motivation\u003c/h2\u003e\n\u003cp\u003eCommon pain points when publishing a blog:\u003c/p\u003e","title":"How to Build a Blog System"},{"content":"How to Publish with Hugo: From Markdown to Online Blog Subtitle / Abstract This guide explains how to create, manage, and publish Hugo posts: front matter, drafts, images, directory structure, local preview, and deployment.\nTarget readers Hugo beginners Developers building a technical blog with Hugo Writers using Markdown + static sites Users of PaperMod, DoIt, and similar themes Background / Motivation After setting up a Hugo site, common questions include:\nWhere should posts go? How should front matter be written? Where do images live? Why does the post show locally but not online? How do drafts and publish dates work? How do posts appear on the homepage? This guide provides practical steps and best practices for the full publishing flow.\nCore concepts 1) Content directory Hugo posts live under content/:\ncontent/ posts/ my-first-post.md 2) Front matter Top metadata controls title, date, draft, tags, etc.\n--- title: \u0026#34;My Title\u0026#34; date: 2024-08-26 draft: false tags: [\u0026#34;hugo\u0026#34;, \u0026#34;blog\u0026#34;] --- 3) Draft Drafts are not built. Use hugo server -D to preview drafts.\n4) Section content/posts/* maps to the /posts/ section.\nSteps Step 1: Create a new post hugo new posts/how-to-publish.md This creates:\ncontent/posts/how-to-publish.md Default content:\n--- title: \u0026#34;How to Publish\u0026#34; date: 2024-08-26T10:00:00+08:00 draft: true --- Step 2: Edit front matter A typical PaperMod-friendly front matter:\n--- title: \u0026#34;How to Publish with Hugo\u0026#34; date: 2024-08-26T10:00:00+08:00 draft: false tags: [\u0026#34;hugo\u0026#34;, \u0026#34;blog\u0026#34;, \u0026#34;static-site\u0026#34;] categories: [\u0026#34;tutorial\u0026#34;] summary: \u0026#34;A complete guide from writing to publishing.\u0026#34; cover: image: \u0026#34;/images/hugo-cover.png\u0026#34; alt: \u0026#34;Hugo cover\u0026#34; caption: \u0026#34;Hugo blog cover\u0026#34; --- Step 3: Write content Use Markdown and keep headings consistent. Add code blocks where needed.\nStep 4: Add images Common options:\nstatic/images/... and reference as /images/... Page bundles: content/posts/my-post/index.md with images in the same folder Step 5: Preview locally hugo server -D Open http://localhost:1313.\nStep 6: Build and deploy hugo Static output goes to public/. Deploy via GitHub Pages, Netlify, or your server.\nCommon pitfalls draft: true prevents publishing Wrong folder (e.g., outside content/) Missing or incorrect baseURL Images referenced with wrong paths Theme config not loaded Summary Create posts with hugo new Write front matter carefully Preview with hugo server -D Build with hugo and deploy If you want a complete deployment pipeline with GitHub Actions, see the next guide.\n","permalink":"http://localhost:1313/en/thoughts/thoughts/how-to-publish-by-hugo/","summary":"\u003ch1 id=\"how-to-publish-with-hugo-from-markdown-to-online-blog\"\u003eHow to Publish with Hugo: From Markdown to Online Blog\u003c/h1\u003e\n\u003ch2 id=\"subtitle--abstract\"\u003eSubtitle / Abstract\u003c/h2\u003e\n\u003cp\u003eThis guide explains how to create, manage, and publish Hugo posts: front matter, drafts, images, directory structure, local preview, and deployment.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"target-readers\"\u003eTarget readers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eHugo beginners\u003c/li\u003e\n\u003cli\u003eDevelopers building a technical blog with Hugo\u003c/li\u003e\n\u003cli\u003eWriters using Markdown + static sites\u003c/li\u003e\n\u003cli\u003eUsers of PaperMod, DoIt, and similar themes\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"background--motivation\"\u003eBackground / Motivation\u003c/h2\u003e\n\u003cp\u003eAfter setting up a Hugo site, common questions include:\u003c/p\u003e","title":"How to Publish with Hugo"},{"content":"Title (accurate and keyword-rich) Write Clear Requirements with Issue Templates: A Complete Guide to GitHub Issue Forms\nSubtitle / Abstract This post teaches you how to configure GitHub Issue templates for feature requests and bug reports, including folder structure, YAML forms, Markdown templates, and common pitfalls. It is ideal for teams that want clearer requirements and less back-and-forth.\nTarget readers This article is for:\nBackend/frontend/full-stack engineers who create Issues regularly Leads/TLs/architects who want standardized requirement intake Mid-level developers familiar with GitHub but new to Issue templates Beginners can follow, but basic GitHub knowledge is assumed.\nBackground / Motivation: Why templates? Without templates, you often hear:\n\u0026ldquo;What is the background?\u0026rdquo; \u0026ldquo;Which modules are affected?\u0026rdquo; \u0026ldquo;What is the acceptance criteria?\u0026rdquo; \u0026ldquo;How high is the priority?\u0026rdquo; A one-line Issue like:\n\u0026ldquo;Add export feature\u0026rdquo;\nwill confuse everyone.\nLong-term pain points:\nHigh communication cost: details must be asked repeatedly Information asymmetry: the requester knows, but the Issue does not Hard to plan: no priority or acceptance criteria Hard to trace: months later, nobody knows the intent GitHub Issue Templates are structured questions that guide good input:\nenforce or guide required fields auto-label and auto-prefix titles support form UI validation Goal: make every new Issue understandable at a glance.\nCore concepts 1. Issue Template A preset format shown when creating a new Issue Can be Markdown text or YAML form 2. Markdown template Old and simple Essentially a prefilled Markdown file Path: .github/ISSUE_TEMPLATE/xxx.md or .github/ISSUE_TEMPLATE.md 3. YAML Issue form New and recommended Form UI with inputs and dropdowns Submissions are converted to Markdown in the Issue body Path: .github/ISSUE_TEMPLATE/xxx.yml 4. config.yml Path: .github/ISSUE_TEMPLATE/config.yml Controls: Whether blank Issues are allowed Which templates are displayed Practice guide / Steps overview Create .github/ISSUE_TEMPLATE Create a Feature template (YAML form) (Optional) Create a Bug template Configure config.yml for blank Issue behavior Commit and push to GitHub Verify in the GitHub UI Step 1: Create the template folder mkdir -p .github/ISSUE_TEMPLATE Structure:\nyour-repo/ .github/ ISSUE_TEMPLATE/ # yml / md files go here src/ ... Step 2: Feature request template (YAML form) Create .github/ISSUE_TEMPLATE/feature-request.yml:\nname: \u0026#34;Feature Request\u0026#34; description: \u0026#34;Use for new features or requirement changes\u0026#34; title: \u0026#34;[Feature] \u0026#34; labels: - \u0026#34;feature\u0026#34; - \u0026#34;enhancement\u0026#34; body: - type: markdown attributes: value: | Thanks for submitting a feature request. Please be as clear as possible for evaluation and planning. - type: input id: module attributes: label: Affected module description: Service or module involved (API, crawler, UI, etc.) placeholder: e.g. export API / attachment viewer validations: required: true - type: textarea id: background attributes: label: Background / scenario description: Why do we need this? What problem are we solving? placeholder: | Describe business context, roles, usage scenario, pain points... validations: required: true - type: textarea id: description attributes: label: Requirement description description: Describe desired behavior from the user perspective. placeholder: | 1. Add ... on page ... 2. When user does ..., the system should ... 3. Edge cases to support: ... validations: required: true - type: textarea id: acceptance_criteria attributes: label: Acceptance criteria description: What counts as \u0026#34;done\u0026#34;? Helps testing and review. placeholder: | - [ ] Scenario 1: ... - [ ] Scenario 2: ... - [ ] Performance / security requirements: ... validations: required: true - type: dropdown id: priority attributes: label: Priority description: For planning and ordering options: - P0 (must be done this iteration) - P1 (high) - P2 (normal) - P3 (low) default: 2 validations: required: false - type: textarea id: extra attributes: label: Extra info description: Related APIs, docs, designs, screenshots, linked issues placeholder: | - API docs: - Design / prototype: - Related Issue / ticket: validations: required: false Effect:\nA \u0026ldquo;Feature Request\u0026rdquo; option appears on Issue creation The form replaces plain text Labels feature and enhancement are added Title is prefixed with [Feature] Key fields are required Step 3 (Optional): Bug report template Create .github/ISSUE_TEMPLATE/bug-report.yml:\nname: \u0026#34;Bug Report\u0026#34; description: \u0026#34;Use for bugs and exceptions\u0026#34; title: \u0026#34;[Bug] \u0026#34; labels: - \u0026#34;bug\u0026#34; body: - type: textarea id: summary attributes: label: Summary placeholder: Briefly describe the problem validations: required: true - type: textarea id: steps attributes: label: Steps to reproduce placeholder: | 1. Open ... 2. Click ... 3. See ... validations: required: true - type: textarea id: expected attributes: label: Expected result validations: required: true - type: textarea id: actual attributes: label: Actual result validations: required: true - type: textarea id: extra attributes: label: Extra info description: Logs, screenshots, environment details validations: required: false Now your team can separate feature requests from bugs clearly.\nStep 4: Configure config.yml Create .github/ISSUE_TEMPLATE/config.yml:\nblank_issues_enabled: false # disallow blank Issues, force templates contact_links: - name: Internal request system url: https://example.com/your-internal-system about: If this is a formal request, create it in the internal system first. If you do not have an internal system, remove contact_links or replace with your wiki.\nblank_issues_enabled: false forces template usage and prevents empty Issues.\nStep 5: Commit and push git add .github/ISSUE_TEMPLATE/* git commit -m \u0026#34;chore: add GitHub issue templates for feature and bug\u0026#34; git push Templates take effect on the default branch (usually main or master).\nStep 6: Verify in GitHub UI Open your repo Click Issues Click New issue You should see template choices such as:\nFeature Request Bug Report (Optional) Open a blank issue If blank_issues_enabled: false, the blank option disappears.\nMinimal runnable example If you only need a minimal Feature template, do this:\n1) Create folder:\nmkdir -p .github/ISSUE_TEMPLATE 2) Create .github/ISSUE_TEMPLATE/feature-request.yml:\nname: \u0026#34;Feature Request\u0026#34; description: \u0026#34;Use for new features or requirement changes\u0026#34; title: \u0026#34;[Feature] \u0026#34; labels: [\u0026#34;feature\u0026#34;] body: - type: textarea id: background attributes: label: Background / scenario placeholder: Briefly describe why this is needed validations: required: true - type: textarea id: description attributes: label: Requirement description placeholder: | What should the system do? How will users use it? validations: required: true - type: textarea id: acceptance attributes: label: Acceptance criteria placeholder: | - [ ] Scenario 1: ... - [ ] Scenario 2: ... validations: required: true Then:\ngit add .github/ISSUE_TEMPLATE/feature-request.yml git commit -m \u0026#34;add minimal feature request issue template\u0026#34; git push Why YAML forms instead of Markdown? Benefits of YAML forms Required field validation for background/requirements/acceptance Friendly UI for non-technical teammates Clear structure for reading and automation Auto labels and title prefixes Markdown template pros and cons Markdown templates are fine, but:\nPros: simple and compatible good for technical teams Cons: cannot enforce required fields UI is less friendly for product/ops roles If you want team standards and clarity, YAML forms are better. For small personal projects, Markdown is enough.\nCommon issues and notes 1. Template not working? Check:\ncorrect path: .github/ISSUE_TEMPLATE/xxx.yml or .github/ISSUE_TEMPLATE/xxx.md default branch: template must be on main/master case sensitivity: ISSUE_TEMPLATE must match exactly 2. Template updated but UI unchanged? browser cache: refresh or use private mode confirm you pushed to GitHub for forks, templates are per-repo and do not inherit upstream 3. Org-level templates? You can configure templates in an org-wide .github repo. Repos without templates will use the org default.\n4. YAML errors? YAML is sensitive to indentation and spaces GitHub may ignore or error on malformed YAML Use editor validation (VS Code is great) Best practices Start simple: one feature template first Require core fields: background, description, acceptance Standardize title prefixes: [Feature], [Bug] Auto-label to reduce manual maintenance Keep forms short; balance clarity and friction Review after 1-2 months and refine fields Conclusion This guide covers:\nIssue template concepts (YAML forms vs Markdown) A full Feature template plus optional Bug template The end-to-end workflow: create -\u0026gt; write -\u0026gt; push -\u0026gt; verify Why YAML forms are recommended If you apply these steps, requirement quality will improve immediately.\nReferences and further reading GitHub Docs: Issue and pull request templates Keywords: github issue template yaml github issue forms github .github/ISSUE_TEMPLATE examples Meta Reading time: 8-12 minutes Tags: GitHub, collaboration, Issue templates, team standards, requirements SEO keywords: GitHub Issue template GitHub Issue Template config YAML Issue Form tutorial Feature request template Meta description: A complete guide to configuring GitHub Issue templates (YAML forms and Bug templates) with best practices and pitfalls. Call to Action (CTA) If you finished reading, do this now:\nPick a GitHub repo you use often Create .github/ISSUE_TEMPLATE/feature-request.yml Push and open a test Issue to see the effect ","permalink":"http://localhost:1313/en/notes/git-notes/write-clear-issues-from-zero-to-template/","summary":"\u003ch2 id=\"title-accurate-and-keyword-rich\"\u003eTitle (accurate and keyword-rich)\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eWrite Clear Requirements with Issue Templates: A Complete Guide to GitHub Issue Forms\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"subtitle--abstract\"\u003eSubtitle / Abstract\u003c/h2\u003e\n\u003cp\u003eThis post teaches you how to configure GitHub Issue templates for feature requests and bug reports, including folder structure, YAML forms, Markdown templates, and common pitfalls. It is ideal for teams that want clearer requirements and less back-and-forth.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"target-readers\"\u003eTarget readers\u003c/h2\u003e\n\u003cp\u003eThis article is for:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBackend/frontend/full-stack engineers who create Issues regularly\u003c/li\u003e\n\u003cli\u003eLeads/TLs/architects who want standardized requirement intake\u003c/li\u003e\n\u003cli\u003eMid-level developers familiar with GitHub but new to Issue templates\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBeginners can follow, but basic GitHub knowledge is assumed.\u003c/p\u003e","title":"Write Clear Issues with Templates: From Zero to GitHub Issue Forms"},{"content":"Title How to Write a Qualified API Document: From Swagger to Modern OpenAPI\nSubtitle / Abstract Want developers to actually enjoy using your API? This article covers the structure, examples, and best practices of high-quality API documentation based on Swagger/OpenAPI (originally by Tony Tam).\nTarget readers Beginners who want a standard API doc structure Mid-level developers improving maintainability Architects and leads defining API standards Background / Motivation Common problems in API docs:\ninconsistent format out-of-date content not usable for automation or testing Tony Tam introduced Swagger (renamed to OpenAPI) in 2010 to solve this. It is now the de facto standard for REST API docs, used by Google, Amazon, Stripe, and more.\nCore concepts Concept Description API doc Technical specification of how to call an API and interpret requests/responses Swagger/OpenAPI Standard to define, generate, and test REST APIs Endpoint A concrete path like /users/{id} Schema Field structure for requests and responses Practical steps Define a clear structure\nOverview Authentication Endpoints Schemas Errors and examples Use OpenAPI (YAML is recommended)\nRecommended tools\nEditors: Swagger Editor, Stoplight Studio, VS Code + YAML Docs: Swagger UI / ReDoc Auto-gen: Springdoc, FastAPI, NestJS Runnable example (OpenAPI) openapi: 3.0.0 info: title: User Management API version: 1.0.0 description: APIs for user management. servers: - url: https://api.example.com/v1 paths: /users/{id}: get: summary: Get user by ID parameters: - name: id in: path required: true description: User ID schema: type: string responses: \u0026#39;200\u0026#39;: description: OK content: application/json: schema: $ref: \u0026#39;#/components/schemas/User\u0026#39; \u0026#39;404\u0026#39;: description: User not found components: schemas: User: type: object properties: id: type: string description: Unique user id name: type: string description: User name email: type: string description: Email address You can import this into Swagger Editor for visualization and testing.\nExplanation Why OpenAPI?\nStandardized: avoid custom formats Automated: generate SDKs, tests, mocks Interactive: Swagger UI allows live testing Alternatives:\nRAML (MuleSoft) API Blueprint (documentation-focused) OpenAPI wins because of its tooling ecosystem.\nCommon pitfalls Problem Cause Fix Docs and code drift manual updates auto-generate from code (FastAPI, Springdoc) Schema too complex deep nesting split models with $ref Missing fields in examples no mock testing use mock server to validate Best practices Version your API paths (e.g., /v1/) Standardize error format ({code, message, data}) Keep docs in sync with code Add real examples Validate OpenAPI in CI Summary Great API docs are not just documentation but a collaboration bridge. Swagger/OpenAPI is about making APIs machine-readable and human-usable. With the right structure and tools, your APIs become easier to maintain and test.\nReferences OpenAPI Specification Swagger Editor ReDoc Microsoft API Design Guidelines Meta Reading time: 7 minutes Tags: API docs, Swagger, OpenAPI, standards, Tony Tam SEO keywords: API documentation standard, Swagger tutorial, OpenAPI example, RESTful design Meta description: Based on Swagger/OpenAPI, this guide explains API doc structure, examples, and best practices. Call to Action (CTA) Try it now:\nOpen Swagger Editor and paste the YAML above Or follow this series on API design; next post: auto-generate SDKs with OpenAPI ","permalink":"http://localhost:1313/en/thoughts/thoughts/api-standards/","summary":"\u003ch1 id=\"title\"\u003eTitle\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eHow to Write a Qualified API Document: From Swagger to Modern OpenAPI\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"subtitle--abstract\"\u003eSubtitle / Abstract\u003c/h2\u003e\n\u003cp\u003eWant developers to actually enjoy using your API? This article covers the structure, examples, and best practices of high-quality API documentation based on Swagger/OpenAPI (originally by Tony Tam).\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"target-readers\"\u003eTarget readers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eBeginners who want a standard API doc structure\u003c/li\u003e\n\u003cli\u003eMid-level developers improving maintainability\u003c/li\u003e\n\u003cli\u003eArchitects and leads defining API standards\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"background--motivation\"\u003eBackground / Motivation\u003c/h2\u003e\n\u003cp\u003eCommon problems in API docs:\u003c/p\u003e","title":"API Standards"},{"content":"For a system, a single thread should be a single assistant. We should provide each user with one assistant and optimize that assistant.\nProviding many parallel threads per user is too expensive and unnecessary.\n","permalink":"http://localhost:1313/en/thoughts/thoughts/thoughts-on-ai-systems/","summary":"\u003cp\u003eFor a system, a single thread should be a single assistant. We should provide each user with one assistant and optimize that assistant.\u003c/p\u003e\n\u003cp\u003eProviding many parallel threads per user is too expensive and unnecessary.\u003c/p\u003e","title":"Thoughts on AI Systems"},{"content":"Run Gitea Locally: Your Private GitHub (with Existing Repo Import) Subtitle / Abstract: This guide walks you through installing the lightweight Git server Gitea on your local machine. No root required, no system pollution. Manage, browse, and push projects like GitHub, and import existing repos.\nTarget readers: Personal developers, indie engineers, and small team leads with basic Git knowledge.\nBackground / Motivation Many developers want:\nto host code inside a company or LAN to avoid cloud platforms (GitHub/Gitee) to have a web UI, pull requests, and code browsing GitLab is heavy (often multiple GB of RAM). Gitea is:\nlightweight a single binary supports PR, Wiki, Issues, CI/CD In minutes, you get a private \u0026ldquo;mini GitHub\u0026rdquo;.\nCore concepts Term Description GitLab most powerful open-source Git platform, heavy resource usage Gitea lightweight self-hosted Git service with GitHub-like UI Bare repo repo with history only, no working tree Pull Request merge request from one branch to another SQLite default lightweight database for Gitea Setup steps 1) Prepare environment Supported OS: Linux / macOS / Windows Recommended: RAM \u0026gt;= 512MB, disk \u0026gt;= 1GB\n2) Create directory and download mkdir -p ~/gitea cd ~/gitea wget -O gitea https://dl.gitea.io/gitea/1.22.0/gitea-1.22.0-linux-amd64 chmod +x gitea 3) Start Gitea ./gitea web --port 3000 Open: http://localhost:3000\n4) Install wizard Fill in:\nDB type: SQLite3 Repo root: /home/\u0026lt;username\u0026gt;/gitea/repos Base URL: http://localhost:3000 Create admin account Runnable example: push an existing repo Assume your local project is /home/gong/projects/scrapy:\nCreate a repo named scrapy in Gitea In your project directory: cd ~/projects/scrapy git remote set-url origin http://localhost:3000/JeanphiloGong/scrapy.git git push -u origin --all git push -u origin --tags Refresh the web UI to see full history.\nRegister as a system service 1) Prerequisites Assume Gitea is installed at:\n/home/gong/gitea Binary path:\n/home/gong/gitea/gitea Run as user gong and do not use root.\n2) Create systemd service Create /etc/systemd/system/gitea.service:\n[Unit] Description=Gitea (Self-hosted Git Service) After=network.target [Service] # User and group User=gong Group=gong # Working directory WorkingDirectory=/home/gong/gitea # Start command ExecStart=/home/gong/gitea/gitea web --config /home/gong/gitea/custom/conf/app.ini # Restart policy Restart=always RestartSec=10s # Environment (optional) Environment=USER=gong HOME=/home/gong GITEA_WORK_DIR=/home/gong/gitea # Security PrivateTmp=true ProtectSystem=full NoNewPrivileges=true [Install] WantedBy=multi-user.target Notes:\nWorkingDirectory is the Gitea directory ExecStart defines the launch command Restart=always ensures auto-restart 3) Load and enable # Reload systemd sudo systemctl daemon-reload # Enable auto-start sudo systemctl enable gitea # Start service sudo systemctl start gitea # Check status sudo systemctl status gitea Expected:\nActive: active (running) 4) View logs Real-time logs:\nsudo journalctl -u gitea -f History logs:\nsudo journalctl -u gitea --since \u0026#34;1 hour ago\u0026#34; Explanation Gitea is a Go-based self-hosted Git service. It manages local Git repos (e.g., ~/gitea/repos) and exposes GitHub-like operations via HTTP/SSH.\nCompared to git init --bare (just storage), Gitea adds web UI, users, PRs, and Wiki.\nCommon issues Issue Cause Fix Port 3000 in use Another service uses it Run ./gitea web --port 8080 Permission errors Gitea runs as current user Check repo directory permissions Push fails Repo init conflict Do not select \u0026ldquo;Initialize with README\u0026rdquo; Push slow/timeouts Using HTTP not SSH Configure SSH keys for faster pushes Best practices SQLite is enough for personal or small teams\nRun in background: nohup ./gitea web \u0026amp;\nBackup regularly:\n~/gitea/repos/ ~/gitea/data/gitea.db ~/gitea/custom/conf/app.ini If the team grows, move to a server or Docker\nSummary You have:\nDeployed Gitea locally Avoided port conflicts Pushed existing repos to Gitea Gained a web UI, PRs, and history You now have your own private \u0026ldquo;GitHub\u0026rdquo;.\nReferences Gitea docs Gitea downloads Pro Git book Forgejo Meta Reading time: 8 minutes Tags: Git, Gitea, self-hosted, DevOps, version-control SEO keywords: local Gitea install, self-hosted Git server, private GitHub, import local repo Meta description: Set up a lightweight local Git server with Gitea, including PRs, web UI, and repo management. Call to Action (CTA) Try it now:\nRun the install commands Visit http://localhost:3000 Create your first repo Push a project If you want automation and backup scripts, leave a comment and I will share a follow-up.\n","permalink":"http://localhost:1313/en/notes/git-notes/configure-gitea/","summary":"\u003ch1 id=\"run-gitea-locally-your-private-github-with-existing-repo-import\"\u003eRun Gitea Locally: Your Private GitHub (with Existing Repo Import)\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eSubtitle / Abstract:\u003c/strong\u003e\nThis guide walks you through installing the lightweight Git server Gitea on your local machine. No root required, no system pollution. Manage, browse, and push projects like GitHub, and import existing repos.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTarget readers:\u003c/strong\u003e\nPersonal developers, indie engineers, and small team leads with basic Git knowledge.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"background--motivation\"\u003eBackground / Motivation\u003c/h2\u003e\n\u003cp\u003eMany developers want:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eto host code inside a company or LAN\u003c/li\u003e\n\u003cli\u003eto avoid cloud platforms (GitHub/Gitee)\u003c/li\u003e\n\u003cli\u003eto have a web UI, pull requests, and code browsing\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eGitLab is heavy (often multiple GB of RAM). Gitea is:\u003c/p\u003e","title":"How to Set Up Gitea"},{"content":"Title From feat to fix: master Git commit conventions for collaboration and automation\nSubtitle / Abstract A practical guide to Conventional Commits. Learn commit types (feat:, fix:), write clean messages, and enable automatic changelogs and releases.\nTarget readers Beginners: new to Git, want better commit habits. Mid-level devs: want commits friendly to team and CI. Leads/architects: want a consistent team standard. Background / Motivation Most commit messages look like:\n\u0026ldquo;update code\u0026rdquo; \u0026ldquo;fix bug\u0026rdquo; \u0026ldquo;some changes\u0026rdquo;\nThey are readable short-term but useless long-term. As teams grow, it becomes hard to track intent or automate releases.\nConventional Commits provides a simple, unified format so commits are readable, traceable, and automatable.\nCore concept Conventional Commits define a commit message structure:\n\u0026lt;type\u0026gt;(\u0026lt;scope\u0026gt;): \u0026lt;subject\u0026gt; \u0026lt;body\u0026gt; \u0026lt;footer\u0026gt; type: commit type, e.g. feat, fix, docs scope: optional area, e.g. ui, api subject: short description (\u0026lt;= 50 chars) body: details (optional) footer: metadata (e.g., BREAKING CHANGE) Practical steps Set Git editor to Neovim (optional) git config --global core.editor \u0026#34;nvim\u0026#34; Write a standard commit message git commit -m \u0026#34;feat(lsp): support new nvim-lspconfig API\u0026#34; Structured commit example feat(lsp): update LSP config for new nvim-lspconfig - remove old lspconfig[server].setup - use new function call lspconfig(server, {...}) Enforce with tooling (optional) npm install -g commitlint @commitlint/config-conventional Create .commitlintrc.js:\nmodule.exports = { extends: [\u0026#34;@commitlint/config-conventional\u0026#34;] }; Runnable examples # new feature git commit -m \u0026#34;feat(auth): add two-factor login\u0026#34; # bug fix git commit -m \u0026#34;fix(ui): fix text invisibility in dark mode\u0026#34; # docs git commit -m \u0026#34;docs(readme): add usage notes\u0026#34; # refactor git commit -m \u0026#34;refactor(api): optimize auth logic\u0026#34; # performance git commit -m \u0026#34;perf(db): improve query cache\u0026#34; Explanation This standard comes from the Angular commit message format and became the Conventional Commits spec.\nBenefits:\nClear structure: see type and scope at a glance Machine-readable: auto changelog generation Easy integration: with semantic-release Alternatives:\nGitmoji (emoji commits) Semantic Versioning (release versioning) FAQ Question Answer Can I mix English and Chinese? Yes, but keep it consistent. Prefer English in the subject. What if one commit covers multiple types? Split into multiple commits. What if I cannot write a long message? At least explain \u0026ldquo;why\u0026rdquo; in one line. Is scope required? Optional, but recommended. Best practices One commit does one thing Subject in lowercase, no period First line \u0026lt;= 50 characters Blank line after subject, details start on line 3 Start with a verb (add, fix, update) Conclusion Commit conventions are a small investment with big returns: better history, smoother collaboration, and automation.\nReferences Conventional Commits Angular Commit Message Guidelines semantic-release Gitmoji Meta Reading time: about 6 minutes Tags: Git, standards, Conventional Commits, collaboration SEO keywords: Git commit conventions, Conventional Commits, feat fix refactor, best practices Meta description: A practical guide to writing clean commit messages with feat: and fix: and enabling automation. Call to Action (CTA) Try this in your next commit:\ngit commit -m \u0026#34;feat: first commit with conventional commits\u0026#34; Share your team conventions and lessons learned in the comments.\n","permalink":"http://localhost:1313/en/notes/git-notes/git-commit-conventions-team-efficiency/","summary":"\u003ch3 id=\"title\"\u003eTitle\u003c/h3\u003e\n\u003cp\u003eFrom \u003ccode\u003efeat\u003c/code\u003e to \u003ccode\u003efix\u003c/code\u003e: master Git commit conventions for collaboration and automation\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"subtitle--abstract\"\u003eSubtitle / Abstract\u003c/h3\u003e\n\u003cp\u003eA practical guide to Conventional Commits. Learn commit types (\u003ccode\u003efeat:\u003c/code\u003e, \u003ccode\u003efix:\u003c/code\u003e), write clean messages, and enable automatic changelogs and releases.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"target-readers\"\u003eTarget readers\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBeginners\u003c/strong\u003e: new to Git, want better commit habits.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMid-level devs\u003c/strong\u003e: want commits friendly to team and CI.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLeads/architects\u003c/strong\u003e: want a consistent team standard.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch3 id=\"background--motivation\"\u003eBackground / Motivation\u003c/h3\u003e\n\u003cp\u003eMost commit messages look like:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;update code\u0026rdquo;\n\u0026ldquo;fix bug\u0026rdquo;\n\u0026ldquo;some changes\u0026rdquo;\u003c/p\u003e","title":"Conventional Commits: Make Team Collaboration and Automation Efficient"},{"content":"Bengio-style ML Task Specification: From Research to Engineering Subtitle: How to write a reproducible, explainable, and comparable fine-tuning task document based on Yoshua Bengio\u0026rsquo;s methodology.\nReading time: 10 minutes Tags: ML documentation, fine-tuning, technical standards, deep learning practice Audience: mid to senior ML engineers, researchers, technical writers\n1. Why do we need this document? In ML projects, teams often run fine-tuning experiments. Months later, nobody can reproduce results or explain why a learning rate or LoRA layer was chosen.\nYoshua Bengio (one of the deep learning pioneers) proposed the idea that an ML task document must allow others to fully reproduce results and understand the design rationale. This became the Bengio-style ML project report structure, used by Google Research, Meta AI, OpenAI, and others.\n2. Core ideas of the Bengio template Item Description Source Yoshua Bengio, \u0026ldquo;Deep Learning Research Practice Notes\u0026rdquo; Goal Ensure ML experiments are reproducible, understandable, and comparable Use cases Fine-tuning, comparison studies, research reports, internal docs Benefits Clear structure, unified format, easy to convert into papers or internal whitepapers 3. Standard structure (nine sections) 1) Title page Document title (e.g., \u0026ldquo;Design and Implementation of Four Fine-Tuning Tasks\u0026rdquo;) Author, date, version Project or organization name 2) Abstract Briefly describe goals, model direction, and expected outcomes.\nExample:\nThis document describes the design, experiment plan, and evaluation for fine-tuning four architectures, comparing performance on a specific dataset.\n3) Background and motivation Explain:\ncurrent system limitations why fine-tuning is needed related papers and existing results scientific or business motivation Example: \u0026ldquo;Current LMs generalize poorly in low-resource domains, so we propose parameter-efficient fine-tuning on multilingual data.\u0026rdquo;\n4) Problem definition Define inputs/outputs, task type, and metrics:\nTask type: classification / generation / regression I/O format: text -\u0026gt; label or text -\u0026gt; text Metrics: accuracy, F1, BLEU, loss Constraints: compute budget, time, data privacy 5) Models and approach For each model, record:\narchitecture (Llama-3, Phi-3, Gemma, etc.) fine-tuning method (Full FT, LoRA, Adapter, QLoRA) key hyperparameters (batch size, epochs, LR) Model Method Dataset Epochs Learning Rate Model A LoRA Dataset X 5 3e-5 Model B Full Dataset X 3 2e-5 Model C Adapter Dataset Y 10 1e-4 Model D QLoRA Dataset Z 4 1e-5 6) Experimental setup Environment (GPU type, framework, version) Data split (train/val/test) Random seeds and reproducibility controls Logging tools (e.g., Weights \u0026amp; Biases) 7) Results and analysis Include:\nmetric tables and plots (accuracy, loss curves) model size vs performance trade-offs unexpected results and explanations Tip: include TensorBoard or matplotlib plots to show convergence trends.\n8) Conclusion and future work Which model performed best? Why (architecture, optimization)? Future directions (multi-task learning, quantization) 9) Appendix and references additional logs and code paths cited papers and open-source repos 4. Best practices Ensure reproducibility (version lock + seeds) Record motivation and assumptions per model Use tables/plots for comparability Use structured headings for team sharing and future papers 5. Summary The Bengio-style ML document is not just a format, it is a research culture. It makes collaboration transparent and results verifiable.\nReferences Yoshua Bengio, Deep Learning Research Practice Notes OpenAI Technical Reports (fine-tuning guides) Google Research: Effective ML Experiment Documentation Meta AI: Reproducibility Checklist for ML Models Call to Action Try writing your next fine-tuning report using this template. Use it as a team standard and improve reproducibility.\n","permalink":"http://localhost:1313/en/thoughts/thoughts/how-to-write-a-perfect-ml-document/","summary":"\u003ch1 id=\"bengio-style-ml-task-specification-from-research-to-engineering\"\u003eBengio-style ML Task Specification: From Research to Engineering\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eSubtitle:\u003c/strong\u003e\nHow to write a reproducible, explainable, and comparable fine-tuning task document based on Yoshua Bengio\u0026rsquo;s methodology.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReading time:\u003c/strong\u003e 10 minutes\n\u003cstrong\u003eTags:\u003c/strong\u003e ML documentation, fine-tuning, technical standards, deep learning practice\n\u003cstrong\u003eAudience:\u003c/strong\u003e mid to senior ML engineers, researchers, technical writers\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-why-do-we-need-this-document\"\u003e1. Why do we need this document?\u003c/h2\u003e\n\u003cp\u003eIn ML projects, teams often run fine-tuning experiments. Months later, nobody can reproduce results or explain why a learning rate or LoRA layer was chosen.\u003c/p\u003e","title":"How to Write a Perfect Machine Learning Document"},{"content":"Ping Works but SSH Fails: A Real Case of SSH vs VNC Subtitle: From connection refusal to protocol identification: understand TCP, SSH, and VNC Reading time: 7 minutes Tags: network troubleshooting, SSH, VNC, Linux, remote access SEO keywords: SSH connection failed, kex_exchange_identification, VNC port 5905, RFB 003.008, SSH vs VNC\nTarget readers Linux users, developers, and server admins Engineers learning systematic network troubleshooting Readers interested in SSH/VNC protocol behavior Background and motivation Have you seen this?\n\u0026ldquo;The server can be pinged, but SSH does not connect.\u0026rdquo;\nThis is common on hosts running multiple services (SSH, VNC, HTTP). This article walks through a real case: from \u0026ldquo;SSH failed\u0026rdquo; to finding out the port was actually VNC.\nSymptoms Command:\nssh chenhm@101.6.142.82 -p 5905 Output:\nkex_exchange_identification: Connection closed by remote host Connection closed by 101.6.142.82 port 5905 Ping test:\nping 101.6.142.82 It succeeds with no packet loss.\nSo we know:\nHost is online Network is reachable SSH handshake failed Core concepts Concept Meaning Ping ICMP test for connectivity only TCP Transport protocol that builds connections SSH Application protocol on top of TCP for secure login VNC / RFB Remote desktop protocol (Remote Frame Buffer) In short: Ping OK != SSH OK because they are different layers.\nTroubleshooting steps Step 1. Test TCP connectivity telnet 101.6.142.82 5905 Output:\nTrying 101.6.142.82... Connected to 101.6.142.82. Escape character is \u0026#39;^]\u0026#39;. RFB 003.008 Key clue: RFB 003.008 is the VNC handshake string (Remote Frame Buffer v3.8).\nThis means:\nPort 5905 is open It is running VNC, not SSH Why this happens After TCP connects, SSH sends a greeting like SSH-2.0-OpenSSH_8.x. A VNC server replies with RFB 003.008 instead. Protocol mismatch causes the SSH client to close, resulting in kex_exchange_identification.\nVerification Check the process on the port sudo ss -tlnp | grep 5905 Possible output:\nLISTEN 0 5 0.0.0.0:5905 ... /usr/bin/Xvnc Check SSH port sudo grep ^Port /etc/ssh/sshd_config If it returns Port 22, SSH is still on the default port.\nCorrect connection If you want the GUI Use a VNC client:\nvncviewer 101.6.142.82:5905 Or tools like:\nRealVNC TigerVNC TightVNC If you want the terminal Use SSH on the correct port:\nssh chenhm@101.6.142.82 -p 22 Common issues and fixes Problem Cause Fix Connection closed by remote host Protocol mismatch (SSH to VNC) Use the correct protocol SSH fails on all ports SSH service not running sudo systemctl start sshd VNC refused Firewall blocked firewall-cmd --add-port=5905/tcp --permanent SSH disconnected fail2ban ban check /var/log/auth.log Best practices Separate port and protocol: port number alone does not identify service type. Use telnet or nc to read protocol banners. Check logs: journalctl -u ssh, /var/log/auth.log. Define a clear port map for multi-service hosts: SSH -\u0026gt; 22 VNC -\u0026gt; 5900+ HTTP -\u0026gt; 80/8080 HTTPS -\u0026gt; 443 Summary This case shows:\nHow to separate network, transport, and application layer issues How to identify protocol banners (RFB vs SSH) How to find the real service on a port One-line conclusion:\nSSH is fine; you connected to the wrong service.\nReferences OpenSSH Manual TigerVNC GitHub [Linux man pages: ssh, telnet, ss, netstat] RFC 6143: The Remote Framebuffer Protocol (RFB) Call to Action Try this on your own server:\nnc \u0026lt;server_ip\u0026gt; \u0026lt;port\u0026gt; Check the banner you get back. You may discover more \u0026ldquo;hidden services\u0026rdquo;.\n","permalink":"http://localhost:1313/en/linux/linux/ping-works-ssh-fails-fake-ssh-true-vnc/","summary":"\u003ch1 id=\"ping-works-but-ssh-fails-a-real-case-of-ssh-vs-vnc\"\u003ePing Works but SSH Fails: A Real Case of SSH vs VNC\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eSubtitle:\u003c/strong\u003e From connection refusal to protocol identification: understand TCP, SSH, and VNC\n\u003cstrong\u003eReading time:\u003c/strong\u003e 7 minutes\n\u003cstrong\u003eTags:\u003c/strong\u003e network troubleshooting, SSH, VNC, Linux, remote access\n\u003cstrong\u003eSEO keywords:\u003c/strong\u003e SSH connection failed, kex_exchange_identification, VNC port 5905, RFB 003.008, SSH vs VNC\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2 id=\"target-readers\"\u003eTarget readers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eLinux users, developers, and server admins\u003c/li\u003e\n\u003cli\u003eEngineers learning systematic network troubleshooting\u003c/li\u003e\n\u003cli\u003eReaders interested in SSH/VNC protocol behavior\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"background-and-motivation\"\u003eBackground and motivation\u003c/h2\u003e\n\u003cp\u003eHave you seen this?\u003c/p\u003e","title":"Ping Works but SSH Fails: A Real Case of SSH vs VNC"},{"content":"Below is a full draft based on your SSH startup and debugging process. It is ready for publication on a technical blog.\nRun SSH Without sudo on Linux (User-Level sshd Guide) Subtitle / Abstract: When you have no root access in a lab or restricted server environment, how do you start SSH and access your account remotely? This guide shows how to run sshd in your user directory, enable key login, and connect remotely.\nReading time: 10 minutes Target readers: intermediate Linux users, researchers, server users, DevOps learners Tags: SSH, sshd, Linux, remote access, non-root, system config SEO keywords: SSH without root, user-level sshd, openssh config, unprivileged ports, remote login failed\nBackground and motivation Many research servers and shared hosts do not grant sudo. But we still need:\nremote login file upload/download access from another machine By default, sshd requires root because it binds port 22 and reads system auth info. However, you can run a user-level SSH service in your home directory without changing system config.\nCore concepts Term Meaning sshd SSH server daemon that accepts connections user-space sshd sshd started by a normal user, no root privileges HostKey key pair used to encrypt SSH connections AuthorizedKeys list of public keys allowed to log in /etc/shadow password hash file; non-root cannot read Step-by-step: Start user-level SSH Step 1: Prepare config Create directory:\nmkdir -p ~/.ssh Create config ~/.ssh/ssh_config:\nPort 2222 ListenAddress 0.0.0.0 HostKey /home/\u0026lt;username\u0026gt;/.ssh/ssh_host_ed25519_key AuthorizedKeysFile /home/\u0026lt;username\u0026gt;/.ssh/authorized_keys PasswordAuthentication yes PubkeyAuthentication yes ChallengeResponseAuthentication no PidFile /home/\u0026lt;username\u0026gt;/.ssh/sshd.pid Note: do not use ~ in paths; OpenSSH will not expand it.\nStep 2: Generate host keys ssh-keygen -t ed25519 -f ~/.ssh/ssh_host_ed25519_key -N \u0026#34;\u0026#34; chmod 600 ~/.ssh/ssh_host_ed25519_key Step 3: Start user-level sshd /usr/bin/sshd -d -f ~/.ssh/ssh_config If you see:\nServer listening on 0.0.0.0 port 2222. then it is running. Test locally:\nssh -p 2222 \u0026lt;username\u0026gt;@localhost Explanation Why use port 2222? Ports \u0026lt; 1024 are privileged and require root. Use 2222 or 8022 instead.\nWhy \u0026ldquo;Could not get shadow information\u0026rdquo;? Non-root users cannot read /etc/shadow, so password auth fails. Use public keys instead.\nUse SSH key login (recommended) Generate local key (no email comment):\nssh-keygen -t ed25519 -C \u0026#34;\u0026#34; -f ~/.ssh/id_ed25519_noemail Add to authorized keys:\ncat ~/.ssh/id_ed25519_noemail.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys Test login:\nssh -i ~/.ssh/id_ed25519_noemail -p 2222 \u0026lt;username\u0026gt;@localhost Allow remote access Ensure sshd listens on all addresses\nss -tlnp | grep 2222 If output is 127.0.0.1:2222, it is local only. Set:\nListenAddress 0.0.0.0 and restart sshd.\nFirewall and NAT\nIf external access shows \u0026ldquo;Connection refused\u0026rdquo;, firewall or NAT is blocking. If localhost works but public IP fails, open the port or configure forwarding. Run sshd in background\nnohup /usr/bin/sshd -f ~/.ssh/ssh_config -E ~/.ssh/sshd.log \u0026amp; tail -f ~/.ssh/sshd.log Common issues Issue Cause Fix Permission denied (password) cannot read /etc/shadow use key auth Address already in use port in use kill old process or change port Bind to port failed tried port 22 use port \u0026gt; 1024 Connection refused firewall / NAT block check listen address and policies Could not load host key HostKey path wrong use absolute path and chmod 600 Best practices Use ed25519 keys (secure and fast). In non-root environments, use key-only auth. Keep ~/.ssh at 700 and authorized_keys at 600. Do not expose your home directory or host keys. If remote access is needed, ensure ListenAddress 0.0.0.0 and open ports. Summary This guide shows how to:\nStart SSH without sudo Enable key auth to avoid /etc/shadow Support both local and remote login Debug common errors like \u0026ldquo;Connection refused\u0026rdquo; You can now run your own SSH service under a normal account.\nReferences OpenSSH manual man sshd_config RFC 4251: The Secure Shell Protocol Architecture Linux file permissions Call to Action (CTA) Try starting your own user-level sshd using the steps above. Save and share this guide for restricted environments. Share your SSH deployment pitfalls and fixes. Do you want a Markdown version with syntax highlighting ready for publishing?\n","permalink":"http://localhost:1313/en/linux/linux/enable-ssh-without-sudo/","summary":"\u003cp\u003eBelow is a full draft based on your SSH startup and debugging process. It is ready for publication on a technical blog.\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"run-ssh-without-sudo-on-linux-user-level-sshd-guide\"\u003eRun SSH Without sudo on Linux (User-Level sshd Guide)\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eSubtitle / Abstract:\u003c/strong\u003e\nWhen you have no root access in a lab or restricted server environment, how do you start SSH and access your account remotely? This guide shows how to run \u003ccode\u003esshd\u003c/code\u003e in your user directory, enable key login, and connect remotely.\u003c/p\u003e","title":"Run SSH Without sudo: User-Level sshd on Linux"},{"content":"Title: Run sshd Without sudo: Troubleshooting, nohup, and systemd (User-Level SSH)\nSubtitle / Abstract: How to run OpenSSH as a normal user, solve common errors like \u0026ldquo;connection refused\u0026rdquo;, \u0026ldquo;password auth failed\u0026rdquo;, and start-limit-hit, and keep sshd alive using nohup or systemd.\nTarget readers: Intermediate Linux users, researchers on shared servers, and anyone who needs SSH without root.\n1. Background / Motivation In some lab or shared environments, regular users do not have sudo. The default sshd service cannot be started. If you need to:\nremote into your Linux host use VS Code Remote or SCP but cannot change system config then you must run sshd in user space. This introduces issues: port conflicts, firewall rules, auth failures, and start-limit-hit.\n2. Core concepts Term Meaning sshd OpenSSH daemon that handles SSH logins user-level sshd sshd started by a normal user, no root privileges authorized_keys list of allowed public keys nohup run a process detached from the terminal systemd \u0026ndash;user user-level systemd instance for services start-limit-hit systemd pauses restarts after frequent failures 3. Full setup steps 1) Generate and configure SSH keys ssh-keygen -t ed25519 -C \u0026#34;\u0026#34; -f ~/.ssh/id_ed25519_noemail cat ~/.ssh/id_ed25519_noemail.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys Ensure ~/.ssh/authorized_keys permissions are correct.\n2) Create a user-level sshd config ~/.ssh/ssh_config_pub\nPort 2223 ListenAddress 0.0.0.0 HostKey /home/chenhm/.ssh/ssh_host_ed25519_key AuthorizedKeysFile /home/chenhm/.ssh/authorized_keys PasswordAuthentication no PubkeyAuthentication yes PidFile /home/chenhm/.ssh/sshd_pub.pid LogLevel INFO SyslogFacility AUTH Generate host key:\nssh-keygen -t ed25519 -f ~/.ssh/ssh_host_ed25519_key -N \u0026#34;\u0026#34; 3) Start in debug mode /usr/bin/sshd -d -f ~/.ssh/ssh_config_pub If you see:\nServer listening on 0.0.0.0 port 2223\nthen it is running.\n4. Two ways to keep it running Option A: nohup (simplest) nohup /usr/bin/sshd -f ~/.ssh/ssh_config_pub -E ~/.ssh/sshd_pub.log \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp; Runs after terminal closes\nCheck process:\nps -ef | grep \u0026#34;sshd -f\u0026#34; Check logs:\ntail -f ~/.ssh/sshd_pub.log Stop:\npkill -f \u0026#34;sshd -f /home/chenhm/.ssh/ssh_config_pub\u0026#34; Pros: no dependencies, works instantly. Cons: does not auto-start after reboot.\nOption B: systemd user service (auto-restart/auto-start) 1) Create the unit file ~/.config/systemd/user/sshd-user.service\n[Unit] Description=User-level SSH server [Service] Type=forking ExecStart=/usr/bin/sshd -f /home/chenhm/.ssh/ssh_config_pub -E /home/chenhm/.ssh/sshd_pub.log PIDFile=/home/chenhm/.ssh/sshd_pub.pid Restart=on-failure RestartSec=5 [Install] WantedBy=default.target 2) Enable and start systemctl --user daemon-reload systemctl --user enable sshd-user systemctl --user start sshd-user 3) Verify systemctl --user status sshd-user ss -tlnp | grep sshd You should see Active: active (running) and 0.0.0.0:2223.\n5. Troubleshooting table Error Cause Fix Connection refused sshd not listening on public interface or firewall blocked set ListenAddress 0.0.0.0, check ss -tlnp Permission denied (password) no access to /etc/shadow use public key auth Bind to port ... failed: Address already in use port already used by old sshd pkill -f \u0026quot;sshd -f\u0026quot; start-limit-hit systemd sees frequent crashes set Type=forking and PIDFile= No logs wrong path or permission use -E ~/.ssh/sshd.log 6. Why this works User-level sshd does not need root because it binds to ports \u0026gt;= 1024. Public key auth avoids /etc/shadow access. Type=forking lets systemd track the daemon correctly. PIDFile helps systemd manage the process. 7. Notes Port \u0026gt; 1024: non-root cannot bind to privileged ports. Firewall: must allow your chosen port. Permissions: ~/.ssh must be 700 and authorized_keys must be 600. Multiple instances: use separate PidFile and log paths. Auto-start: systemctl --user enable sshd-user. 8. Best practices Use nohup for testing or temporary runs. Use systemd \u0026ndash;user for stable long-term service. Expose only key-based auth on public interfaces. Separate internal vs external ports. Use @reboot cron as fallback if systemd is unavailable. 9. Conclusion This guide showed how to deploy SSH without sudo:\nGenerate keys and enable key auth Create user-level sshd config Validate with nohup, then stabilize with systemd Fix start-limit-hit, port conflicts, and auth failures You get:\nMultiple ports and instances Auto-restart Auto-start Secure remote access References OpenSSH manual systemd user services OpenSSH key management Meta\nReading time: about 10 minutes Tags: SSH, Linux, systemd, nohup, no-sudo SEO keywords: no-sudo sshd systemd user OpenSSH start-limit-hit Meta description: A complete guide to running OpenSSH without sudo and fixing common startup errors. Call to Action (CTA) Try running a user-level sshd on your lab server. If this helps, share your setup and lessons learned.\n","permalink":"http://localhost:1313/en/linux/linux/fix-sshsystem-process-start-failure/","summary":"\u003cp\u003e\u003cstrong\u003eTitle:\u003c/strong\u003e\nRun sshd Without sudo: Troubleshooting, nohup, and systemd (User-Level SSH)\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSubtitle / Abstract:\u003c/strong\u003e\nHow to run OpenSSH as a normal user, solve common errors like \u0026ldquo;connection refused\u0026rdquo;, \u0026ldquo;password auth failed\u0026rdquo;, and \u003ccode\u003estart-limit-hit\u003c/code\u003e, and keep sshd alive using nohup or systemd.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTarget readers:\u003c/strong\u003e\nIntermediate Linux users, researchers on shared servers, and anyone who needs SSH without root.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-background--motivation\"\u003e1. Background / Motivation\u003c/h2\u003e\n\u003cp\u003eIn some lab or shared environments, regular users do not have sudo. The default sshd service cannot be started. If you need to:\u003c/p\u003e","title":"Run sshd Without sudo: Troubleshooting and Persistent User-Level SSH"},{"content":"Auto-start frp on Ubuntu: A Complete Guide Subtitle / Abstract Use systemd to run frp (Fast Reverse Proxy) as a managed service for stable, secure, and monitored auto-start on boot.\nReading time: 8 minutes Tags: frp, intranet tunneling, systemd, auto-start, Linux, Ubuntu SEO keywords: frp auto start, Ubuntu frp config, frpc systemd, frps service, intranet tunneling Meta description: Step-by-step systemd setup for frp (frpc/frps) with config templates and troubleshooting.\nTarget readers Developers deploying frps on cloud servers Intermediate Linux users building stable home/office tunnels DevOps and self-hosting enthusiasts Background and motivation Many developers use frp to expose internal services (SSH, web, NAS) to the internet. The problem is that running ./frpc -c frpc.ini manually is inconvenient and unreliable after reboot.\nWe want auto-start on boot + auto-restart on failure + centralized logs, which is exactly what systemd provides.\nCore concepts frps / frpc: server and client binaries for frp systemd: service manager for modern Linux unit file: configuration for service startup, dependencies, and restart policy Step-by-step setup 1) Install and place files sudo mv frpc /usr/local/bin/ sudo chmod +x /usr/local/bin/frpc sudo mkdir -p /etc/frp sudo mv frpc.ini /etc/frp/frpc.ini For the server side, replace frpc with frps and frpc.ini with frps.ini.\n2) (Optional) Create a dedicated user sudo useradd --system --no-create-home --shell /sbin/nologin frp sudo chown -R frp:frp /etc/frp 3) Create a systemd unit Create /etc/systemd/system/frpc.service:\n[Unit] Description=frp client service After=network-online.target Wants=network-online.target [Service] Type=simple User=frp Group=frp ExecStart=/usr/local/bin/frpc -c /etc/frp/frpc.ini Restart=on-failure RestartSec=5 LimitNOFILE=65536 [Install] WantedBy=multi-user.target 4) Start and enable sudo systemctl daemon-reload sudo systemctl start frpc sudo systemctl enable frpc 5) Check status and logs sudo systemctl status frpc sudo journalctl -u frpc -f Logs are centralized in the systemd journal for easier troubleshooting.\nHow it works WantedBy=multi-user.target ensures auto-start during boot. After=network-online.target starts only after the network is ready. Restart=on-failure auto-restarts frpc on unexpected exit. Compared to @reboot cron, systemd gives better dependency control, restart policy, and unified logs.\nCommon issues and fixes Issue Cause Fix Service fails to start Config file permission issue Ensure /etc/frp/frpc.ini is readable by user frp Network not ready Missing systemd dependencies Enable systemd-networkd-wait-online.service frp cannot connect Firewall or security group blocks Open TCP/UDP ports Service not auto-starting enable not run sudo systemctl enable frpc Best practices Run with non-root user for safety. Ship logs to ELK/Promtail if needed. Enable token auth or TLS in frp configs. For multiple frpc instances, use frpc@name.service templates. Summary You learned how to:\nInstall and configure frp Create a systemd service Enable auto-start and auto-restart Understand common pitfalls Once you understand systemd, you can manage any custom daemon the same way.\nReferences frp docs: https://github.com/fatedier/frp systemd.service: https://www.freedesktop.org/software/systemd/man/systemd.service.html Ubuntu Server Guide - systemd: https://ubuntu.com/server/docs/service-systemd Call to Action Copy the unit file to your server and run sudo systemctl enable --now frpc. If it works, share what you are exposing via frp. You can also publish a template or script for others.\n","permalink":"http://localhost:1313/en/linux/linux/frp-auto-start-on-ubuntu/","summary":"\u003ch1 id=\"auto-start-frp-on-ubuntu-a-complete-guide\"\u003eAuto-start frp on Ubuntu: A Complete Guide\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eSubtitle / Abstract\u003c/strong\u003e\nUse systemd to run frp (Fast Reverse Proxy) as a managed service for stable, secure, and monitored auto-start on boot.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReading time\u003c/strong\u003e: 8 minutes\n\u003cstrong\u003eTags\u003c/strong\u003e: frp, intranet tunneling, systemd, auto-start, Linux, Ubuntu\n\u003cstrong\u003eSEO keywords\u003c/strong\u003e: frp auto start, Ubuntu frp config, frpc systemd, frps service, intranet tunneling\n\u003cstrong\u003eMeta description\u003c/strong\u003e: Step-by-step systemd setup for frp (frpc/frps) with config templates and troubleshooting.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"target-readers\"\u003eTarget readers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eDevelopers deploying frps on cloud servers\u003c/li\u003e\n\u003cli\u003eIntermediate Linux users building stable home/office tunnels\u003c/li\u003e\n\u003cli\u003eDevOps and self-hosting enthusiasts\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"background-and-motivation\"\u003eBackground and motivation\u003c/h2\u003e\n\u003cp\u003eMany developers use \u003cstrong\u003efrp\u003c/strong\u003e to expose internal services (SSH, web, NAS) to the internet. The problem is that running \u003ccode\u003e./frpc -c frpc.ini\u003c/code\u003e manually is inconvenient and unreliable after reboot.\u003c/p\u003e","title":"Auto-start frp on Ubuntu with systemd"},{"content":"Windows + WSL2 Port Forwarding Guide (Access Flask 5000) Prerequisites You are using WSL2 (Ubuntu or another Linux distro) The Windows host can access the LAN (Wi-Fi or Ethernet) A Flask service is running inside WSL2 and listening on: app.run(host=\u0026#34;0.0.0.0\u0026#34;, port=5000) host=\u0026quot;0.0.0.0\u0026quot; is required; otherwise external access will fail.\nStep 1: Check the WSL2 IP In WSL2:\nip addr show eth0 You should see something like:\ninet 172.26.209.37/20 Record the IP after inet (here: 172.26.209.37). This is the WSL2 internal IP.\nStep 2: Open PowerShell (Admin) Press Win + X and select Windows PowerShell (Admin) Confirm admin privileges if prompted by UAC Step 3: Add Port Forwarding In PowerShell, forward Windows port 5000 to WSL2:\n# Forward Windows port 5000 to WSL2 port 5000 netsh interface portproxy add v4tov4 listenport=5000 listenaddress=0.0.0.0 connectport=5000 connectaddress=172.26.209.37 # Allow LAN access through the firewall netsh advfirewall firewall add rule name=\u0026#34;WSL Flask 5000\u0026#34; dir=in action=allow protocol=TCP localport=5000 listenaddress=0.0.0.0 listens on all Windows interfaces connectaddress=172.26.209.37 is the WSL2 internal IP The firewall rule allows LAN devices to access Windows port 5000 Step 4: Test the Forwarding On the Windows machine: curl http://localhost:5000 # or curl http://192.168.1.227:5000 From another LAN device: http://\u0026lt;Windows-LAN-IP\u0026gt;:5000 Example:\nhttp://192.168.1.227:5000 Step 5 (Optional): Auto-update Script WSL2 IP can change after reboot. You can create a PowerShell script wsl_port_forward.ps1 to update rules:\n# Get current WSL IP $wsl_ip = wsl hostname -I | ForEach-Object { $_.Split(\u0026#34; \u0026#34;)[0] } Write-Host \u0026#34;Detected WSL IP: $wsl_ip\u0026#34; # Remove old rule netsh interface portproxy delete v4tov4 listenport=5000 listenaddress=0.0.0.0 # Add new rule netsh interface portproxy add v4tov4 listenport=5000 listenaddress=0.0.0.0 connectport=5000 connectaddress=$wsl_ip # Allow firewall netsh advfirewall firewall add rule name=\u0026#34;WSL Flask 5000\u0026#34; dir=in action=allow protocol=TCP localport=5000 Run this script before starting WSL each time It detects the current WSL IP and updates the forwarding rule Step 6: Notes Flask must listen on 0.0.0.0, otherwise only local access works Ensure Windows Firewall allows TCP port 5000 If LAN devices still cannot access: Check router policies for blocked LAN ports Verify Windows firewall rules WSL2 uses NAT; LAN devices cannot reach the WSL IP directly. Use Windows IP + port forwarding Summary WSL2 networking is isolated by default; LAN cannot access WSL directly Windows port forwarding + firewall rules enable LAN access to WSL services An auto-update script can handle WSL IP changes after reboot ","permalink":"http://localhost:1313/en/linux/linux/wsl-intranet-not-shared-with-windows/","summary":"\u003ch1 id=\"windows--wsl2-port-forwarding-guide-access-flask-5000\"\u003eWindows + WSL2 Port Forwarding Guide (Access Flask 5000)\u003c/h1\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eYou are using \u003cstrong\u003eWSL2\u003c/strong\u003e (Ubuntu or another Linux distro)\u003c/li\u003e\n\u003cli\u003eThe Windows host can access the LAN (Wi-Fi or Ethernet)\u003c/li\u003e\n\u003cli\u003eA Flask service is running inside WSL2 and listening on:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eapp\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erun(host\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;0.0.0.0\u0026#34;\u003c/span\u003e, port\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e5000\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cblockquote\u003e\n\u003cp\u003e\u003ccode\u003ehost=\u0026quot;0.0.0.0\u0026quot;\u003c/code\u003e is required; otherwise external access will fail.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-1-check-the-wsl2-ip\"\u003eStep 1: Check the WSL2 IP\u003c/h2\u003e\n\u003cp\u003eIn WSL2:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eip addr show eth0\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eYou should see something like:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003einet 172.26.209.37/20\n\u003c/code\u003e\u003c/pre\u003e\u003cblockquote\u003e\n\u003cp\u003eRecord the IP after \u003ccode\u003einet\u003c/code\u003e (here: \u003ccode\u003e172.26.209.37\u003c/code\u003e). This is the WSL2 internal IP.\u003c/p\u003e","title":"Expose WSL2 Services to the LAN via Windows Port Forwarding"},{"content":"Load Testing APIs with wrk (Detailed Guide) This article explains how to use wrk on Ubuntu to stress-test backend APIs (Flask, FastAPI, Spring Boot, etc.) and interpret the results.\n1. What is wrk? wrk is a modern, high-performance HTTP benchmarking tool written in C. Key features:\nHigh concurrency: thousands of concurrent connections Multi-threaded: uses multiple CPU cores Lua scripting: for custom headers, bodies, tokens Faster than Apache Benchmark (ab): lighter and more stable 2. Install wrk On Ubuntu/Debian:\nsudo apt update sudo apt install wrk -y Verify:\nwrk --version Expected output:\nwrk 4.2.0 [epoll] 3. Quick start Suppose your service is at:\nhttp://192.168.1.224:5000/api/tenders Run:\nwrk -t4 -c100 -d30s http://192.168.1.224:5000/api/tenders Parameters Flag Meaning -t4 4 threads (use multi-core CPU) -c100 100 concurrent connections -d30s 30 seconds duration last arg target URL 4. Sample output explained Example output:\nRunning 30s test @ http://192.168.1.224:5000/api/tenders 4 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 1.12s 248.83ms 1.99s 85.59% Req/Sec 22.88 14.29 90.00 77.73% 2452 requests in 30.09s, 27.02MB read Socket errors: connect 0, read 0, write 0, timeout 2 Requests/sec: 81.49 Transfer/sec: 0.90MB Metrics Metric Meaning Example Notes Latency Average response time 1.12s Slow if \u0026gt; 1s Req/Sec Requests per thread per second 22.88 Depends on thread count Requests/sec Total QPS 81.49 Throughput Transfer/sec Data per second 0.90MB Bandwidth usage Timeouts Timed-out requests 2 Indicates delays In general:\nExcellent: latency \u0026lt; 200ms OK: 200-800ms Slow: \u0026gt; 1s 5. Tips to improve concurrency 1) Use a production server (Flask example) Do not use app.run(). Use Gunicorn:\npip install gunicorn gunicorn -w 4 -b 0.0.0.0:5000 run:app -w 4: 4 worker processes (recommended 2 * CPU + 1) Improves concurrency and stability 2) Increase async throughput (I/O-bound APIs) gunicorn -w 4 -k gevent -b 0.0.0.0:5000 run:app -k gevent uses async workers to handle many waiting requests.\n3) Reduce response size Large responses consume network bandwidth. Suggestions:\nReturn only required fields Enable gzip (Nginx or Flask plugins) 6. Advanced: Lua scripts for custom requests Lua scripts can do:\nCustom headers and tokens POST JSON bodies Randomized parameters Example post.lua:\nwrk.method = \u0026#34;POST\u0026#34; wrk.body = \u0026#39;{\u0026#34;keyword\u0026#34;:\u0026#34;test\u0026#34;}\u0026#39; wrk.headers[\u0026#34;Content-Type\u0026#34;] = \u0026#34;application/json\u0026#34; Run:\nwrk -t4 -c100 -d30s -s post.lua http://127.0.0.1:5000/api/search ","permalink":"http://localhost:1313/en/linux/linux/wrk-load-testing-guide/","summary":"\u003ch1 id=\"load-testing-apis-with-wrk-detailed-guide\"\u003eLoad Testing APIs with wrk (Detailed Guide)\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThis article explains how to use \u003ccode\u003ewrk\u003c/code\u003e on Ubuntu to stress-test backend APIs (Flask, FastAPI, Spring Boot, etc.) and interpret the results.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-what-is-wrk\"\u003e1. What is wrk?\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/wg/wrk\"\u003e\u003ccode\u003ewrk\u003c/code\u003e\u003c/a\u003e is a modern, high-performance HTTP benchmarking tool written in C. Key features:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eHigh concurrency\u003c/strong\u003e: thousands of concurrent connections\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMulti-threaded\u003c/strong\u003e: uses multiple CPU cores\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLua scripting\u003c/strong\u003e: for custom headers, bodies, tokens\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFaster than Apache Benchmark (ab)\u003c/strong\u003e: lighter and more stable\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-install-wrk\"\u003e2. Install wrk\u003c/h2\u003e\n\u003cp\u003eOn Ubuntu/Debian:\u003c/p\u003e","title":"How to Use wrk for Load Testing"},{"content":"Access a Git Bare Repo on Windows WSL2 from the LAN In development, you often need to share Git repositories across multiple machines. If you use WSL2 on Windows and want other LAN machines to access a Git bare repo inside WSL2, this guide walks you through the setup.\n1. Create a Git bare repo in WSL2 In WSL2, go to the target directory:\ngit init --bare my_project.git my_project.git is a bare repo with no working tree, only Git data. A bare repo behaves like a remote and can be cloned and pushed. 2. Enable SSH in WSL2 Other machines will access via SSH.\nInstall SSH server: sudo apt update sudo apt install openssh-server -y Start SSH: sudo service ssh start Check status: sudo service ssh status Default port is 22; you can change it in /etc/ssh/sshd_config. 3. Get the WSL2 IP In WSL2:\nip addr Find the inet under eth0, for example:\ninet 172.25.190.21/20 Note: WSL2 IP can change after reboot.\n4. Configure Windows Firewall Allow SSH port through firewall:\nWindows Firewall -\u0026gt; Advanced settings -\u0026gt; Inbound rules -\u0026gt; New rule Rule type: Port -\u0026gt; TCP -\u0026gt; Port 22 (or custom like 2222) Allow connection -\u0026gt; Apply to Domain/Private/Public Name the rule and finish 5. Recommended: Windows port forwarding Because WSL2 IP changes, use Windows port forwarding:\nOpen PowerShell (Admin): netsh interface portproxy add v4tov4 listenport=2222 listenaddress=0.0.0.0 connectport=22 connectaddress=\u0026lt;WSL_IP\u0026gt; From another LAN machine, access via Windows IP + 2222: git clone ssh://user@WINDOWS_IP:2222/home/user/my_project.git user is your WSL2 username WINDOWS_IP is the Windows host LAN IP 6. Clone, push, pull from another machine Clone:\ngit clone ssh://user@WINDOWS_IP:2222/home/user/my_project.git Commit and push:\ngit add . git commit -m \u0026#34;update\u0026#34; git push origin main # or master Pull updates:\ngit pull origin main 7. Summary WSL2 has a virtual network; its IP may change on each boot. Port forwarding + firewall rules are the most reliable solution. A bare repo inside WSL2 works like a remote for LAN access. With these steps, multiple LAN machines can access a WSL2 Git repo for easy collaboration.\n","permalink":"http://localhost:1313/en/notes/git-notes/lan-git-bare-repo/","summary":"\u003ch1 id=\"access-a-git-bare-repo-on-windows-wsl2-from-the-lan\"\u003eAccess a Git Bare Repo on Windows WSL2 from the LAN\u003c/h1\u003e\n\u003cp\u003eIn development, you often need to share Git repositories across multiple machines. If you use WSL2 on Windows and want other LAN machines to access a Git bare repo inside WSL2, this guide walks you through the setup.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-create-a-git-bare-repo-in-wsl2\"\u003e1. Create a Git bare repo in WSL2\u003c/h2\u003e\n\u003cp\u003eIn WSL2, go to the target directory:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit init --bare my_project.git\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emy_project.git\u003c/code\u003e is a bare repo with no working tree, only Git data.\u003c/li\u003e\n\u003cli\u003eA bare repo behaves like a remote and can be cloned and pushed.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-enable-ssh-in-wsl2\"\u003e2. Enable SSH in WSL2\u003c/h2\u003e\n\u003cp\u003eOther machines will access via SSH.\u003c/p\u003e","title":"LAN Git Bare on WSL2"},{"content":"Simplified Git Branch Workflow (Solo / Small Team) This workflow is a simplified version of Git Flow. It is suitable for personal projects or small teams: structured but not heavy.\n1. Main branch (long-lived) main Always stable and release-ready Production deployments come from here For small teams, main is usually enough; no need for develop.\n2. Feature development (feature branch) Naming: feature/\u0026lt;feature-name\u0026gt; Purpose: build new features, then merge back to main Examples:\nfeature/login-api feature/user-profile Flow:\n# create feature branch from main git checkout -b feature/login-api main # merge back to main when done git checkout main git merge feature/login-api git branch -d feature/login-api 3. Bug fixes (bugfix branch) Naming: bugfix/\u0026lt;issue-name\u0026gt; Purpose: fix bugs in dev/test Example:\nbugfix/fix-login-redirect Same flow as feature branch, merge back to main.\n4. Hotfixes (hotfix branch) Naming: hotfix/\u0026lt;issue-name\u0026gt; Purpose: urgent production fixes Example:\nhotfix/security-patch Flow:\ngit checkout -b hotfix/security-patch main # fix, commit git checkout main git merge hotfix/security-patch git branch -d hotfix/security-patch 5. Releases (tags) Use Git tags for release versions No dedicated release branch required Example:\ngit tag v1.0.0 git push origin v1.0.0 Minimal recommended rules Permanent branch: main Temporary branches: feature/..., bugfix/..., hotfix/... Use tags for releases, no separate release branch Branch lifecycle diagram gitGraph commit id: \u0026#34;Init main\u0026#34; branch feature/login-api commit id: \u0026#34;Build login API\u0026#34; checkout main merge feature/login-api id: \u0026#34;Merge feature\u0026#34; branch bugfix/fix-redirect commit id: \u0026#34;Fix login redirect\u0026#34; checkout main merge bugfix/fix-redirect id: \u0026#34;Merge bugfix\u0026#34; branch hotfix/security-patch commit id: \u0026#34;Emergency security patch\u0026#34; checkout main merge hotfix/security-patch id: \u0026#34;Merge hotfix\u0026#34; commit id: \u0026#34;Tag v1.0.0\u0026#34; ","permalink":"http://localhost:1313/en/notes/git-notes/git-branching-workflow/","summary":"\u003ch1 id=\"simplified-git-branch-workflow-solo--small-team\"\u003eSimplified Git Branch Workflow (Solo / Small Team)\u003c/h1\u003e\n\u003cp\u003eThis workflow is a simplified version of Git Flow. It is suitable for personal projects or small teams: structured but not heavy.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-main-branch-long-lived\"\u003e1. Main branch (long-lived)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003emain\u003c/code\u003e\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eAlways stable and release-ready\u003c/li\u003e\n\u003cli\u003eProduction deployments come from here\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eFor small teams, \u003ccode\u003emain\u003c/code\u003e is usually enough; no need for \u003ccode\u003edevelop\u003c/code\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-feature-development-feature-branch\"\u003e2. Feature development (feature branch)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eNaming: \u003ccode\u003efeature/\u0026lt;feature-name\u0026gt;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003ePurpose: build new features, then merge back to \u003ccode\u003emain\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eExamples:\u003c/p\u003e","title":"Git Branch Workflow for Small Teams"},{"content":"Use a Local Git Bare Repo to Separate Dev and Test Environments In full-stack work, a common problem is how to isolate dev and test environments. Many people host on GitHub or GitLab, but private projects may not be suitable for public hosting.\nGit is distributed. You can set up a local bare repo as a remote to move code from dev -\u0026gt; test in one machine.\nWhat is a bare repository? A normal repo (git init) has a working tree + .git metadata and can be edited directly. A bare repo (git init --bare) has only Git data, no working tree. It is usually used as a remote. In short:\nDev repo: where you write code Bare repo: remote sync point with full history Test repo: clone from bare repo to simulate deployment Step 1: Create the bare repo Create a bare repo under a local directory (e.g., ~/.repos):\nmkdir -p ~/.repos cd ~/.repos git init --bare scrapy.git Now ~/.repos/scrapy.git is your local remote.\nStep 2: Add the local remote in your dev repo Assume your dev repo is ~/scrapy:\ncd ~/scrapy git remote add local ~/.repos/scrapy.git Check:\ngit remote -v Expected:\nlocal /home/gong/.repos/scrapy.git (fetch) local /home/gong/.repos/scrapy.git (push) Step 3: Push to the local remote Push main:\ngit push local main Your bare repo now contains all commits.\nStep 4: Clone in the test environment Assume your test environment is ~/test-env:\ncd ~/test-env git clone ~/.repos/scrapy.git You now have a clean copy for testing without affecting dev.\nNote on HEAD warning Sometimes you see:\nwarning: remote HEAD refers to nonexistent ref, unable to checkout This happens because a newly created bare repo has no default HEAD. Set it:\ncd ~/.repos/scrapy.git git symbolic-ref HEAD refs/heads/main Then clone again.\nStep 5: Sync workflow In dev (~/scrapy):\ngit add . git commit -m \u0026#34;feat: finish feature\u0026#34; git push local main In test (~/test-env/scrapy):\ngit pull Now you can sync dev -\u0026gt; test easily on one machine.\nSummary If you cannot push to GitHub/GitLab, a local bare repo can separate dev and test:\nno external platform required dev and test isolated full Git history preserved If the project grows, consider a private Git service (Gitea/GitLab CE) or Docker deployment.\n","permalink":"http://localhost:1313/en/notes/git-notes/git-bare-repo-dev-test-isolation/","summary":"\u003ch1 id=\"use-a-local-git-bare-repo-to-separate-dev-and-test-environments\"\u003eUse a Local Git Bare Repo to Separate Dev and Test Environments\u003c/h1\u003e\n\u003cp\u003eIn full-stack work, a common problem is \u003cstrong\u003ehow to isolate dev and test environments\u003c/strong\u003e. Many people host on GitHub or GitLab, but private projects may not be suitable for public hosting.\u003c/p\u003e\n\u003cp\u003eGit is distributed. You can set up a \u003cstrong\u003elocal bare repo\u003c/strong\u003e as a remote to move code from \u003cstrong\u003edev -\u0026gt; test\u003c/strong\u003e in one machine.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"what-is-a-bare-repository\"\u003eWhat is a bare repository?\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eA normal repo (\u003ccode\u003egit init\u003c/code\u003e) has a \u003cstrong\u003eworking tree + .git metadata\u003c/strong\u003e and can be edited directly.\u003c/li\u003e\n\u003cli\u003eA bare repo (\u003ccode\u003egit init --bare\u003c/code\u003e) has only Git data, no working tree. It is usually used as a \u003cstrong\u003eremote\u003c/strong\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn short:\u003c/p\u003e","title":"Use a Local Git Bare Repo to Separate Dev and Test Environments"},{"content":"Introduction For TypeScript files with the .ts extension, we cannot run them directly. We need to transpile TypeScript to JavaScript and then run the JavaScript output.\nThere are two common approaches: upload .ts to the server and compile via CI, or transpile locally and upload the .js build to production. If you want to run and test locally during development, you can use ts-node, but the project still needs a build step for production.\n","permalink":"http://localhost:1313/en/dev/frontend/typescript-setup-guide/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eFor TypeScript files with the \u003ccode\u003e.ts\u003c/code\u003e extension, we cannot run them directly. We need to transpile TypeScript to JavaScript and then run the JavaScript output.\u003c/p\u003e\n\u003cp\u003eThere are two common approaches: upload \u003ccode\u003e.ts\u003c/code\u003e to the server and compile via CI, or transpile locally and upload the \u003ccode\u003e.js\u003c/code\u003e build to production. If you want to run and test locally during development, you can use \u003ccode\u003ets-node\u003c/code\u003e, but the project still needs a build step for production.\u003c/p\u003e","title":"How to Use and Configure a TypeScript Environment"},{"content":"Introduction I want to build an AI system that supports tree-shaped or graph-shaped Q\u0026amp;A, instead of a traditional single-thread chat flow.\nExploration Open-source framework research flowise ","permalink":"http://localhost:1313/en/thoughts/thoughts/ai-assistant-frontend-rebuild-ideas/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eI want to build an AI system that supports tree-shaped or graph-shaped Q\u0026amp;A, instead of a traditional single-thread chat flow.\u003c/p\u003e\n\u003ch1 id=\"exploration\"\u003eExploration\u003c/h1\u003e\n\u003ch2 id=\"open-source-framework-research\"\u003eOpen-source framework research\u003c/h2\u003e\n\u003ch3 id=\"flowise\"\u003eflowise\u003c/h3\u003e","title":"A New Frontend Idea for AI Assistants"},{"content":"Introduction Mermaid is a framework for creating diagrams using code. This post shows how to install the tooling on your server and render Mermaid code into images.\nSteps Install the renderer Run:\nnpm install -g @mermaid-js/mermaid-cli Note: the CLI requires npm version \u0026gt;= 20. It is recommended to manage npm versions with nvm.\nIf you do not have nvm, install it with:\ncurl -o https://raw.githubusercontent.com/nvm-sh/nvim/v0.39.4/install.sh | bash Restart your shell, then run:\nnvm install 20 nvm use 20 nvm alias default 20 Verify:\nnode -v npm -v Render a diagram Put your Mermaid code in a file ending with .mmd, then run:\nmmdc -i diagrams/example.mmd -o images/example.svg ","permalink":"http://localhost:1313/en/linux/linux/create-and-edit-mermaid-diagrams/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eMermaid is a framework for creating diagrams using code. This post shows how to install the tooling on your server and render Mermaid code into images.\u003c/p\u003e\n\u003ch1 id=\"steps\"\u003eSteps\u003c/h1\u003e\n\u003ch2 id=\"install-the-renderer\"\u003eInstall the renderer\u003c/h2\u003e\n\u003cp\u003eRun:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003enpm install -g @mermaid-js/mermaid-cli\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eNote: the CLI requires npm version \u0026gt;= 20. It is recommended to manage npm versions with nvm.\u003c/p\u003e\n\u003cp\u003eIf you do not have nvm, install it with:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ecurl -o https://raw.githubusercontent.com/nvm-sh/nvim/v0.39.4/install.sh | bash\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eRestart your shell, then run:\u003c/p\u003e","title":"How to Create and Edit Mermaid Diagrams"},{"content":"How to Truly Master a Paper Conclusion To truly master a paper, reading once is not enough. You need to decompose, verify, and reconstruct it, and then express the key points in your own words or implementation. The goal: explain the core contribution in 5 minutes, derive key formulas by hand, and reproduce a core experiment.\nPrinciples and background A paper is a compressed expression of a problem. It omits background, intuition, failed attempts, and many details. Mastery requires \u0026ldquo;decompressing\u0026rdquo; that information into your own knowledge network: assumptions, derivations, engineering steps, and the limits of the results. Only then can you judge when to use it and when not to.\nSteps Do not treat a paper as authority. Treat it as a claim you can test. Break the claims into verifiable assertions and test them. Mastery is not memorizing text, but turning it into a tool you can use. Real understanding requires action: derive, implement, compare, explain.\nPreparation and pre-read (30-60 minutes)\nRead title, abstract, conclusion, figures (skip details). Capture what problem it solves and what results it claims. Scan intro and contributions; list 3 key claims. Check references to see if you need to read prerequisites. Deep read (2-6 hours)\nRead methods/theory carefully. Hand-derive key formulas. Create a symbol table; write pseudocode for algorithms. Mark unclear points and create a question list. Decompose and reconstruct (half day to days)\nBreak the paper into: problem, assumptions, method, theorems, experiments, conclusions, limits. Write 2-3 sentences for each section in your own words. Implement a minimal runnable version of the algorithm. Implement and reproduce (hours to days)\nFocus on the part that best reflects the contribution. Debug on small synthetic data, then match paper settings. Suggested environments: Python + Jupyter/Colab, or C++/Rust for systems/perf. Common libraries: numpy/pandas/matplotlib/scikit-learn/torch/tensorflow. Map paper symbols to code variables in comments/docstrings. Plot and compare\nReproduce key plots (loss curves, error tables). If exact numbers are hard, verify trends. Add assertions/unit tests to confirm theory on synthetic cases. Digest and output\nWrite a one-page cheatsheet or short blog; aim for a 5-minute explanation. Create Anki cards for assumptions, theorem conditions, derivation steps. Explain to someone else or write a report. Tools (practical)\nReferences: Zotero / Mendeley Notes: Obsidian / Notion / org-mode Code and experiments: Git + Jupyter/Colab + Docker Text tools: pdftotext, pdfgrep, grep, ripgrep Common mistakes Mistake: only read, never do (no derivation or implementation). Fix: force yourself to implement or write pseudocode and derive key steps. Mistake: ignore assumptions and boundaries. Fix: list all assumptions and test violations. Mistake: equate code with the paper. Fix: read author code and compare with the paper; record differences. Mistake: chase exact numeric reproduction too early. Fix: verify trends first, then refine details. Mistake: accept formulas without checking steps. Fix: derive line by line and track missing lemmas. Verification checklist Explain the core contribution, use cases, and limits in 5 minutes. Derive key formulas or rewrite the proof by hand. Implement a minimal working example that matches paper trends. Answer: what assumptions are critical, and what failure modes exist? Apply the idea to a slightly different problem and observe results. ","permalink":"http://localhost:1313/en/thoughts/thoughts/mastering-paper/","summary":"\u003ch1 id=\"how-to-truly-master-a-paper\"\u003eHow to Truly Master a Paper\u003c/h1\u003e\n\u003ch1 id=\"conclusion\"\u003eConclusion\u003c/h1\u003e\n\u003cp\u003eTo truly master a paper, reading once is not enough. You need to decompose, verify, and reconstruct it, and then express the key points in your own words or implementation. The goal: explain the core contribution in 5 minutes, derive key formulas by hand, and reproduce a core experiment.\u003c/p\u003e\n\u003ch1 id=\"principles-and-background\"\u003ePrinciples and background\u003c/h1\u003e\n\u003cp\u003eA paper is a compressed expression of a problem. It omits background, intuition, failed attempts, and many details. Mastery requires \u0026ldquo;decompressing\u0026rdquo; that information into your own knowledge network: assumptions, derivations, engineering steps, and the limits of the results. Only then can you judge when to use it and when not to.\u003c/p\u003e","title":"Mastering a Paper"},{"content":"What problem does this paper solve, and what are the results? We know AI systems are expanding and can solve general tasks. But many AI agent applications today target small tasks. NVIDIA argues that small language models (SLMs) are capable, more suitable, and cheaper, and should be a main direction for future agents.\nThe paper discusses:\nWhat tasks current SLMs can handle Where general language ability matters The limits of SLMs as agents Conclusion: moving from LLMs to SLMs has advantages in both capability and cost.\n","permalink":"http://localhost:1313/en/thoughts/thoughts/reading-nvidia-small-models-paper/","summary":"\u003ch1 id=\"what-problem-does-this-paper-solve-and-what-are-the-results\"\u003eWhat problem does this paper solve, and what are the results?\u003c/h1\u003e\n\u003cp\u003eWe know AI systems are expanding and can solve general tasks. But many AI agent applications today target small tasks. NVIDIA argues that small language models (SLMs) are capable, more suitable, and cheaper, and should be a main direction for future agents.\u003c/p\u003e\n\u003cp\u003eThe paper discusses:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eWhat tasks current SLMs can handle\u003c/li\u003e\n\u003cli\u003eWhere general language ability matters\u003c/li\u003e\n\u003cli\u003eThe limits of SLMs as agents\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eConclusion: moving from LLMs to SLMs has advantages in both capability and cost.\u003c/p\u003e","title":"Reading an NVIDIA Paper on Small Language Models"}]